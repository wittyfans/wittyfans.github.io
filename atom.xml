<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>wittyfans</title>
  
  <subtitle>学则不固,知则不惑</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://wittyfans.com/"/>
  <updated>2019-11-21T08:24:31.315Z</updated>
  <id>http://wittyfans.com/</id>
  
  <author>
    <name>wittyfans</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>非监督学习：PCA and NMF</title>
    <link href="http://wittyfans.com/coding/%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%EF%BC%9APCA-and-NMF.html"/>
    <id>http://wittyfans.com/coding/非监督学习：PCA-and-NMF.html</id>
    <published>2019-11-21T08:20:37.000Z</published>
    <updated>2019-11-21T08:24:31.315Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://i.loli.net/2019/11/21/I34aLMFuywnHqzA.png" alt=""></p><blockquote><p>非监督学习的最后两章，我们会学习 Dimension reduction, Dimension reduction就是从数据中发现一定的模式，通过这种模式我们就可以对数据进行压缩，这对于计算和存储来说都是非常有利的，特别是在大数据时代。</p></blockquote><a id="more"></a><p>dimension reduction核心的功能是去除数据中的噪音，保留那些最基本的东西，噪音去除之后，有助于减少我们处理 classfication 与 regression 中碰到的问题。</p><p>接下来我们介绍最基本的 dimension reduction 算法，<em>Principal Component Analysis</em> (PCA).</p><h1 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h1><p>PCA 主要有两个步骤：</p><ol><li>decorrlation</li><li>dimension reduction</li></ol><p>我们先讲第一个步骤，decorrlation, decorrlation会将数据旋转到与坐标轴对齐，并将其均值移动到0附近，所以PCA并不会改变原始数据。</p><p><img src="https://i.loli.net/2019/11/20/qolJbVCpOUg5PBY.png" alt=""></p><p>PCA和 StandardScaler 一样，有fit和transform方法，fit方法会学习如何去shift与rotate数据，但并不会做出任何操作。</p><p>transform方法，则会应用fit学习到的东西。</p><p>在PCA对数据transform后，原来数据的columns对应数据的features，转换后的数据列则对应pca的features。</p><p>我们用皮尔逊系数来衡量相关性，如果原来的数据是有相关性的，则转化后的数据不会再具备这种特性。</p><p>以我们的谷物的长、宽数据为例，</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># Perform the necessary imports</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from scipy.stats import pearsonr</span><br><span class="line"></span><br><span class="line"># Assign the 0th column of grains: width</span><br><span class="line">width = grains[:,0]</span><br><span class="line"></span><br><span class="line"># Assign the 1st column of grains: length</span><br><span class="line">length = grains[:,1]</span><br><span class="line"></span><br><span class="line"># Scatter plot width vs length</span><br><span class="line">plt.scatter(width, length)</span><br><span class="line">plt.axis(&apos;equal&apos;)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"># Calculate the Pearson correlation</span><br><span class="line">correlation, pvalue = pearsonr(width,length)</span><br><span class="line"></span><br><span class="line"># Display the correlation</span><br><span class="line">print(correlation)</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/11/20/XuxqSG6vWB7Ddlf.png" alt="transform前"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># Import PCA</span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line"></span><br><span class="line"># Create PCA instance: model</span><br><span class="line">model = PCA()</span><br><span class="line"></span><br><span class="line"># Apply the fit_transform method of model to grains: pca_features</span><br><span class="line">pca_features = model.fit_transform(grains)</span><br><span class="line"></span><br><span class="line"># Assign 0th column of pca_features: xs</span><br><span class="line">xs = pca_features[:,0]</span><br><span class="line"></span><br><span class="line"># Assign 1st column of pca_features: ys</span><br><span class="line">ys = pca_features[:,1]</span><br><span class="line"></span><br><span class="line"># Scatter plot xs vs ys</span><br><span class="line">plt.scatter(xs, ys)</span><br><span class="line">plt.axis(&apos;equal&apos;)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"># Calculate the Pearson correlation of xs and ys</span><br><span class="line">correlation, pvalue = pearsonr(xs, ys)</span><br><span class="line"></span><br><span class="line"># Display the correlation</span><br><span class="line">print(correlation)</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/11/20/kPyiZ9QhEKxY58S.png" alt="transform后"></p><p>可以看到，谷物的长与宽是有相关性的，即它的叶片越长，宽度也越宽。但在transofor后，数据就与坐标系对齐了。</p><h2 id="Intrinsic-dimension"><a href="#Intrinsic-dimension" class="headerlink" title="Intrinsic dimension"></a>Intrinsic dimension</h2><p>Intrinsic dimension 即在降维或者压缩数据过程中，为了让你的数据特征最大程度的保持，你最低限度需要保留哪些features。</p><p>它同时也告诉了我们可以把数据压缩到什么样的程度，所以你需要了解哪些 feature 对你的数据集影响是最大的。</p><p>比如我们衡量电脑性能，我们可以把键盘鼠标这些feature去掉，但是cpu、gpu、内存性能这些你肯定要保留对不对？cpu、gpu、内存性能，这就是我们说的 features required to approximate it。</p><p>但有的人说，我觉得硬盘也得加上去，这样我们的 intrinsic dimension 就从 3 增加到4了。</p><p>所以你看，intrinsic dimension 数量是一个视不同情况而定的值。</p><p>那我们将设为多少比较合适呢？考虑我们的iris数据，我们选择</p><ul><li>sepal width</li><li>sepal length</li><li>petal width</li></ul><p>这3个变量，这样我们就可以将它绘制到3维空间，但我们发现它的图像在3维空间是很平的，这意味着某个变量的值的方差很小，也就是说它对整个图像的影响不大，我们只选择另外2个变量，也可以不损失太多的细节。</p><p><img src="https://i.loli.net/2019/11/20/iUkctja8u2RovbA.png" alt=""></p><p>但scatter图只能表示3维以下的数据，如果我们的 features 有很多个，我们要如何找到那些影响程度大的 features 呢？</p><p>这就是 PCA 擅长的地方，我们可以统计 PCA 中那些方差显著的features。</p><p>下面是iris数据集各个features的方差排序图：</p><p><img src="https://i.loli.net/2019/11/20/qDPFfX7E8xjMwAu.png" alt=""></p><p>可以看到最后的那个数据方差非常小，所以它对我们数据集的影响完全可以去除掉。</p><p>那么如何绘制数据集的 variances 呢？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># Perform the necessary imports</span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.pipeline import make_pipeline</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"># Create scaler: scaler</span><br><span class="line">scaler = StandardScaler()</span><br><span class="line"></span><br><span class="line"># Create a PCA instance: pca</span><br><span class="line">pca = PCA()</span><br><span class="line"></span><br><span class="line"># Create pipeline: pipeline</span><br><span class="line">pipeline = make_pipeline(scaler,pca)</span><br><span class="line"></span><br><span class="line"># Fit the pipeline to &apos;samples&apos;</span><br><span class="line">pipeline.fit(samples)</span><br><span class="line"></span><br><span class="line"># Plot the explained variances</span><br><span class="line">features = range(pca.n_components_)</span><br><span class="line">plt.bar(features,pca.explained_variance_)</span><br><span class="line">plt.xlabel(&apos;PCA feature&apos;)</span><br><span class="line">plt.ylabel(&apos;variance&apos;)</span><br><span class="line">plt.xticks(features)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h2 id="PCA降维"><a href="#PCA降维" class="headerlink" title="PCA降维"></a>PCA降维</h2><p>我们在做数据降维的时候，得指定需要保留的features，即通过指定pca的参数<code>n_components=2</code>, 我们保留多少个features，这可以通过Intrinsic dimension来计算。</p><p>我们以iris数据为例，当我们用PCA把数据从四维（petal width,length和sepal length,width）降到2维后，我们再绘制它的scatter图，会发现它们还是分为三部分。</p><p>但是对于如字词统计的例子中，我们可能需要用其他的算法来代替，在这种数据中，每一行代表一个文档，每一列代表某个固定词组（fixed vocabulary）中的词语.</p><p>我们会统计，每个词语在每个文档中出现的次数array。不过，只有少数的词语会出现很多的文档之中，大部分词语在某些文档中的出现次数都是0，这样的array叫做sparse(稀疏的），sparse array中大部分的值都是0.</p><p>我们使用 <em>csr_matrix</em> 来代替 <em>numpy array</em> 去处理这样的数据。</p><p><em>csr_matrix</em> 只会保存那些非0值，这样就更方便，但是PCA不支持 <em>csr_matrix</em>，我们需要用 <em>TruncatedSVD</em> 来代替 PCA。</p><p><em>‌TruncatedSVD</em> 的效果与 PCA 是一样的，只不过它接受 <em>csr_matrix</em> 数组，除此之外使用方法都是一样的。</p><p>示例，我们来对一组词语进行分词操作，我们的词组如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># data</span><br><span class="line">documents=[&apos;cats say meow&apos;, &apos;dogs say woof&apos;, &apos;dogs chase cats&apos;]</span><br><span class="line"></span><br><span class="line"># Import TfidfVectorizer</span><br><span class="line">from sklearn.feature_extraction.text import TfidfVectorizer</span><br><span class="line"></span><br><span class="line"># Create a TfidfVectorizer: tfidf</span><br><span class="line">tfidf = TfidfVectorizer() </span><br><span class="line"></span><br><span class="line"># Apply fit_transform to document: csr_mat</span><br><span class="line">csr_mat = tfidf.fit_transform(documents)</span><br><span class="line"></span><br><span class="line"># Print result of toarray() method</span><br><span class="line">print(csr_mat.toarray())</span><br><span class="line"></span><br><span class="line"># Get the words: words</span><br><span class="line">words = tfidf.get_feature_names()</span><br><span class="line"></span><br><span class="line"># Print words</span><br><span class="line">print(words)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">output: [[0.51785612 0.         0.         0.68091856 0.51785612 0.        ]</span><br><span class="line"> [0.         0.         0.51785612 0.         0.51785612 0.68091856]</span><br><span class="line"> [0.51785612 0.68091856 0.51785612 0.         0.         0.        ]]</span><br><span class="line"> </span><br><span class="line"> [&apos;cats&apos;, &apos;chase&apos;, &apos;dogs&apos;, &apos;meow&apos;, &apos;say&apos;, &apos;woof&apos;]</span><br></pre></td></tr></table></figure><h1 id="NMF"><a href="#NMF" class="headerlink" title="NMF"></a>NMF</h1><p>NMF与PCA一样，都是降维算法。不过NMF不能用于所有的预测，只能用于非负值。</p><p>NMF会将数据集中的每组数据分解并分别计算其和。</p><p>考虑字词统计的例子，NMF使用tf-idf来计算字词出现的频率。<br>tf是词语出现的频率，在每一个document中，如果一个词占整个document中文字的百分之10，那么NMF的输出的tf就是0.1.</p><p>而idf用来降低那些常用词的影响，如,<code>的,那个，这个</code>等等。</p><p>我们知道，在PCA中，我们定义了多少个<code>n_components</code>,就相当于是保留了多少个features。</p><p>在NMF中，它也会去学习数据集的 <em>component dimension</em>。</p><p>需注意，NMF的条目，以及features的值，总是正数。</p><h2 id="NMF算法使用"><a href="#NMF算法使用" class="headerlink" title="NMF算法使用"></a>NMF算法使用</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># Import NMF</span><br><span class="line">from sklearn.decomposition import NMF</span><br><span class="line"></span><br><span class="line"># Create an NMF instance: model</span><br><span class="line">model = NMF(n_components=6)</span><br><span class="line"></span><br><span class="line"># Fit the model to articles</span><br><span class="line">model.fit(articles)</span><br><span class="line"></span><br><span class="line"># Transform the articles: nmf_features</span><br><span class="line">nmf_features = model.transform(articles)</span><br><span class="line"></span><br><span class="line"># Print the NMF features</span><br><span class="line">print(nmf_features)</span><br></pre></td></tr></table></figure><h2 id="论文字词统计"><a href="#论文字词统计" class="headerlink" title="论文字词统计"></a>论文字词统计</h2><blockquote><p>Components correspond to topics of documents, and the NMF features reconstruct the documents from the topics</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># Import pandas</span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line"># Create a DataFrame: components_df</span><br><span class="line">components_df = pd.DataFrame(model.components_,columns=words)</span><br><span class="line"></span><br><span class="line"># Print the shape of the DataFrame</span><br><span class="line">print(components_df.shape)</span><br><span class="line"></span><br><span class="line"># Select row 3: component</span><br><span class="line">component = components_df.iloc[3]</span><br><span class="line"></span><br><span class="line"># Print result of nlargest</span><br><span class="line">print(component.nlargest())</span><br></pre></td></tr></table></figure><h2 id="用户喜好预测"><a href="#用户喜好预测" class="headerlink" title="用户喜好预测"></a>用户喜好预测</h2><p>NMF有一个重要的应用是作为内容推荐，假设我们有一个用户和一部电影，我们想要根据电影的内容做出预测：</p><table><thead><tr><th style="text-align:left"></th><th style="text-align:left">喜剧片</th><th style="text-align:left">动作片</th></tr></thead><tbody><tr><td style="text-align:left">小雅</td><td style="text-align:left">喜欢</td><td style="text-align:left">不喜欢</td></tr><tr><td style="text-align:left">百货战警</td><td style="text-align:left">3</td><td style="text-align:left">1</td></tr></tbody></table><blockquote><p>红番区是动作喜剧片。</p></blockquote><p>现在假设小雅喜欢喜剧片，不喜欢动作片，同时假设我们现在只根据一部电影拥有多少喜剧成分与动作片成分来评价它。</p><p>现在因为小雅喜欢喜剧片<code>+3</code>，不喜欢动作片<code>+0</code>，所以它可能给出的评价是 3分 。</p><p>我们再来考虑小明的情况：</p><table><thead><tr><th style="text-align:left"></th><th style="text-align:left">喜剧片</th><th style="text-align:left">动作片</th></tr></thead><tbody><tr><td style="text-align:left">小明</td><td style="text-align:left">不喜欢</td><td style="text-align:left">喜欢</td></tr><tr><td style="text-align:left">红番区</td><td style="text-align:left">3</td><td style="text-align:left">1</td></tr></tbody></table><p>小明喜欢动作片，不喜欢喜剧片，所以喜剧片的3分不计，动作片1分计入，即小明只给出了1分的评价。</p><table><thead><tr><th style="text-align:left"></th><th style="text-align:left">喜剧片</th><th style="text-align:left">动作片</th></tr></thead><tbody><tr><td style="text-align:left">小雅</td><td style="text-align:left">喜欢</td><td style="text-align:left">喜欢</td></tr><tr><td style="text-align:left">红番区</td><td style="text-align:left">3</td><td style="text-align:left">1</td></tr></tbody></table><p>再考虑一个例子：</p><table><thead><tr><th style="text-align:left"></th><th style="text-align:left">喜剧片</th><th style="text-align:left">动作片</th></tr></thead><tbody><tr><td style="text-align:left">小刘</td><td style="text-align:left">喜欢</td><td style="text-align:left">喜欢</td></tr><tr><td style="text-align:left">让子弹飞</td><td style="text-align:left">1</td><td style="text-align:left">3</td></tr></tbody></table><p>小刘喜欢喜剧也喜欢动作，所以这部电影他可能会给出1+3，四分的评价。</p><p>我们把一批电影编号为M1-M5,列表示分别占喜剧与动作的成分，同时把一批用户分类为他们是否喜欢喜剧或动作片。</p><p><img src="https://i.loli.net/2019/11/21/1RKTpP4MFcVuyfS.png" alt=""></p><p>当我们把左边的两个表结合，就可以得到后面的这个表：</p><p><img src="https://i.loli.net/2019/11/21/PTgzFwfcnsX5uQp.png" alt=""></p><p>这是通过算点积算出来的，你可以看到：</p><p><img src="https://i.loli.net/2019/11/21/Astuv1eTKCGHDyP.png" alt=""></p><ul><li>有些人的喜好一样，则他们给出的电影评分也是一样的</li><li>如果两个电影所占的成分差不多，则也会得到一样的评分</li><li>B+C=D,这是因为B的喜欢与C的喜好相反，而D对与这两者都喜欢</li><li>M2与M3的平均值是M5，即M5的喜剧与动作成分是M2与M3的平均值，所以M5的评分也是M2与M3的平均值</li></ul><p>上面的这个表叫做Matrix Factorization, 我们要存储这个表是非常费存储的，假设我们有很多的电影与用户，算一下我们需要一个多大的Matrix.</p><p><img src="https://i.loli.net/2019/11/21/SnX2JGWdIgsM6oL.png" alt=""></p><p>所以我们在存储的时候，只存储用户的喜好与电影的信息,再通过图表演示一下：</p><p><img src="https://i.loli.net/2019/11/21/TqmufiSXRHQchPZ.png" alt=""></p><p>第一种方案是我们直接存储用户对所有电影评分与可能的评分，假设有2000个用户，1000部电影，这意味着200万份数据。</p><p><img src="https://i.loli.net/2019/11/21/8fwGTU7L96uIc5e.png" alt=""></p><p>如果我们通过feature计算，则只需要30万份数据</p><p><img src="https://i.loli.net/2019/11/21/k9Ml5mUPoBg4SZC.png" alt=""></p><p>现在我们回到以前，对与NMP算法，其中一个问题是，</p><p><img src="https://i.loli.net/2019/11/21/Astuv1eTKCGHDyP.png" alt=""></p><p>如何通过中间的点积，得到两边的数据？就像24可以是2x12,也可以是4x6.</p><p>最开始我们可以随机的将两边的数据列出来，算出点积并与手上的点积比对，如果过低，那么我们将相应的用户喜好与电影评分做出调整，直到所有的值接近我们已有的点积中的值。</p><p><img src="https://i.loli.net/2019/11/21/c9QkmIZ5TbEUFMY.png" alt=""></p><p>我们算到什么程度，才停止呢？我们需要定义一个error function,它就是告诉机器，你哪里错了，做的还不够，得继续算。</p><p><img src="https://i.loli.net/2019/11/21/I34aLMFuywnHqzA.png" alt=""></p><p>这里的error就是我们手上的数据与机器算出来的数据的差的平方，我们把每个用户或者每个电影的error加起来，error function的作用就是尽量让error的和最小。</p><p>在现实的情况中，我们不可能每个用户对每个电影都有评分，所以我们拿到的点积图中间可能有很多空白:</p><p><img src="https://i.loli.net/2019/11/21/q865U2sbpad9x3l.png" alt=""></p><p>但是我们可以根据这些值算出来用户与电影的属性,进而给用户推荐电影:</p><p><img src="https://i.loli.net/2019/11/21/qUIHQT75DZ6Rhdk.png" alt=""></p><blockquote><p><a href="https://www.youtube.com/watch?v=ZspR5PZemcs&amp;t=693s" target="_blank" rel="noopener">参考:How does Netflix recommend movies? Matrix Factorization</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/11/21/I34aLMFuywnHqzA.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;非监督学习的最后两章，我们会学习 Dimension reduction, Dimension reduction就是从数据中发现一定的模式，通过这种模式我们就可以对数据进行压缩，这对于计算和存储来说都是非常有利的，特别是在大数据时代。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="coding" scheme="http://wittyfans.com/categories/coding/"/>
    
    
      <category term="python" scheme="http://wittyfans.com/tags/python/"/>
    
      <category term="data analysis" scheme="http://wittyfans.com/tags/data-analysis/"/>
    
      <category term="sklearn" scheme="http://wittyfans.com/tags/sklearn/"/>
    
  </entry>
  
  <entry>
    <title>非监督学习：Clustering and Visualization</title>
    <link href="http://wittyfans.com/coding/%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%EF%BC%9AClustering-and-Visualization.html"/>
    <id>http://wittyfans.com/coding/非监督学习：Clustering-and-Visualization.html</id>
    <published>2019-11-19T15:02:57.000Z</published>
    <updated>2019-11-20T03:14:45.440Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://i.loli.net/2019/11/19/GIND7pRkxahrXBu.png" alt=""></p><blockquote><p>非监督学习：即根据现有的数据去发掘存在数据中的一些模式,比如根据用户的购买记录，(<em>clustering</em>) 定义用户画像, 或根据数据的模式来压缩数据（<em>dimension reduction</em>.</p></blockquote><a id="more"></a><h1 id="非监督学习"><a href="#非监督学习" class="headerlink" title="非监督学习"></a>非监督学习</h1><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><h2 id="非监督学习介绍"><a href="#非监督学习介绍" class="headerlink" title="非监督学习介绍"></a>非监督学习介绍</h2><p>相比较监督学习，如对癌症良性（<em>benign</em>）与恶性（<em>cancerous</em>）的分类，在这个例子中，我们发现的模式是: <em>guided</em>,或者说是: <em>supervised</em>，这一过程依赖我们标记过的数据，而非监督学习不需要我们使用标记过的数据去发现这些模式，我们不需要去guide the machine。</p><h1 id="聚类与数据探索"><a href="#聚类与数据探索" class="headerlink" title="聚类与数据探索"></a>聚类与数据探索</h1><h2 id="iris-数据集"><a href="#iris-数据集" class="headerlink" title="iris 数据集"></a>iris 数据集</h2><p>iris数据集包括了三种植物，它们有四种衡量方式：</p><ul><li>petal width</li><li>petal length</li><li>sepal width</li><li>sepql length</li></ul><p>这些叫做数据的 <em>features</em> ,在这门课程中，像这样的课程将会将数据集定义为2维数组,列定义衡量标准( <em>the features</em> )，行代表一个样例( <em>a sample</em> ).</p><p>我们的数据集有<strong>四个衡量方式，对应一个四维数组</strong>，事实上你可以推算出来：</p><p>$$Dimension=number\ of\ features$$</p><p>我们无法直接对四维数据可视化，但我们可以使用非监督学习技术来从其中获取想要的信息。</p><p>这一章，我们会使用 k-means 聚类算法将所有的样例数据分类。</p><p>k-means算法会从数据集中发现特定的分类，即把n个点（可以是样本的一次观察或一个实例）划分到k个聚类中，使得每个点都属于离它最近的均值（此即聚类中心）对应的聚类，以之作为聚类的标准。</p><p>k-means算法在sklearn中有实现，我们来看一个示例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.cluster import KMeans</span><br><span class="line">modal = KMeans(n_clusters=3)</span><br><span class="line"></span><br><span class="line">modal.fit(samples)</span><br><span class="line"></span><br><span class="line">labels = model.predit(samples)</span><br></pre></td></tr></table></figure><ol><li>导入kmeans包</li><li>实例化，并指定你想要从数据中发现的聚类数量(n_clusters)</li><li>fit sample数据</li><li>用同样的数据做预测（演示需要），这会返回所有的sample，同时其中包含它所属的聚类。</li></ol><blockquote><p><a href="http://shabal.in/visuals/kmeans/4.html" target="_blank" rel="noopener">这里</a>有k-means算法的动画演示,看一下你就明白啦，另外一个油管的<a href="http://shabal.in/visuals/kmeans/4.html" target="_blank" rel="noopener">视频版</a></p></blockquote><h2 id="一个简单的例子"><a href="#一个简单的例子" class="headerlink" title="一个简单的例子"></a>一个简单的例子</h2><p><strong>我们的数据：</strong></p><p>我们的数据 <em>points</em> 是一个300行，2列的数据集。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">array([[ 0.06544649, -0.76866376],</span><br><span class="line">       [-1.52901547, -0.42953079],</span><br><span class="line">       [ 1.70993371,  0.69885253],</span><br><span class="line">       [ 1.16779145,  1.01262638],</span><br><span class="line">       [-1.80110088, -0.31861296],</span><br><span class="line">       [-1.63567888, -0.02859535])</span><br></pre></td></tr></table></figure><p><strong>数据集的分布</strong>:</p><p><img src="https://i.loli.net/2019/11/19/9ALwWz1bRlOBCor.png" alt=""></p><p>我们会把数据集中的第一列作为 x,第二列作为 y，使用数组的切片分别将 x,y 部分的值赋给xs,ys.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">xs = points[:,0]</span><br><span class="line">ys = points[:1]</span><br></pre></td></tr></table></figure><p>有了数据之后，我们就可以对模型进行初始化与训练了，我们初始化Kmeans实例，并将数据整个传给它进行训练，训练之后我们用新准备的数据new_points来预测它的性能。</p><p>model预测后的结果保存在labels中，这是对new_points数据的预测，labels的数据只有一列，保存着分类的情况，它跟我们的数组new_points对应的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># Import KMeans</span><br><span class="line">from sklearn.cluster import KMeans</span><br><span class="line"></span><br><span class="line"># Create a KMeans instance with 3 clusters: model</span><br><span class="line">model = KMeans(n_clusters=3)</span><br><span class="line"></span><br><span class="line"># Fit model to points</span><br><span class="line">model.fit(points)</span><br><span class="line"></span><br><span class="line"># Determine the cluster labels of new_points: labels</span><br><span class="line">labels = model.predict(new_points)</span><br><span class="line"></span><br><span class="line"># Print cluster labels of new_points</span><br><span class="line">print(labels)</span><br></pre></td></tr></table></figure><p>因为预测的数据跟原始数据是对应的，所以我们以数据中的第一列作为x，第二列作为y，绘制scatter图，然后指定scatter的颜色参数c为labels，这样就可以在数据可视化的时候将不同聚类的数据分开表示。</p><p><strong>聚类的中心：centroids</strong></p><p>不同的聚类，它们都有自己的中心点，这个中心点可以直接通过模型的属性 <code>model.cluster_centers_</code> 找到。我们的模型找到了几个聚类，cluster_centers_就有几组数据，下面是3个<code>n_clusters</code>的例子:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([[-1.57568905, -0.22531944],</span><br><span class="line">       [ 0.18034887, -0.81701955],</span><br><span class="line">       [ 1.01378685,  0.98288627]])</span><br></pre></td></tr></table></figure><p>我们将聚类后的数据与centroids都绘出来的效果：</p><p><img src="https://i.loli.net/2019/11/19/Q4gzo9pkG7vr1PI.png" alt=""></p><h2 id="选择-n-clusters（inertia）"><a href="#选择-n-clusters（inertia）" class="headerlink" title="选择 n_clusters（inertia）"></a>选择 n_clusters（inertia）</h2><p>如何选择n_clusters,一个好的聚合器，需要尽可能的使不同聚类的数量少，同时聚类中的数据集与centroids的距离最近。</p><p>聚类器有一个参数专门来描述这种关系，即 <em>‌inertia_</em>， 我们可以对同一个数据变化不同的n_clusters来查看它的inertia_的变化:</p><p><img src="https://i.loli.net/2019/11/19/IPUG5LMecSDAxoy.png" alt=""></p><p>在这里例子中，可以看到k从1-3一直是急剧下降的，随后开始变得平缓，我们一般选择图像从急剧下降到变的平缓之间的这个值，这个例子中，3是不错的选择。</p><h2 id="缩放数据与pipline"><a href="#缩放数据与pipline" class="headerlink" title="缩放数据与pipline"></a>缩放数据与pipline</h2><p>我们有一组这样的数据:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[242.0, 23.2, 25.4, 30.0, 38.4, 13.4]</span><br></pre></td></tr></table></figure><p>每一列是features，对数据集进行聚类，但是发现效果并不理想，原因是这些列之间的方差很大，我们需要将其标准化到同一个维度，如0，1或者-1，1,这个步骤叫 <em>‌Scaling</em>。</p><p>我们使用 <em>‌StandardScaler</em> 来缩放数据，另外这里我们使用管道来将缩放与kmeans的步骤结合到一起，关于pipline的介绍，请参考之前的文章。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"># 导入数据</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn.pipeline import make_pipeline</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.cluster import KMeans</span><br><span class="line"></span><br><span class="line"># 创建scaler</span><br><span class="line">scaler = StandardScaler()</span><br><span class="line"></span><br><span class="line"># 创建 kmeans 实例</span><br><span class="line">kmeans = KMeans(n_clusters=4)</span><br><span class="line"></span><br><span class="line"># 创建管道 pipeline</span><br><span class="line">pipeline = make_pipeline(scaler,kmeans)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 对管道fit数据</span><br><span class="line">pipeline.fit(samples)</span><br><span class="line"></span><br><span class="line"># 计算 labels</span><br><span class="line">labels = pipeline.predict(samples)</span><br><span class="line"></span><br><span class="line"># 根据 labels 和 species 组合成dataframe</span><br><span class="line">df = pd.DataFrame(&#123;&apos;labels&apos;:labels,&apos;species&apos;:species&#125;)</span><br><span class="line"></span><br><span class="line"># 计算 crosstab</span><br><span class="line">ct = pd.crosstab(df[&apos;labels&apos;],df[&apos;species&apos;])</span><br><span class="line"></span><br><span class="line"># 打印 ct</span><br><span class="line">print(ct)</span><br></pre></td></tr></table></figure><blockquote><p>如果你对 <em>crosstab</em> 函数不是很了解，<a href="https://medium.com/@yangdustin5/quick-guide-to-pandas-pivot-table-crosstab-40798b33e367" target="_blank" rel="noopener">这里</a>有 <em>pandas</em> 中关于<em>crosstab</em> 函数与 <em>pivot_table</em> 函数的对比。</p></blockquote><h2 id="根据股价变动聚类股票"><a href="#根据股价变动聚类股票" class="headerlink" title="根据股价变动聚类股票"></a>根据股价变动聚类股票</h2><p>我们这里有一份股价数据，它的shape为:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">In [2]: movements.shape</span><br><span class="line">Out[2]: (60, 963)</span><br></pre></td></tr></table></figure><p>其中每一行是一个公司的数据，对于 movements 其中的每一行数据，长度为963:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">In [5]: len(movements[0])</span><br><span class="line">Out[5]: 963</span><br></pre></td></tr></table></figure><p>其记录的是这个公司每天的股价波动情况。</p><p>我们前面处理的数据，在缩放的时候，我们使用的是 <em>‌StandardScaler</em>, standardscaler缩放的方式是移除所有数据的平均值然后缩放到一个维度，但对于股价来说，我们使用 <em>‌Normalizer</em>，它会针对每个公司的股价分别缩放，彼此独立。</p><p><strong>缩放数据并创建管道</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># Import Normalizer</span><br><span class="line">from sklearn.preprocessing import Normalizer</span><br><span class="line"></span><br><span class="line"># Create a normalizer: normalizer</span><br><span class="line">normalizer = Normalizer()</span><br><span class="line"></span><br><span class="line"># Create a KMeans model with 10 clusters: kmeans</span><br><span class="line">kmeans = KMeans(n_clusters=10)</span><br><span class="line"></span><br><span class="line"># Make a pipeline chaining normalizer and kmeans: pipeline</span><br><span class="line">pipeline = make_pipeline(normalizer,kmeans)</span><br><span class="line"></span><br><span class="line"># Fit pipeline to the daily price movements</span><br><span class="line">pipeline.fit(movements)</span><br></pre></td></tr></table></figure><p><strong>聚类股票</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># Import pandas</span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line"># Predict the cluster labels: labels</span><br><span class="line">labels = pipeline.predict(movements)</span><br><span class="line"></span><br><span class="line"># Create a DataFrame aligning labels and companies: df</span><br><span class="line">df = pd.DataFrame(&#123;&apos;labels&apos;: labels, &apos;companies&apos;: companies&#125;)</span><br><span class="line"></span><br><span class="line"># Display df sorted by cluster label</span><br><span class="line">print(df.sort_values(by=&apos;labels&apos;))</span><br></pre></td></tr></table></figure><p>这里的companies数据，是在导入数据之前就剔出来了的。</p><h1 id="可视化层次结构"><a href="#可视化层次结构" class="headerlink" title="可视化层次结构"></a>可视化层次结构</h1><p>对于那些没有技术背景的人来说，最好使用图表表达你的发现。对于非监督学习这部分，我们学习两种可视化技术：</p><ul><li>t-SNE</li><li>Hierarchical clustring</li></ul><p>我们先介绍 <em>Hierarchical clustring</em>。</p><h2 id="Hierarchical-clustring"><a href="#Hierarchical-clustring" class="headerlink" title="Hierarchical clustring"></a>Hierarchical clustring</h2><p>Hierarchical clustring 的原理是，我们处理数据时，第一次使用比较大的 <em>‌n_clusters</em>，随后慢慢缩小，到最后只剩一个 <em>‌n_clusters</em>。</p><p>为了绘制Hierarchical clustring，我们需要的包主要是 linkage,dendrogram.</p><ul><li>linkage: 负责计算层次聚类信息</li><li>dendrogram: 负责可视化</li></ul><p>下面我们以一份谷物数据举例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># Perform the necessary imports</span><br><span class="line">from scipy.cluster.hierarchy import linkage, dendrogram</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"># Calculate the linkage: mergings</span><br><span class="line">mergings = linkage(samples,method=&apos;complete&apos;)</span><br><span class="line"></span><br><span class="line"># Plot the dendrogram, using varieties as labels</span><br><span class="line">dendrogram(mergings,</span><br><span class="line">           labels=varieties,</span><br><span class="line">           leaf_rotation=90,</span><br><span class="line">           leaf_font_size=6,</span><br><span class="line">)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/11/19/kaw1DUq2AYxlEfi.png" alt=""></p><h2 id="股票的层次化示例"><a href="#股票的层次化示例" class="headerlink" title="股票的层次化示例"></a>股票的层次化示例</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># Import normalize</span><br><span class="line">from sklearn.preprocessing import normalize</span><br><span class="line"></span><br><span class="line"># Normalize the movements: normalized_movements</span><br><span class="line">normalized_movements = normalize(movements)</span><br><span class="line"></span><br><span class="line"># Calculate the linkage: mergings</span><br><span class="line">mergings = linkage(normalized_movements,method=&apos;complete&apos;)</span><br><span class="line"></span><br><span class="line"># Plot the dendrogram</span><br><span class="line">dendrogram(mergings,labels=companies,leaf_rotation=90,leaf_font_size=6)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>这里我们来对比下标准化与无标准化的结果,即<code>linkage(normalized_movements,method=&#39;complete&#39;)</code>与<code>linkage(movements,method=&#39;complete&#39;)</code>的区别：</p><p><img src="https://i.loli.net/2019/11/19/Ns8USVibcFehlxw.png" alt="not normalized"></p><p><img src="https://i.loli.net/2019/11/19/QtBcrdTgPMA6U73.png" alt="normalized"></p><h2 id="intermediate-clustering"><a href="#intermediate-clustering" class="headerlink" title="intermediate clustering"></a>intermediate clustering</h2><p>dendrogram的图是有高度的，它的高度值描述的是两个features之间的距离，chevron与exxon的距离是它们两者merge的时候那个柱子的高度，也就是这两者之间的距离，在这个层面，它们之间的距离是最短的。</p><p>而看整个图像的话，图像最高的部分发生的合并，则说明它们之间的距离是最远的。</p><p>当我们在计算层次聚类信息的时候，linkage方法中有一个method，我们把它指定为 <em>complete</em>,它的意思是我们不会限定 features之间的距离，我需要计算所有features之间的距离，不管他们多远；如果我在这里作出限制，比如15，那么两个features之间距离超过15的部分我就忽略了。</p><p>怎么从一堆数据集中，根据 features之间的距离 来筛选数据呢？我们需要 fcluster 方法。</p><p>我们看看设定高度为 15 的情况: </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># Perform the necessary imports</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from scipy.cluster.hierarchy import linkage, dendrogram</span><br><span class="line"></span><br><span class="line"># Calculate the linkage: mergings</span><br><span class="line">mergings = linkage(samples,method=&apos;single&apos;)</span><br><span class="line"></span><br><span class="line"># Plot the dendrogram</span><br><span class="line">dendrogram(mergings,labels=country_names,leaf_rotation=90,leaf_font_size=6)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/11/19/FoWTypesfNmHgtI.png" alt=""></p><p>下面是fcluster方法使用示例,筛选高度为6以内的数据：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># Perform the necessary imports</span><br><span class="line">import pandas as pd</span><br><span class="line">from scipy.cluster.hierarchy import fcluster</span><br><span class="line"></span><br><span class="line"># Use fcluster to extract labels: labels</span><br><span class="line">labels = fcluster(mergings,6,criterion=&apos;distance&apos;)</span><br><span class="line"></span><br><span class="line"># Create a DataFrame with labels and varieties as columns: df</span><br><span class="line">df = pd.DataFrame(&#123;&apos;labels&apos;: labels, &apos;varieties&apos;: varieties&#125;)</span><br><span class="line"></span><br><span class="line"># Create crosstab: ct</span><br><span class="line">ct = pd.crosstab(df[&apos;labels&apos;],df[&apos;varieties&apos;])</span><br><span class="line"></span><br><span class="line"># Display ct</span><br><span class="line">print(ct)</span><br></pre></td></tr></table></figure><h1 id="t-SNE"><a href="#t-SNE" class="headerlink" title="t-SNE"></a>t-SNE</h1><p>t-sne算法的原理就是把高维度的数据转化成2维或者3维的，所以它是一种用于降维的机器学习方法。当我们想要对高维数据进行分类，又不清楚这个数据集有没有很好的可分性（即同类之间间隔小，异类之间间隔大），可以通过t-SNE投影到2维或者3维的空间中观察一下。</p><ul><li>SNE构建一个高维对象之间的概率分布，使得相似的对象有更高的概率被选择，而不相似的对象有较低的概率被选择。</li><li>SNE在低维空间里在构建这些点的概率分布，使得这两个概率分布之间尽可能的相似。</li></ul><p>我们看到t-SNE模型是非监督的降维，他跟kmeans等不同，他不能通过训练得到一些东西之后再用于其它数据（比如kmeans可以通过训练得到k个点，再用于其它数据集，而t-SNE只能单独的对数据做操作，也就是说他只有fit_transform，而没有fit操作）</p><blockquote><p>参考 <a href="https://blog.csdn.net/hustqb/article/details/78144384" target="_blank" rel="noopener">数据降维与可视化——t-SNE</a> 以及 <a href="http://www.datakit.cn/blog/2017/02/05/t_sne_full.html" target="_blank" rel="noopener">t-SNE完整笔记</a></p></blockquote><p>t-sne中有两个地方值得注意的，一个是fit_transform方法，它的作用是将X投影到一个嵌入空间并返回转换结果，另一个是learning_rate,它是学习率，建议取值为10.0-1000.0。</p><p>t-sne生成的数据是不一样的，尽管你绘图的代码是一样的。</p><p><strong>TSNE对于谷物数据的可视化</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># Import TSNE</span><br><span class="line">from sklearn.manifold import TSNE</span><br><span class="line"></span><br><span class="line"># Create a TSNE instance: model</span><br><span class="line">model = TSNE(learning_rate=200)</span><br><span class="line"></span><br><span class="line"># Apply fit_transform to samples: tsne_features</span><br><span class="line">tsne_features = model.fit_transform(samples)</span><br><span class="line"></span><br><span class="line"># Select the 0th feature: xs</span><br><span class="line">xs = tsne_features[:,0]</span><br><span class="line"></span><br><span class="line"># Select the 1st feature: ys</span><br><span class="line">ys = tsne_features[:,1]</span><br><span class="line"></span><br><span class="line"># Scatter plot, coloring by variety_numbers</span><br><span class="line">plt.scatter(xs,ys,c=variety_numbers)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/11/19/kj4BNZbtY1l7Qzx.png" alt=""></p><p><strong>TSNE对于股票数据的可视化</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># Import TSNE</span><br><span class="line">from sklearn.manifold import TSNE</span><br><span class="line"></span><br><span class="line"># Create a TSNE instance: model</span><br><span class="line">model = TSNE(learning_rate=50)</span><br><span class="line"></span><br><span class="line"># Apply fit_transform to normalized_movements: tsne_features</span><br><span class="line">tsne_features = model.fit_transform(normalized_movements)</span><br><span class="line"></span><br><span class="line"># Select the 0th feature: xs</span><br><span class="line">xs = tsne_features[:,0]</span><br><span class="line"></span><br><span class="line"># Select the 1th feature: ys</span><br><span class="line">ys = tsne_features[:,1]</span><br><span class="line"></span><br><span class="line"># Scatter plot</span><br><span class="line">plt.scatter(xs,ys,alpha=0.5)</span><br><span class="line"></span><br><span class="line"># Annotate the points</span><br><span class="line">for x, y, company in zip(xs, ys, companies):</span><br><span class="line">    plt.annotate(company, (x, y), fontsize=5, alpha=0.75)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/11/19/ONSqKFLUwQ7EDBJ.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/11/19/GIND7pRkxahrXBu.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;非监督学习：即根据现有的数据去发掘存在数据中的一些模式,比如根据用户的购买记录，(&lt;em&gt;clustering&lt;/em&gt;) 定义用户画像, 或根据数据的模式来压缩数据（&lt;em&gt;dimension reduction&lt;/em&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="coding" scheme="http://wittyfans.com/categories/coding/"/>
    
    
      <category term="python" scheme="http://wittyfans.com/tags/python/"/>
    
      <category term="data analysis" scheme="http://wittyfans.com/tags/data-analysis/"/>
    
      <category term="data science" scheme="http://wittyfans.com/tags/data-science/"/>
    
      <category term="sklearn" scheme="http://wittyfans.com/tags/sklearn/"/>
    
  </entry>
  
  <entry>
    <title>机器学习：处理jira工单的分类问题</title>
    <link href="http://wittyfans.com/coding/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%9A%E5%A4%84%E7%90%86jira%E5%B7%A5%E5%8D%95%E7%9A%84%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98.html"/>
    <id>http://wittyfans.com/coding/机器学习：处理jira工单的分类问题.html</id>
    <published>2019-11-18T12:10:20.000Z</published>
    <updated>2019-11-18T12:12:17.045Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>如何根据jira工单的category自动找到处理它的组呢？这是一个利用机器学习中knn算法的小实践.</p></blockquote><a id="more"></a><h1 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h1><p>我们使用knn分类算法，knn是广为使用的一种机器学习算法，应用于各种应用，如金融、医疗保健、政治学、手写字识别、图像识别与视频识别。</p><p>在信用评级中，金融机构用来预测客户的信用评级。在贷款支付机构中，银行来预测贷款是否安全。在政治中，它被用来预测潜在选名是否会投票。</p><p>简单介绍下knn:</p><p>knn是non-parametric算法，即无假设的意思，它不会对基础数据的分布做任何假设，即不会根据数据集来确定模型结构。</p><p>这很有用，因为在现实世界中，很多的数据集是不遵从数学理论的假设的。</p><p>同时knn是lazy algorithm算法，即它不需要在模型建立前做大量的数据训练工作。</p><h1 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h1><p>我们已经把一些数据保存到了jira数据库，现在将它们的分类与所属组拿出来：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sql = select category,assign_group from issues limit 10000</span><br><span class="line">db = pymysql.connect(&apos;db_host&apos;,&apos;db_username&apos;,&apos;db_pwd&apos;,&apos;db&apos;)</span><br><span class="line">df = pd.read_sql(sql,con=db)</span><br></pre></td></tr></table></figure><p>现在数据已经保存到了df中。</p><h1 id="A-basic-Exapple"><a href="#A-basic-Exapple" class="headerlink" title="A basic Exapple"></a>A basic Exapple</h1><h2 id="单个features"><a href="#单个features" class="headerlink" title="单个features"></a>单个features</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import preprocessing</span><br><span class="line">le = preprocessing.LabelEncoder()</span><br><span class="line">category_encoded = le.fit_transform(df.category)</span><br><span class="line">reporter_encoded = le.fit_transform(reporter)</span><br><span class="line">features = list(zip(category_encoded,reporter_encoded))</span><br><span class="line">label = le.fit(df.assign_group)</span><br><span class="line"></span><br><span class="line">knn = KNeighborsClassifier(n_neighbors=3)</span><br><span class="line">knn.fit(features,label)</span><br><span class="line">knn.predict([[0,2]])</span><br></pre></td></tr></table></figure><h2 id="多个features"><a href="#多个features" class="headerlink" title="多个features"></a>多个features</h2><p>另外一种方式，x是我们的category，y则是所属组。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.neighbors import KNeighborsClassifier </span><br><span class="line"></span><br><span class="line">x_df = df.category</span><br><span class="line">x_train = pd.get_dummies(x_df)</span><br><span class="line"></span><br><span class="line">y_df = df.assign_group</span><br><span class="line">y_train = y_df.values</span><br><span class="line"></span><br><span class="line">knn = KNeighborsClassifier(n_neighbors=6)</span><br><span class="line">knn.fit(x_train,y_train)</span><br></pre></td></tr></table></figure><p>随后你可以直接将x_train传给knn做个预测，然后跟真实的数据做个对比。</p><blockquote><p>拿训练的数据来做预测是不可取的，你必须给模型一些它从来没有看见过的数据预测，这样才能准确的测试模型的性能</p></blockquote><p>你也可以自己生成一些数据来查看，如你已经知道get_dummies后的df有144列，那么你可以自行生成一个2d的dummie数组传给knn.predit.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">arr_list = np.concatenate(np.zeros((1,143)))</span><br><span class="line">temp_arr = arr_list.tolist()</span><br><span class="line">temp_arr.insert(44,1)</span><br><span class="line">new_x = [temp_arr.insert]</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">output: array([&apos;Helpdesk CN&apos;])</span><br></pre></td></tr></table></figure><h2 id="分割数据并查看得分"><a href="#分割数据并查看得分" class="headerlink" title="分割数据并查看得分"></a>分割数据并查看得分</h2><p>下面演示了将数据拆分成train,和test后的预测分数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)</span><br><span class="line"></span><br><span class="line">knn= KNeighborsClassifier(n_neighbors=6)</span><br><span class="line">knn.fit(X_train,y_train)</span><br><span class="line"></span><br><span class="line">knn.score(X_test,y_test)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">output:0.781</span><br></pre></td></tr></table></figure><p>78%，这个模型效果还是不错的！</p><h2 id="选择Neighbors"><a href="#选择Neighbors" class="headerlink" title="选择Neighbors"></a>选择Neighbors</h2><p>我们知道对于knn算法，其中一个关键的参数是neighbors,那么对于不同的neighbors，我们的accuracy的分数是什么样的呢？我们可以来画个图检测一下：</p><p><img src="https://i.loli.net/2019/11/18/Qzlb7BVyCJT3X6F.png" alt=""></p><p>可以看到neighbors在6-7之间，accuracy是最高的，在2-5之间，test的得分竟然比训练数据都要高。</p><h2 id="使用knn的优缺点"><a href="#使用knn的优缺点" class="headerlink" title="使用knn的优缺点"></a>使用knn的优缺点</h2><ul><li>knn算法对于处理非线性数据很有用，可以用它一起处理回归问题</li><li>knn的测试阶段较慢且耗资源，需要很多的内存来保存来预测的整个数据集</li><li>强烈建议将数据进行同比例的标准化，比如将所有数据缩放到0,1的区间内</li><li>knn不适合太高维度的数据，在那种情况下，需要将维度降低</li><li>处理缺失值有助于改善模型的准确度</li></ul><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p><strong>1. knn fit其中的x,x一定只能是get_dummies算出来的数据吗？</strong></p><p>不是，比如 iris 的数据摘要，X的数据是各个部分的长、宽:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[[5.1,3.5,1.4,0.2],</span><br><span class="line">[4.9,3,1.4,0.2]]</span><br></pre></td></tr></table></figure><p><strong>2. knn fit其中的y，y可以是原始数据类型吗？如a,b,a,c</strong></p><p>可以，如 datacamp 题目中的政党数据，y=df[‘party’]:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Out[8]: </span><br><span class="line">0      republican</span><br><span class="line">1      republican</span><br><span class="line">2        democrat</span><br><span class="line">3        democrat</span><br><span class="line">4        democrat</span><br><span class="line">5        democrat</span><br><span class="line">6        democrat</span><br><span class="line">7      republican</span><br><span class="line">8      republican</span><br><span class="line">9        democrat</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;如何根据jira工单的category自动找到处理它的组呢？这是一个利用机器学习中knn算法的小实践.&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="coding" scheme="http://wittyfans.com/categories/coding/"/>
    
    
      <category term="jira" scheme="http://wittyfans.com/tags/jira/"/>
    
      <category term="data analysis" scheme="http://wittyfans.com/tags/data-analysis/"/>
    
      <category term="machine learning" scheme="http://wittyfans.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>数学复习：求和符号</title>
    <link href="http://wittyfans.com/math/%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%EF%BC%9A%E6%B1%82%E5%92%8C%E7%AC%A6%E5%8F%B7.html"/>
    <id>http://wittyfans.com/math/数学复习：求和符号.html</id>
    <published>2019-11-16T08:00:56.000Z</published>
    <updated>2019-11-16T08:09:59.554Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>简单介绍一下了求和符号的定义与运算规则.</p></blockquote><a id="more"></a><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><h1 id="求和符号"><a href="#求和符号" class="headerlink" title="求和符号"></a>求和符号</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>$$\sum$$</p><p>叫做求和符号，读作<em>sigma</em>,它的意思就是连续的加法，比如:</p><p>$$\sum_{k=1}^{n}ak=a_1+a_2+a_3+..a_n$$</p><p>k是下标，它会从k变化到n，当k=1的时候，ak就是a1，当k=2的时候，ak就是a2，最后一项就是k=n,segima的意思呢就是把这些项全都加起来。</p><p>这里再多提一点初学者容易犯的错误,请看下面的公式,其中c为常数：</p><p>$$\sum_{k=1}^{n}C=nc$$</p><p>这里的结果等于<em>n乘c</em>,而不是<em>c</em>。</p><h2 id="分拆求和符号"><a href="#分拆求和符号" class="headerlink" title="分拆求和符号"></a>分拆求和符号</h2><p><em>segima</em>可以分拆，请看下面的公式:</p><p>$$\sum_{k=1}^{n}(a_k+b_k)=\sum_{k=1}^{n}a_k+\sum_{k=1}^{n}b_k$$</p><p>我们先来分析第一部分:<br>$$\sum_{k=1}^{n}(a_k+b_k)$$</p><p>它的意思呢就是：<br>$$(a_1+b_1)+(a_2+b_2)+…+(a_n+b_n)$$</p><p>我们把 ai 与 b_i 单独拿出来排列，得到:</p><p>$$(a_1+a_2+a_3+a_i)+(b_1+b_2+b_3+b_n)$$</p><p>那么根据sigma的性质，即得到:</p><p>$$\sum_{k=1}^{n}a_k+\sum_{k=1}^{n}b_k$$</p><h2 id="常数可脱离"><a href="#常数可脱离" class="headerlink" title="常数可脱离"></a>常数可脱离</h2><p>$$\sum_{k=1}^{n}Cak=C\sum_{k=1}^{n}ak$$</p><p>首先看左边，等于:</p><p>$$Ca_1+Ca_2+Ca_n$$</p><p>那么把C提出来，则得：</p><p>$$C(a_1+a_2+a_n)$$</p><p>即：</p><p>$$C\sum_{k=1}^{n}a_k$$</p><h2 id="乘除不等"><a href="#乘除不等" class="headerlink" title="乘除不等"></a>乘除不等</h2><p>$$\sum_{k=1}^{n}(a_k*b_k)≠\sum_{k=1}^{n}(a_k)\sum_{k=1}^{n}(b_k)$$</p><p>证明很简单,让 $$n=2$$ 显然下列两项不相等：</p><p>$$(a_1b_1)+(a_2b_2)≠(a_1+a_2)(b_1+b_2)$$</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;简单介绍一下了求和符号的定义与运算规则.&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="math" scheme="http://wittyfans.com/categories/math/"/>
    
    
      <category term="data analysis" scheme="http://wittyfans.com/tags/data-analysis/"/>
    
      <category term="math" scheme="http://wittyfans.com/tags/math/"/>
    
  </entry>
  
  <entry>
    <title>数学复习：指数与对数</title>
    <link href="http://wittyfans.com/math/%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%EF%BC%9A%E6%8C%87%E6%95%B0%E5%AF%B9%E6%95%B0.html"/>
    <id>http://wittyfans.com/math/数学复习：指数对数.html</id>
    <published>2019-11-16T07:57:44.000Z</published>
    <updated>2019-11-16T08:00:43.911Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>这篇文章包括指数与对数的性质，函数图像等基本知识。</p></blockquote><a id="more"></a><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><h1 id="指数"><a href="#指数" class="headerlink" title="指数"></a>指数</h1><h2 id="指数的性质"><a href="#指数的性质" class="headerlink" title="指数的性质"></a>指数的性质</h2><p>$$a^{mn}=(a^m)^n$$<br>$$a^\frac{m}{n}=\sqrt[^n!]{(a^m)}$$<br>$$a^{m+n}=a^ma^n$$<br>$$a^{m-n}=\frac{a^m}{a^n}$$<br>$$a^{-m}=\frac{1}{a^m}$$</p><h2 id="指数函数的图像与性质"><a href="#指数函数的图像与性质" class="headerlink" title="指数函数的图像与性质"></a>指数函数的图像与性质</h2><p>$$y= a^x(a&gt;0,a≠1)$$</p><ul><li>x可取全体实数</li><li>结果y&gt;0</li><li>图像永远经过(0,1)点</li><li>a&gt;1,x变大，y也变大</li><li>0&lt;a&lt;1,x变大，y变小</li><li>第一象限内（右上），图像忘左上方向，a变大</li></ul><h2 id="指数函数举例"><a href="#指数函数举例" class="headerlink" title="指数函数举例"></a>指数函数举例</h2><p>求：</p><p>$$2^{-\frac{2}{3}}$$</p><p>得<br>$$\frac{1}{\sqrt[^3]{2^2}}$$</p><blockquote><p>提示:一个数的负次方即为这个数的正次方的倒数</p></blockquote><h1 id="对数"><a href="#对数" class="headerlink" title="对数"></a>对数</h1><p>如果:<br>$$a^b = N$$</p><p>那么<code>b叫做以a为底N的对数</code>,记为：</p><p>$$\log_a^N$$</p><h2 id="对数的性质"><a href="#对数的性质" class="headerlink" title="对数的性质"></a>对数的性质</h2><p>$$a^b=N \Longleftrightarrow b=\log_a^N$$<br>将<em>b</em>代入左边a的上面，可以推出来,<br>$$a^{log_a^N}=N$$</p><p>其实这里的意思就是<code>对n取对数再取指数</code></p><p>换底公式：</p><p>$$\log_a^b=\frac{log_c^b}{log_c^a}$$</p><p>和、差公式：</p><p>$$\log_a^{mn}=\log_a^m+\log_a^n$$<br>$$\log_a^{\frac{m}{n}}=\log_a^m-\log_a^n$$<br>幂公式，<br>$$\log_a^{(n^k)}=k\log_a^n$$<br>$$\log_{(a^k)}^n=\frac{1}{k}\log_a^n$$<br>倒数，<br>$$\log_a^b=\frac{1}{log_b^a}$$</p><h2 id="对数函数"><a href="#对数函数" class="headerlink" title="对数函数"></a>对数函数</h2><p>$$y=\log_{a}x(a&gt;0,a≠1)$$</p><ul><li>对数函数是指数函数的反函数，单调性相同</li><li>x可取全体正数</li><li>y可为所有值</li><li>永远经过(1,0)点</li><li>a&gt;1,x变大，y也变大，a&lt;1，x变大，y变小</li><li>在第一象限，图像往右下，a变大</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;这篇文章包括指数与对数的性质，函数图像等基本知识。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="math" scheme="http://wittyfans.com/categories/math/"/>
    
    
      <category term="data analysis" scheme="http://wittyfans.com/tags/data-analysis/"/>
    
      <category term="math" scheme="http://wittyfans.com/tags/math/"/>
    
  </entry>
  
  <entry>
    <title>数据可视化基础与技术</title>
    <link href="http://wittyfans.com/coding/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E5%9F%BA%E7%A1%80%E4%B8%8E%E6%8A%80%E6%9C%AF.html"/>
    <id>http://wittyfans.com/coding/数据可视化基础与技术.html</id>
    <published>2019-11-15T09:26:51.000Z</published>
    <updated>2019-11-15T14:24:41.818Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://i.loli.net/2019/11/15/kIahY4xBReDAVob.png" alt=""></p><blockquote><p>数据可视化的目的是准确而客观的讲述故事与展示数据，希望这篇文章可以对你的可视化工作有所帮助。</p></blockquote><a id="more"></a><h1 id="数据可视化基础与技术"><a href="#数据可视化基础与技术" class="headerlink" title="数据可视化基础与技术"></a>数据可视化基础与技术</h1><h1 id="名词"><a href="#名词" class="headerlink" title="名词"></a>名词</h1><ul><li>标度(scale)</li><li>坐标系(coord)</li><li>美学（aesthetic）</li><li>离散的（discrete）</li><li>将什么什么作为y轴，我们说, <em>mapping xx onto the y axis</em></li><li>我们感兴趣的关键变量，是key variable of interest</li><li>直角坐标系 Cartesian coordinate system</li><li>连续的位置标度：continuous position scales</li></ul><h1 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h1><p>aesthetic的一个关键的要素（critical component）是，元素的位置。</p><p>其次是，元素之间的颜色，字体，背景等等。</p><p>需要了解数据有两类，一类是连续型数据（continuous data），另一类是非连续型（discrete numerical values）。</p><p>比如时间间隔（time duration），是连续型的。<br>而一个房间里人员的数量则是非连续的，离散的。</p><p><strong>一般来说，位置、大小、颜色和线宽可以表示连续数据，但是形状和线型通常只能表示离散数据。</strong></p><p>数据是数字，我们称为定量。<br>数据是分类，我们称为定性。</p><p>常见的图都是三套scales,但你也可以定义更多的scale.</p><h1 id="坐标系和轴"><a href="#坐标系和轴" class="headerlink" title="坐标系和轴"></a>坐标系和轴</h1><p>坐标系和轴就不多介绍了。<br>在坐标系和轴上的数据，不仅仅是数字，也可以是任何单位，比如温度，距离。</p><h2 id="非线性轴"><a href="#非线性轴" class="headerlink" title="非线性轴"></a>非线性轴</h2><p>在轴上，均匀的间距与值的对应关系是有讲究的。特别是当你的值之间的间距是不一样而轴的标尺是一样的，或者相反的情况出现的时候。</p><p>你的轴和你的值之间的间距，必须有一个是固定的。</p><blockquote><p>When plotting log-transformed data, always specify the base in the labeling of the axis.</p></blockquote><p>如何让你的坐标是以倍数为轴来呈现？</p><h3 id="对数刻度"><a href="#对数刻度" class="headerlink" title="对数刻度"></a>对数刻度</h3><p>如果数据的最小值和最大值之间的数据很多且非常连续，那么使用对数刻度比较合适。</p><h3 id="平方根刻度"><a href="#平方根刻度" class="headerlink" title="平方根刻度"></a>平方根刻度</h3><p>对于对数刻度，如果有0怎么办？这时候可以考虑平方根刻度，它允许0的存在。在线性标度上，一个单位步长对应于一个常数值的加法或减法；在对数标度上，它对应于一个常数值的乘积或除，而平方根刻度则没有这种要求。</p><h3 id="极坐标轴"><a href="#极坐标轴" class="headerlink" title="极坐标轴"></a>极坐标轴</h3><p>极坐标类似太阳系的行星轨道。它对于一些重复的周期性数据很有用，比如一年的最后一天，也是第二年的第一天。</p><p>再比如，对于不同城市平均温度的绘制，使用极坐标的效果更好。</p><h1 id="颜色"><a href="#颜色" class="headerlink" title="颜色"></a>颜色</h1><p>颜色的用途主要是几种：</p><ul><li>区分数据组</li><li>展示数据</li><li>高亮特定的值</li></ul><h2 id="区分"><a href="#区分" class="headerlink" title="区分"></a>区分</h2><p>对于离散discrete数据或者不同组别的数据，使用颜色区分是很常见的。<br>这里有个定性色标的概念(qualitative color scale)，这些被选出来的颜色，可以比较清晰的区分彼此，并且不会让你产生颜色之间有顺序的感觉。</p><h2 id="展示"><a href="#展示" class="headerlink" title="展示"></a>展示</h2><p>颜色可以用来展示数据（主要指连续型的，比如速度，温度，收入等），这样的颜色组合我们叫做顺序色标（sequential color scale），但如果你要展示的值其中还包括负值，那就需要diverging color scale了，这种颜色的分布在中间是相对比较白或者透明的，两端则是对比明显颜色。</p><h2 id="标注"><a href="#标注" class="headerlink" title="标注"></a>标注</h2><p>对于某些carry key information的数据，我们需要将其标注出来，于是我们有了accent color scales，我们需要选择一个有表现力的颜色，同时一个不争夺我们注意力的颜色作为背景。</p><h1 id="选择合适的图"><a href="#选择合适的图" class="headerlink" title="选择合适的图"></a>选择合适的图</h1><h2 id="数量"><a href="#数量" class="headerlink" title="数量"></a>数量</h2><ul><li>bar(group,stack,vertically,horizontally)</li><li>dots</li><li>heatmap</li></ul><h2 id="分布"><a href="#分布" class="headerlink" title="分布"></a>分布</h2><ul><li>hist</li><li>density plots</li><li>cdf,累计密度图</li><li>qq plots</li><li>boxplots</li><li>violins</li><li>strip charts</li><li>sina plots</li><li>stacked hist</li><li>overlapping densities</li><li>ridgeline plot</li></ul><p>如果我们只对分布的移动趋势有兴趣，那么Boxplots, violins, strip charts, and sina plots是不错的选择。</p><p>如果你想对数据有更深层次的理解，同时你的数据集也比较小，可以使用stacked hist。</p><h2 id="比例"><a href="#比例" class="headerlink" title="比例"></a>比例</h2><ul><li>bar</li><li>pie</li><li>stacked bar</li><li>stacked densities</li><li>mosaic plot</li><li>treemap</li><li>parallel sets</li></ul><h1 id="展现数量的图"><a href="#展现数量的图" class="headerlink" title="展现数量的图"></a>展现数量的图</h1><h2 id="Bar-plots"><a href="#Bar-plots" class="headerlink" title="Bar plots"></a>Bar plots</h2><p>如果你的图竖着摆放，有时候会出现label的文字太长被遮挡的情况，这时候可以使用水平的bar图，不建议使用旋转的label。</p><p>应该根据bar的大小（即数值的大小）来排序，而不是lable的字母。</p><h2 id="dot-plots"><a href="#dot-plots" class="headerlink" title="dot plots"></a>dot plots</h2><p>bar图的长度取决于数值的大小，另外bar图的开始都是从0开始的，这意味着如果数值全部在某个大一点的区间，它们之间的对比可能会看起来比较小。</p><p>所以dot图是个更好的选择，但也要注意要根据数值来排列点，而不是label。</p><h2 id="heatmaps"><a href="#heatmaps" class="headerlink" title="heatmaps"></a>heatmaps</h2><p>使用bar图适用于那些数据组比较少的情况，你会发现如果你的数据有5，6组，整个图形已经显得有点拥挤了，如果你有超过20组数据需要展示，那么不妨选择热力图。</p><h1 id="展现分布"><a href="#展现分布" class="headerlink" title="展现分布"></a>展现分布</h1><h2 id="hist与density"><a href="#hist与density" class="headerlink" title="hist与density"></a>hist与density</h2><p>使用hist，一般程序都会给出默认的bin，但这也许不是不是合适的bin，需要你去调整与探索以找到最适合你的bin值。</p><p>直方图从18世纪开始就很流行，因为它很容易绘制，随着手机与电脑计算能力的改善，现在直方图开始被密度图所取代，密度图的曲线更平滑，同样在density图中，也有类似hist的bin参数，叫做bandwidth。</p><p>密度图的首尾需要特别注意，处理不得当，可能会出现负值。</p><p>如果有多个组的数据需要展示分布状态，不要使用stack hist，这样很不清晰，可以使用分开的density，或者是分开的hist。</p><blockquote><p>这两者都需要去选择合适的bin与bandwidth</p></blockquote><h2 id="ECDF"><a href="#ECDF" class="headerlink" title="ECDF"></a>ECDF</h2><p>在hist与densit图中，它们的局限性在于必须选择合适的bins值与带宽值，所以，bins与带宽值的选择，本身是一种主观性的行为，那么这只能说是一种对数据的解释，不是客观的（除非你选择的是公认的合适的值），所以我们还需要一种客观的对数据进行展示的方法。</p><p>将所有的数据描绘成点值，可以突出整个数据的分布，但是没办法突出具体某一个数据点的价值。</p><p>为了解决这个问题，统计学家发明了ecdf与qq图。</p><p>这些图不需要任何参数选择，可以一次性显示所有数据。</p><p>经验分布函数的思想是，x值为所有样本中排序后的值，y为所有的样本总数按均等分（根据个数），然后累加在一起的值。</p><p>这样通过观察，就可以看到所有的样本点的分布，如果某个值出现的比较多，即x往右变化时值没有变，而y则增加了一个均等分的值，此时图像上的表现就是在x处网上增加一个点，也就是斜率变得更为陡峭了。</p><h1 id="应用技巧"><a href="#应用技巧" class="headerlink" title="应用技巧"></a>应用技巧</h1><h2 id="不同的图表"><a href="#不同的图表" class="headerlink" title="不同的图表"></a>不同的图表</h2><p>you can do this:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.plt.bar()</span><br></pre></td></tr></table></figure><p>and this is the diffrent types plot:</p><ul><li>‘bar’ or ‘barh’ for bar plots</li><li>‘hist’ for histogram</li><li>‘box’ for boxplot</li><li>‘kde’ or ‘density’ for density plots</li><li>‘area’ for area plots</li><li>‘scatter’ for scatter plots</li><li>‘hexbin’ for hexagonal bin plots</li><li>‘pie’ for pie plots</li></ul><p>and you can specific the kind in methond:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot(kind=&apos;bar&apos;)</span><br></pre></td></tr></table></figure><p>Reference:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.plot.area     df.plot.barh     df.plot.density  df.plot.hist     df.plot.line     df.plot.scatter</span><br><span class="line">df.plot.bar      df.plot.box      df.plot.hexbin   df.plot.kde      df.plot.pie</span><br></pre></td></tr></table></figure><h2 id="把列合并展示"><a href="#把列合并展示" class="headerlink" title="把列合并展示"></a>把列合并展示</h2><p>When you plotting, <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">![](https://pandas.pydata.org/pandas-docs/stable/_images/bar_plot_multi_ex.png)</span><br><span class="line"></span><br><span class="line">to this:</span><br><span class="line"></span><br><span class="line">![](https://pandas.pydata.org/pandas-docs/stable/_images/bar_plot_stacked_ex.png)</span><br><span class="line"></span><br><span class="line">plot.bar(stacked=True);</span><br><span class="line"></span><br><span class="line">If you want thehorizontal bar plots, use the barh method:</span><br><span class="line"></span><br><span class="line"> ```df2.plot.barh(stacked=True)</span><br></pre></td></tr></table></figure></p><h1 id="使用绘图对象"><a href="#使用绘图对象" class="headerlink" title="使用绘图对象"></a>使用绘图对象</h1><p>Plots in matplotlib is a Figure object, you can new a plot window:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 多个图一起绘制</span><br><span class="line">and you can add the sub plots to this object,</span><br></pre></td></tr></table></figure><p>fig = plt.figure()<br>ax1 = fig.add_subplot(2, 2, 1)<br>ax2 = fig.add_subplot(2, 2, 2)<br>ax3 = fig.add_subplot(2, 2, 3)<br>ax4 = fig.add_subplot(2, 2, 4)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">This will let you get four plot sub plots in one  window, and any command will show in the last plot.</span><br><span class="line"></span><br><span class="line">## 快速创建多个子图</span><br><span class="line"></span><br><span class="line">and you create subplots fast like this:</span><br></pre></td></tr></table></figure></p><p>fig,axes = plt.subplots(3,3)<br>axes[0,0].hist(np.random.randn(100),bins=20,color=’k’,alpha=0.3)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 控制子图之间的间隙</span><br><span class="line">subplots spacing is under control by ```plt.subplots_adjust(wspace=0,hspace=0)</span><br></pre></td></tr></table></figure></p><h2 id="个性化"><a href="#个性化" class="headerlink" title="个性化"></a>个性化</h2><h3 id="线的虚实、颜色"><a href="#线的虚实、颜色" class="headerlink" title="线的虚实、颜色"></a>线的虚实、颜色</h3><p>In the plot() method, it can accept a string to stylying, to plot x verus y with green dashes , you would execute:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">of course, the color and dash can setting seperate:</span><br><span class="line"></span><br><span class="line">```ax.plot(x, y, linestyle=&apos;--&apos;, color=&apos;g&apos;)</span><br></pre></td></tr></table></figure><p>linestyle:</p><ul><li>-</li><li>--</li></ul><p>Line plots can additionally have <em>markers</em> to highlight the actual data points.</p><figure class="highlight plain"><figcaption><span>or ```plot(marker</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">### 一份数据，多种展示方式</span><br><span class="line">我们可以将不同的drawstyle结合在一起，放在同一幅图中显示，比如这样</span><br></pre></td></tr></table></figure><p>ri.groupby(ri.stop_datetime.dt.hour).drugs_related_stop.mean().plot(linestyle=’–’,color=’g’,marker=’o’,label=’Default’)<br>ri.groupby(ri.stop_datetime.dt.hour).drugs_related_stop.mean().plot(linestyle=’-‘,color=’r’,marker=’o’,label=’steps-post’,drawstyle=’steps-post’)<br>plt.legend(loc=’best’)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">![](https://xfjlcq.bn.files.1drv.com/y4mHSUL0Fe0J2icuEUtKoUHovl1jCzOHR3BSoy5LdPsDttVbG0OJYys58TNGyXOLLj0elzuvTe8dSPxanf28ZanIF5y-qdjw_BoG3hlVLh0HiLxXbQpTRX2Mdg_wqv7jHA-cWaQdKRwpT07LUWhQNNF97VE4rtUSwCGLslxsludS7d7FTp1X9_c9z1eMPE5Nj2-Z4FZYU6zSUZXSD_iLFspsw/legendPlot.png?psid=1)</span><br><span class="line"></span><br><span class="line">drawstyle的类型：</span><br><span class="line"></span><br><span class="line">```&#123;&apos;default&apos;, &apos;steps&apos;, &apos;steps-pre&apos;, &apos;steps-mid&apos;, &apos;steps-post&apos;&#125;</span><br></pre></td></tr></table></figure></p><h3 id="多份数据合并展示"><a href="#多份数据合并展示" class="headerlink" title="多份数据合并展示"></a>多份数据合并展示</h3><p>An easy way to adding legends:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from numpy.random import randn</span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(1, 1, 1)</span><br><span class="line">ax.plot(randn(1000).cumsum(), &apos;k&apos;, label=&apos;one&apos;) ax.plot(randn(1000).cumsum(), &apos;k--&apos;, label=&apos;two&apos;)</span><br><span class="line">ax.plot(randn(1000).cumsum(), &apos;k.&apos;, label=&apos;three&apos;)</span><br><span class="line">ax.legend(loc=&apos;best&apos;)</span><br></pre></td></tr></table></figure><blockquote><p>The loc tells matplotlib where to place the plot. If you aren’t picky, ‘best’ is a good option, as it will choose a location that is most out of the way. To exclude one or more elements from the legend, pass no label or label=’<em>nolegend</em>‘.</p></blockquote><h3 id="设置图的基本属性"><a href="#设置图的基本属性" class="headerlink" title="设置图的基本属性"></a>设置图的基本属性</h3><p>设置plot的标题:</p><figure class="highlight plain"><figcaption><span>Releted Stop Search Rate')```</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">设置x轴的标题：</span><br><span class="line"></span><br><span class="line">```ax.set_xlabel(&apos;hours&apos;)</span><br></pre></td></tr></table></figure><p>下面的x轴的单位和标签也可以设置，注意个数必须统一:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">drm = ri.groupby(ri.stop_datetime.dt.hour).drugs_related_stop.mean()</span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(1,1,1)</span><br><span class="line">ax.plot(drm)</span><br><span class="line"></span><br><span class="line">ticks = ax.set_xticks([0,6,12,18])</span><br><span class="line">labels = ax.set_xticklabels([&apos;Mid Night&apos;,&apos;Morning&apos;,&apos;Moon&apos;,&apos;AftenNoon&apos;])</span><br></pre></td></tr></table></figure><blockquote><p>Y-axis is same, substituting y for x in above.</p></blockquote><h3 id="如何根据GroupBy中多列的值绘制"><a href="#如何根据GroupBy中多列的值绘制" class="headerlink" title="如何根据GroupBy中多列的值绘制"></a>如何根据GroupBy中多列的值绘制</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fig,ax = plt.subplots(figsize=(16,7))</span><br><span class="line">data.groupby(&apos;A&apos;,&apos;B&apos;).count().unstack().plot(ax=ax)</span><br></pre></td></tr></table></figure><p>Use the unstack method to plotting.</p><blockquote><p>To be contiuned…</p></blockquote><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul><li><a href="https://serialmentor.com/dataviz/" target="_blank" rel="noopener">Fundamentals of Data Visualization - Claus O. Wilke</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/11/15/kIahY4xBReDAVob.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;数据可视化的目的是准确而客观的讲述故事与展示数据，希望这篇文章可以对你的可视化工作有所帮助。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="coding" scheme="http://wittyfans.com/categories/coding/"/>
    
    
      <category term="data analysis" scheme="http://wittyfans.com/tags/data-analysis/"/>
    
      <category term="data visualizing" scheme="http://wittyfans.com/tags/data-visualizing/"/>
    
      <category term="matplotlib" scheme="http://wittyfans.com/tags/matplotlib/"/>
    
  </entry>
  
  <entry>
    <title>监督学习实例：学校图书数据分类</title>
    <link href="http://wittyfans.com/coding/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E5%AE%9E%E4%BE%8B%EF%BC%9A%E5%AD%A6%E6%A0%A1%E5%9B%BE%E4%B9%A6%E6%95%B0%E6%8D%AE%E5%88%86%E7%B1%BB.html"/>
    <id>http://wittyfans.com/coding/监督学习实例：学校图书数据分类.html</id>
    <published>2019-08-17T16:02:27.000Z</published>
    <updated>2019-11-18T03:11:14.378Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><p><img src="https://i.loli.net/2019/11/18/SbPAWvxuiRELnO6.png" alt=""></p><blockquote><p>我们学校比旁边的学校在教科书上面花了更多的钱吗？这是否有用呢？</p></blockquote><a id="more"></a><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>学校想知道，我们比旁边的学校在教科书上面花了更多的钱吗？这是否有用？</p><p>要回答这个问题，首先我们需要有教科书的数据，并进行分类。然而分类是一个及其复杂的操作，学校每年都会花很多的时间去手动分类。</p><p>我们的目标是可以建立一个机器学习模型自动处理这个分类步骤。</p><p>比如《线性代数》，这本书我们会给他几个标签：</p><ul><li>数学</li><li>教科书</li><li>中学</li></ul><p>这些标签，就是我们的target variable。</p><p>这是一个典型的分类问题。</p><p>不过我们的预测应该由概率来定义，我们不会预测说，这就是本数学书，而是说,我有百分之60的把握认为这是一本数学书，如果不对，那我有百分之70的把握认为这是一本物理书。</p><h1 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h1><p>数据是csv格式的，我们使用<code>df = pd.read_csv(&#39;TrainingData.csv&#39;)</code>导入数据并保存到名为<code>df</code>的变量。</p><h2 id="探索数据"><a href="#探索数据" class="headerlink" title="探索数据"></a>探索数据</h2><p><strong>基本信息</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">In [6]: df.info()</span><br><span class="line">&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;</span><br><span class="line">RangeIndex: 1560 entries, 0 to 1559</span><br><span class="line">Data columns (total 26 columns):</span><br><span class="line">Unnamed: 0                1560 non-null int64</span><br><span class="line">Function                  1560 non-null object</span><br><span class="line">Use                       1560 non-null object</span><br><span class="line">Sharing                   1560 non-null object</span><br><span class="line">Reporting                 1560 non-null object</span><br><span class="line">Student_Type              1560 non-null object</span><br><span class="line">Position_Type             1560 non-null object</span><br><span class="line">Object_Type               1560 non-null object</span><br><span class="line">Pre_K                     1560 non-null object</span><br><span class="line">Operating_Status          1560 non-null object</span><br><span class="line">Object_Description        1461 non-null object</span><br><span class="line">Text_2                    382 non-null object</span><br><span class="line">SubFund_Description       1183 non-null object</span><br><span class="line">Job_Title_Description     1131 non-null object</span><br><span class="line">Text_3                    677 non-null object</span><br><span class="line">Text_4                    193 non-null object</span><br><span class="line">Sub_Object_Description    364 non-null object</span><br><span class="line">Location_Description      874 non-null object</span><br><span class="line">FTE                       449 non-null float64</span><br><span class="line">Function_Description      1340 non-null object</span><br><span class="line">Facility_or_Department    252 non-null object</span><br><span class="line">Position_Extra            1026 non-null object</span><br><span class="line">Total                     1542 non-null float64</span><br><span class="line">Program_Description       1192 non-null object</span><br><span class="line">Fund_Description          819 non-null object</span><br><span class="line">Text_1                    1132 non-null object</span><br><span class="line">dtypes: float64(2), int64(1), object(23)</span><br><span class="line">memory usage: 317.0+ KB</span><br></pre></td></tr></table></figure><p><strong>简单描述:</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">In [5]: df.describe()</span><br><span class="line">Out[5]:</span><br><span class="line">          Unnamed: 0         FTE         Total</span><br><span class="line">count    1560.000000  449.000000  1.542000e+03</span><br><span class="line">mean   227767.180128    0.493532  1.446867e+04</span><br><span class="line">std    130207.535688    0.452844  7.916752e+04</span><br><span class="line">min       198.000000   -0.002369 -1.044084e+06</span><br><span class="line">25%    113690.750000         NaN           NaN</span><br><span class="line">50%    226445.500000         NaN           NaN</span><br><span class="line">75%    340883.500000         NaN           NaN</span><br><span class="line">max    450277.000000    1.047222  1.367500e+06</span><br></pre></td></tr></table></figure><h2 id="FTE-全职员工数"><a href="#FTE-全职员工数" class="headerlink" title="FTE 全职员工数"></a>FTE 全职员工数</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">In [4]: df.FTE.head()</span><br><span class="line">Out[4]:</span><br><span class="line">198     NaN</span><br><span class="line">209     NaN</span><br><span class="line">750     1.0</span><br><span class="line">931     NaN</span><br><span class="line">1524    NaN</span><br><span class="line">Name: FTE, dtype: float64</span><br></pre></td></tr></table></figure><p>数据里的FTE为(Full Time equivalent)全职员工的意思,在我们的数据中，如果一项预算与一个员工有关，这个值就反应了这个员工的全职工作的百分比。</p><ul><li>1，全职员工</li><li>0，兼职或者合同制员工</li></ul><p>这个值本身是有许多的数据缺失的，所以如果要使用的话，需要先将na值去掉。</p><p>将FTE绘图，可以看到，这所学校的兼职员工和全职员工的支出很高，而中间的数据则比较少。</p><p><img src="https://i.loli.net/2019/11/15/2cYvGT3VPQhU5dE.png" alt=""></p><h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><p>我们的数据中，有些列只有特定的值，比如:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df.label.unique()</span><br><span class="line"></span><br><span class="line">[&apos;a&apos;,&apos;b&apos;]</span><br></pre></td></tr></table></figure><p>我们需要将其变成数字来处理，一是我们的模型只能计算数字，而是可以提升速度。</p><p>在pandas中，有一种 <code>category</code> 类型的数据，可以干这件事。</p><p>通过pandas的 <code>astype()</code>方法，可以将一列数据转化成 <code>category</code>，转化后，就可以使用 <code>get_dummies方法</code>来查看 dummy variables,这会让原来的每个值都用数字来替代,如：</p><p><em>原始数据：</em></p><table><thead><tr><th style="text-align:left"></th><th style="text-align:left">origin</th></tr></thead><tbody><tr><td style="text-align:left">0</td><td style="text-align:left">US</td></tr><tr><td style="text-align:left">1</td><td style="text-align:left">Europe</td></tr><tr><td style="text-align:left">2</td><td style="text-align:left">Asia</td></tr></tbody></table><p><em>get_dummies()后：</em></p><table><thead><tr><th style="text-align:left">origin_Asia</th><th style="text-align:left">origin_Europe</th><th style="text-align:left">origin_US</th></tr></thead><tbody><tr><td style="text-align:left">0</td><td style="text-align:left">0</td><td style="text-align:left">1</td></tr><tr><td style="text-align:left">0</td><td style="text-align:left">1</td><td style="text-align:left">0</td></tr><tr><td style="text-align:left">1</td><td style="text-align:left">0</td><td style="text-align:left">0</td></tr></tbody></table><p>这个步骤又叫做 <code>binary indicator</code> representation.</p><p>如果你有多列数据需要转化成 <code>category</code>类型，可以使用 lambda 函数加dataframe的apply方法，记得设置axis=0，也就是处理方式是按列，处理完成之后，你可以使用<code>df.dtypes.value_counts()</code>来查看你的数据里数据类型的分布情况。</p><h1 id="如何定义成功？"><a href="#如何定义成功？" class="headerlink" title="如何定义成功？"></a>如何定义成功？</h1><p>用accuracy，没办法解决垃圾邮件的问题，这个我们在机器学习那一章已经讲过，所以我们使用<code>log loss</code>，简单来说,accuracy是尽可能的提高正确率，而<code>log loss</code>则是尽可能的降低错误率。</p><p>下面是我们使用的<code>loss function</code>的定义：</p><p>$$logloss=-\frac{1}{N}\sum_{i=1}^{N}(y_ilogs(p_i))+(1-y_i)log(1-p_i)$$</p><ul><li>y：是否分类正确，1=yes,0=no</li><li>p：为1的概率</li></ul><p>复习一下， </p><p>$$\sum$$ </p><p>叫做求和符号，读作<em>segema</em>,它的意思就是连续的加法，比如:</p><p>$$\sum_{k=1}^{n}ak=a_1+a_2+a_3+..a_n$$</p><p>k是下标，它会从k变化到n，当k=1的时候，ak就是a1，当k=2的时候，ak就是a2，最后一项就是k=n,segima的意思呢就是把这些项全都加起来。</p><p>所以这里的segema的意思就是把数据中，每一行的数据都加起来，如果你不了解求和符号，可以参考我的这篇<a href="http://wittyfans.com/math/%E6%95%B0%E5%AD%A6%E5%A4%8D%E4%B9%A0%EF%BC%9A%E6%B1%82%E5%92%8C%E7%AC%A6%E5%8F%B7.html">文章</a></p><p>把一行的数据乘以 $$-\frac{1}{N}$$，得到这一行的logloss.</p><h2 id="log-loss函数示例"><a href="#log-loss函数示例" class="headerlink" title="log loss函数示例"></a>log loss函数示例</h2><h3 id="假设A"><a href="#假设A" class="headerlink" title="假设A"></a>假设A</h3><ul><li>true label=0</li><li>预测1的概率是p=0.9：</li></ul><p>带入公式计算可得：</p><p>$$log loss=(1-y)\log^{1-p}$$</p><p>$$=\log^{1-0.9}$$</p><p>$$=\log^{0.1}$$</p><p>$$=2.3$$</p><h3 id="假设B"><a href="#假设B" class="headerlink" title="假设B"></a>假设B</h3><ul><li>true label=1</li><li>预测0的概率是0.5</li></ul><p>则los函数表示为：</p><p>$$logloss=-\frac{1}{1}1\log^{0.5}+(1-1)\log^{1-0.5}$$</p><p>带入公式计算可得：</p><p>$$=-\log^{0.5}$$</p><p>$$=0.69$$</p><h3 id="log-loss-python实现"><a href="#log-loss-python实现" class="headerlink" title="log loss python实现"></a>log loss python实现</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">def compute_log_loss(predicted, actual, eps=1e-14):</span><br><span class="line"> &quot;&quot;&quot; Computes the logarithmic loss between predicted and</span><br><span class="line"> actual when these are 1D arrays.</span><br><span class="line"></span><br><span class="line"> :param predicted: The predicted probabilities as floats between 0-1</span><br><span class="line"> :param actual: The actual binary labels. Either 0 or 1.</span><br><span class="line"> :param eps (optional): log(0) is inf, so we need to offset our</span><br><span class="line"> predicted values slightly by eps from 0 or 1.</span><br><span class="line"> &quot;&quot;&quot;</span><br><span class="line"> predicted = np.clip(predicted, eps, 1 - eps)</span><br><span class="line"> loss = -1 * np.mean(actual * np.log(predicted)</span><br><span class="line"> + (1 - actual)</span><br><span class="line"> * np.log(1 - predicted))</span><br><span class="line"></span><br><span class="line"> return loss</span><br></pre></td></tr></table></figure><p>我们可以用这个函数取计算一些提供好的值的log loss值，下面是算好后的结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Log loss, correct and confident: 0.05129329438755058</span><br><span class="line">Log loss, correct and not confident: 0.4307829160924542</span><br><span class="line">Log loss, wrong and not confident: 1.049822124498678</span><br><span class="line">Log loss, wrong and confident: 2.9957322735539904</span><br><span class="line">Log loss, actual labels: 9.99200722162646e-15</span><br></pre></td></tr></table></figure><p>可以看到，模型的预测越准确，则logloss值越低，真实值的logloss是极低的。</p><h1 id="建立模型"><a href="#建立模型" class="headerlink" title="建立模型"></a>建立模型</h1><p>我们建模往往都是一开始建立简单的模型，然后再慢慢的优化。</p><p>所以快速的建立模型，很有必要，我们从 <em>mutil-class logistic regression</em> 开始，简单的模型我们就只选择数字类型的了，其他的列都不要，然后将列分开建模，然后把整个数据按行拿进来预测，观察在这一列是否有出现。</p><p>但还有一个问题，在之前的课程中，我们将数据分割成train组与test组，但这个方案在这里是不行的，而且那中情况只适合单个 target 的情况。</p><p>这里我们会使用另外一个函数来分割数据，叫做 <em>mutil_label_train_test_split</em></p><p>随后我们找出所有数字类型的features作为trains set, 把我们感兴趣的 lebels 也拿出来（以get_dummies的形式），就可以利用这两组数据生成train与test数据了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># Create the new DataFrame: numeric_data_only</span><br><span class="line">numeric_data_only = df[NUMERIC_COLUMNS].fillna(-1000)</span><br><span class="line"></span><br><span class="line"># Get labels and convert to dummy variables: label_dummies</span><br><span class="line">label_dummies = pd.get_dummies(df[LABELS])</span><br><span class="line"></span><br><span class="line"># Create training and test sets</span><br><span class="line">X_train, X_test, y_train, y_test = multilabel_train_test_split(numeric_data_only,label_dummies,size=0.2,seed=123)</span><br><span class="line"></span><br><span class="line"># Print the info</span><br><span class="line">print(&quot;X_train info:&quot;)</span><br><span class="line">print(X_train.info())</span><br><span class="line">print(&quot;\nX_test info:&quot;)  </span><br><span class="line">print(X_test.info())</span><br><span class="line">print(&quot;\ny_train info:&quot;)  </span><br><span class="line">print(y_train.info())</span><br><span class="line">print(&quot;\ny_test info:&quot;)  </span><br><span class="line">print(y_test.info())</span><br></pre></td></tr></table></figure><p>有了traning数据之后，就可以训练模型并计算我们的模型得分了，这里为了将我们的列分开计算，我们需要使用 <em>‌OneVsRestClassifier</em> 包，用法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># Import classifiers</span><br><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line">from sklearn.multiclass import OneVsRestClassifier</span><br><span class="line"></span><br><span class="line"># Create the DataFrame: numeric_data_only</span><br><span class="line">numeric_data_only = df[NUMERIC_COLUMNS].fillna(-1000)</span><br><span class="line"></span><br><span class="line"># Get labels and convert to dummy variables: label_dummies</span><br><span class="line">label_dummies = pd.get_dummies(df[LABELS])</span><br><span class="line"></span><br><span class="line"># Create training and test sets</span><br><span class="line">X_train, X_test, y_train, y_test = multilabel_train_test_split(numeric_data_only,label_dummies,size=0.2, seed=123)</span><br><span class="line"></span><br><span class="line"># Instantiate the classifier: clf</span><br><span class="line">clf = OneVsRestClassifier(LogisticRegression())</span><br><span class="line"></span><br><span class="line"># Fit the classifier to the training data</span><br><span class="line">clf.fit(X_train,y_train)</span><br><span class="line"></span><br><span class="line"># Print the accuracy</span><br><span class="line">print(&quot;Accuracy: &#123;&#125;&quot;.format(clf.score(X_test,y_test)))</span><br></pre></td></tr></table></figure><h2 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h2><p>这一次我们利用真实的数据来预测，这些数据是模型从未见过的，我们通过pd.read_csv导入它</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># Instantiate the classifier: clf</span><br><span class="line">clf = OneVsRestClassifier(LogisticRegression())</span><br><span class="line"></span><br><span class="line"># Fit it to the training data</span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"># Load the holdout data: holdout</span><br><span class="line">holdout = pd.read_csv(&quot;HoldoutData.csv&quot;,index_col=0)</span><br><span class="line"></span><br><span class="line"># Generate predictions: predictions</span><br><span class="line">predictions = clf.predict_proba(holdout[NUMERIC_COLUMNS].fillna(-1000))</span><br></pre></td></tr></table></figure><h2 id="自然语言处理简要概述（NLP）"><a href="#自然语言处理简要概述（NLP）" class="headerlink" title="自然语言处理简要概述（NLP）"></a>自然语言处理简要概述（NLP）</h2><h3 id="Tokenizing-与-gram"><a href="#Tokenizing-与-gram" class="headerlink" title="Tokenizing 与 gram"></a>Tokenizing 与 gram</h3><p>Tokenizing即将文本变成词语，简单的直接按照空格或者是标点符号分割，复杂一点会有自此识别，如结巴分词中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">我来到北京清华大学</span><br></pre></td></tr></table></figure><p>变成：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">我/ 来到/ 北京/ 清华/ 清华大学/ 华大/ 大学</span><br></pre></td></tr></table></figure><p>在上面的例子中，gram的选择会有不一样的效果,如果gram=1，则结果变成:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">我/ 来/到/ 北/京/ 清/华/ 大/学</span><br></pre></td></tr></table></figure><p>如果gram=2,则：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">我来/到北/京清/华大/学</span><br></pre></td></tr></table></figure></p><h2 id="文本到数字"><a href="#文本到数字" class="headerlink" title="文本到数字"></a>文本到数字</h2><p>上面的语句变成词语组，这些词语就叫做 <code>bag of words</code></p><p>在 sklearn中，有一个方法可以计算bag of words，<em>CountVectorizer</em>。</p><p>使用之前，你需要给CountVectorizer传入一个正则表达式，它才知道如何去分割字词，对了，不要忘记处理你数据中的missing value.</p><p>当你用正则创建好CountVectorizer后，就可以把语句传进来计算bag of words,一样它也是使用fit方法。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># Import CountVectorizer</span><br><span class="line">from sklearn.feature_extraction.text import CountVectorizer</span><br><span class="line"></span><br><span class="line"># Create the token pattern: TOKENS_ALPHANUMERIC</span><br><span class="line">TOKENS_ALPHANUMERIC = &apos;[A-Za-z0-9]+(?=\\s+)&apos;</span><br><span class="line"></span><br><span class="line"># Fill missing values in df.Position_Extra</span><br><span class="line">df.Position_Extra.fillna(&apos;&apos;,inplace=True)</span><br><span class="line"></span><br><span class="line"># Instantiate the CountVectorizer: vec_alphanumeric</span><br><span class="line">vec_alphanumeric = CountVectorizer(token_pattern=&apos;[A-Za-z0-9]+(?=\s+)&apos;)</span><br><span class="line"></span><br><span class="line"># Fit to the data</span><br><span class="line">vec_alphanumeric.fit(df.Position_Extra)</span><br><span class="line"></span><br><span class="line"># Print the number of tokens and first 15 tokens</span><br><span class="line">msg = &quot;There are &#123;&#125; tokens in Position_Extra if we split on non-alpha numeric&quot;</span><br><span class="line">print(msg.format(len(vec_alphanumeric.get_feature_names())))</span><br><span class="line">print(vec_alphanumeric.get_feature_names()[:15])</span><br></pre></td></tr></table></figure><h1 id="改善您的模型"><a href="#改善您的模型" class="headerlink" title="改善您的模型"></a>改善您的模型</h1><h2 id="Pipelines-feature-amp-text-preprocessing"><a href="#Pipelines-feature-amp-text-preprocessing" class="headerlink" title="Pipelines, feature &amp; text preprocessing"></a>Pipelines, feature &amp; text preprocessing</h2><p>我们已经接触过pipline了，它可以让我们处理数据的步骤变得更容易。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># Import Pipeline</span><br><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line"># Import other necessary modules</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line">from sklearn.multiclass import OneVsRestClassifier</span><br><span class="line"></span><br><span class="line"># Split and select numeric data only, no nans</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(sample_df[[&apos;numeric&apos;]],pd.get_dummies(sample_df[&apos;label&apos;]),random_state=22)</span><br><span class="line"></span><br><span class="line"># Instantiate Pipeline object: pl</span><br><span class="line">pl = Pipeline([</span><br><span class="line">    (&apos;clf&apos;, OneVsRestClassifier(LogisticRegression()))</span><br><span class="line">])</span><br><span class="line"># Fit the pipeline to the training data</span><br><span class="line">pl.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"># Compute and print accuracyaccuracy = pl.score(X_test, y_test)</span><br><span class="line">print(&quot;\nAccuracy on sample data - numeric, no nans: &quot;, accuracy)</span><br></pre></td></tr></table></figure><p>对于pipline，它是按照顺序来执行里面的步骤的，所以您需要规划好顺序，例如对于你的数据，如果有缺失值，你必须在训练模型之前就将这些na值处理好:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pl = Pipeline([</span><br><span class="line">        (&apos;imp&apos;, Imputer()),</span><br><span class="line">        (&apos;clf&apos;, OneVsRestClassifier(LogisticRegression()))</span><br><span class="line">    ])</span><br></pre></td></tr></table></figure><p>这里使用了inputer来处理缺失值。</p><p>pipline对象的使用一样也是调用fit方法，并且pipline对象还提供了打分的功能(默认是accuracy)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Fit the pipeline to the training data</span><br><span class="line">pl.fit(X_train,y_train)</span><br><span class="line"></span><br><span class="line"># Compute and print accuracy</span><br><span class="line">accuracy = pl.score(X_test,y_test)</span><br></pre></td></tr></table></figure><h2 id="Text-features-and-feature-unions"><a href="#Text-features-and-feature-unions" class="headerlink" title="Text features and feature unions"></a>Text features and feature unions</h2><p>对于我们的text值，不可以把它和数值型的数据一起处理，即不可以放在同一个pipline中。</p><p>怎么办呢？解决方案是使用Function Transformer()和FeatureUnion()</p><p>Function Transformer()做的事情很简单，就是接受一个python函数，把它转化成sklearn可以理解的对象，然后用它去处理数据。</p><p>我们可以写两个函数，都接受所有的dataframe，但是一个输出text的处理结果，另一个输出数值型数据的结果。</p><p>这样我们就可以对数值型数据与text型数据分别设置两套pipline。</p><p>在 Function Transformer() 参数重，我们将参数 validate设置为false，以让其不检查空值。</p><p>FeatureUnion是另一个我们需要用到的包，当我们用function transformer的时候，一个是数值型数据，另一个是文本型数据，FeatureUnion可以把这两个features联合到一起作为同一个数组，作为classifier的输入。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"># Import FeatureUnion</span><br><span class="line">from sklearn.pipeline import FeatureUnion</span><br><span class="line"></span><br><span class="line"># Split using ALL data in sample_df</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(sample_df[[&apos;numeric&apos;, &apos;with_missing&apos;, &apos;text&apos;]],pd.get_dummies(sample_df[&apos;label&apos;]), random_state=22)</span><br><span class="line"></span><br><span class="line"># Create a FeatureUnion with nested pipeline: process_and_join_features</span><br><span class="line">process_and_join_features = FeatureUnion(</span><br><span class="line">            transformer_list = [</span><br><span class="line">                (&apos;numeric_features&apos;, Pipeline([</span><br><span class="line">                    (&apos;selector&apos;, get_numeric_data),</span><br><span class="line">                    (&apos;imputer&apos;, Imputer())</span><br><span class="line">                ])),</span><br><span class="line">                (&apos;text_features&apos;, Pipeline([</span><br><span class="line">                    (&apos;selector&apos;, get_text_data),</span><br><span class="line">                    (&apos;vectorizer&apos;, CountVectorizer())</span><br><span class="line">                ]))</span><br><span class="line">             ]</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"># Instantiate nested pipeline: pl</span><br><span class="line">pl = Pipeline([</span><br><span class="line">        (&apos;union&apos;, process_and_join_features),</span><br><span class="line">        (&apos;clf&apos;, OneVsRestClassifier(LogisticRegression()))</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Fit pl to the training data</span><br><span class="line">pl.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"># Compute and print accuracy</span><br><span class="line">accuracy = pl.score(X_test, y_test)</span><br><span class="line">print(&quot;\nAccuracy on sample data - all data: &quot;, accuracy)</span><br></pre></td></tr></table></figure><h2 id="回归学校数据"><a href="#回归学校数据" class="headerlink" title="回归学校数据"></a>回归学校数据</h2><p>对于之前的问题，我们的数据中只有一列是文本型数据，而学校数据中，则有14列。</p><p>我们需要将这些列都结合起来，这个函数已经写好了，叫做 <code>combine_text_columns</code>, 定义好之后，只需要在定义Function Transformer()的时候更改一下参数就好了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># Import FunctionTransformer</span><br><span class="line">from sklearn.preprocessing import FunctionTransformer</span><br><span class="line"></span><br><span class="line"># Get the dummy encoding of the labels</span><br><span class="line">dummy_labels = pd.get_dummies(df[LABELS])</span><br><span class="line"></span><br><span class="line"># Get the columns that are features in the original df</span><br><span class="line">NON_LABELS = [c for c in df.columns if c not in LABELS]</span><br><span class="line"></span><br><span class="line"># Split into training and test sets</span><br><span class="line">X_train, X_test, y_train, y_test = multilabel_train_test_split(df[NON_LABELS],dummy_labels,0.2, seed=123)</span><br><span class="line"></span><br><span class="line"># Preprocess the text data: get_text_data</span><br><span class="line">get_text_data = FunctionTransformer(combine_text_columns,validate=False)</span><br><span class="line"></span><br><span class="line"># Preprocess the numeric data: get_numeric_data</span><br><span class="line">get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS], validate=False)</span><br></pre></td></tr></table></figure><p>定义好处理文本和数字的函数之后，我们就可以建立模型了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># Complete the pipeline: pl</span><br><span class="line">pl = Pipeline([</span><br><span class="line">        (&apos;union&apos;, FeatureUnion(</span><br><span class="line">            transformer_list = [</span><br><span class="line">                (&apos;numeric_features&apos;, Pipeline([</span><br><span class="line">                    (&apos;selector&apos;, get_numeric_data),</span><br><span class="line">                    (&apos;imputer&apos;, Imputer())</span><br><span class="line">                ])),</span><br><span class="line">                (&apos;text_features&apos;, Pipeline([</span><br><span class="line">                    (&apos;selector&apos;, get_text_data),</span><br><span class="line">                    (&apos;vectorizer&apos;, CountVectorizer())</span><br><span class="line">                ]))</span><br><span class="line">             ]</span><br><span class="line">        )),</span><br><span class="line">        (&apos;clf&apos;, OneVsRestClassifier(LogisticRegression()))</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line"># Fit to the training data</span><br><span class="line">pl.fit(X_train,y_train)</span><br><span class="line"></span><br><span class="line"># Compute and print accuracy</span><br><span class="line">accuracy = pl.score(X_test, y_test)</span><br><span class="line">print(&quot;\nAccuracy on budget dataset: &quot;, accuracy)</span><br></pre></td></tr></table></figure><p>可以看到pipline输出的分数。这个处理的步骤是不是很熟悉，这个步骤是通用的，而且如果你想要更换别的分类器，只需要将 <code>LogisticRegression</code> 改成别的就好了，例如在这个例子里，你把模型改成<em>RandomForestClassifier</em>，将会有0.2的提升，如果把<em>RandomForestClassifier</em>的参数<em>n_estimators</em>改成15，<em>accuracy</em> 还有有所增加。</p><h1 id="专家指点"><a href="#专家指点" class="headerlink" title="专家指点"></a>专家指点</h1><ul><li>tokenize text，不仅仅只是根据空格与标点来处理文字</li><li>n-gram statistics，文字的选择我们定义gram，我们也可以同时定义多个gram，如,<code>CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC,ngram_range=(1,2)))</code></li><li>使用预知的alpha-numeric sequences,对于text，只接受字母数字序列</li></ul><h2 id="统计技巧-interaction-terms"><a href="#统计技巧-interaction-terms" class="headerlink" title="统计技巧,interaction terms"></a>统计技巧,interaction terms</h2><p>来看一组例子,这两组数据中，English teacher和2nd grade 都有出现</p><ul><li><em>English teacher for 2nd grade</em></li><li><em>2nd grade - budget for English teacher</em></li></ul><p>$$\beta_1x_1+\beta_2x_2+\beta_3(x_1x_2)$$</p><table><thead><tr><th style="text-align:left">x_1</th><th style="text-align:left">x_2</th><th style="text-align:left">x3</th></tr></thead><tbody><tr><td style="text-align:left">0</td><td style="text-align:left">1</td><td style="text-align:left">x1*x2=0*1=0</td></tr><tr><td style="text-align:left">1</td><td style="text-align:left">1</td><td style="text-align:left">x1*x2=1*1=1</td></tr></tbody></table><ul><li>x1,x2代表某个特定的token有出现</li><li>beta符号则代表其重要程度或者说相关系数</li><li>x3是x1、x2两者的乘积</li></ul><p>当然，sklearn提供了一种非常直接的方式使用interaction terms，即：<em>PolynomialFeatures</em>,</p><p>另外还有一个叫做SparseInteractions的包，也可以做同样的事情。</p><p>最后，我们不可能因为选一个不一样的模型就改善所有的情况，模型的优化是一个渐进的步骤，可能是你将模型的某个参数调整一下，可能是你在语义处理方面更换了一个更好的工具，这些东西都需要你去根据你的实际情况作出调整。</p><p>这篇文章就到这里结束了，下一篇将会是非监督学习。</p>]]></content>
    
    <summary type="html">
    
      &lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/11/18/SbPAWvxuiRELnO6.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;我们学校比旁边的学校在教科书上面花了更多的钱吗？这是否有用呢？&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="coding" scheme="http://wittyfans.com/categories/coding/"/>
    
    
      <category term="data analysis" scheme="http://wittyfans.com/tags/data-analysis/"/>
    
      <category term="data science" scheme="http://wittyfans.com/tags/data-science/"/>
    
  </entry>
  
  <entry>
    <title>scikit-learn与监督学习</title>
    <link href="http://wittyfans.com/coding/scikit-learn%E4%B8%8E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0.html"/>
    <id>http://wittyfans.com/coding/scikit-learn与监督学习.html</id>
    <published>2019-07-26T09:38:14.000Z</published>
    <updated>2019-11-15T14:18:26.118Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://i.loli.net/2019/11/15/AFHezumhwD5grWB.png" alt=""></p><blockquote><p>给机器学习的能力，让它可以根据<strong>数据</strong>自己做决定的一种技术。</p></blockquote><a id="more"></a><h1 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h1><h2 id="监督学习与非监督学习"><a href="#监督学习与非监督学习" class="headerlink" title="监督学习与非监督学习"></a>监督学习与非监督学习</h2><p>什么是机器学习？它是给机器学习的能力，让它可以根据<strong>数据</strong>自己做决定的一种技术。</p><p>如，电子邮件是否是垃圾邮件，根据数据自动分类。</p><p>如果您使用的<strong>数据</strong>，是labled的，这就叫监督学习，如果是不unlabeled，则是非监督学习。</p><p>非监督学习的例子，如企业根据用户的数据，对用户进行分类(clustering).</p><blockquote><p>clustering，非监督学习的一个分支。</p></blockquote><h2 id="Reinforcement-learning"><a href="#Reinforcement-learning" class="headerlink" title="Reinforcement learning"></a>Reinforcement learning</h2><p>这是一种对系统进行奖赏与惩罚的训练技术，让机器可以根据环境的变化作出反应,典型的应用如阿法狗。</p><p>我们将首先focus在监督学习这部分。</p><p>我们将根据数据来训练，这些数据叫做 <code>prodictor varibles</code> 或者 <code>features</code>,<code>indenpendent varibles</code>，训练的目的是要做出预测，要预测的值叫做 <code>target varibles</code>,<code>denpendent varibles</code>或<code>response varible</code>, 如果预测的值是一组分类信息，如花的品种，人的性格，这种预测叫做<code>classfication</code>,如果是一些连续的值，如股票的价格，那就叫做<code>regression</code>.</p><p>现在我们先学习 <code>classfication</code>.</p><p>对于监督学习，首先需要数据，那么数据从哪里来？</p><ul><li>历史的数据，已经做好了分类</li><li>通过自己的试验获取，如A/B Test</li></ul><p>机器学习的工具有很多，我们主要是用 <code>scikit-learn</code>或者说<code>sklearn</code>.</p><p>其他的工具包括:</p><ul><li>TensorFlow</li><li>keras</li></ul><h1 id="探索数据"><a href="#探索数据" class="headerlink" title="探索数据"></a>探索数据</h1><h2 id="示例数据"><a href="#示例数据" class="headerlink" title="示例数据"></a>示例数据</h2><p>主要是用花瓣的数据，其中包括:</p><ul><li>petal lengh, 花瓣长度</li><li>petal width，花瓣宽度</li><li>sepal length，萼片 <code>èpiàn</code> 长度</li><li>sepal width，萼片 <code>èpiàn</code> 宽度</li></ul><blockquote><p>萼片，即花瓣下面，包住花的那部分。</p></blockquote><p>关于花，有不同的品种，在英文中叫做<code>species</code>，我们的数据中有三种，Iris Setosa（山鸢尾）、Iris Versicolour（杂色鸢尾），以及Iris Virginica（维吉尼亚鸢尾）。</p><p>数据怎么导入呢？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import datasets</span><br><span class="line">iris = datases.load_iris()</span><br></pre></td></tr></table></figure><p>这是bunch类型的数据，跟python内置的dict数据差不多。</p><blockquote><p>对于数据，记住,sample in rows, features are columns.</p></blockquote><h2 id="实例数据"><a href="#实例数据" class="headerlink" title="实例数据"></a>实例数据</h2><p>美国众议员议员数据,US House of Representatives Congressmen.</p><p>我们去预测它们的政党隶属关系(party affiliation),即：</p><ul><li>‘Democrat’,民主党</li><li>‘Republican’，共和党</li></ul><p>根据什么来预测呢？根据它们对特定问题的投票。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[&apos;party&apos;, &apos;infants&apos;, &apos;water&apos;, &apos;budget&apos;,</span><br><span class="line">&apos;physician&apos;, &apos;salvador&apos;,&apos;religious&apos;,</span><br><span class="line">&apos;satellite&apos;, &apos;aid&apos;, &apos;missile&apos;, &apos;immigration&apos;,</span><br><span class="line">&apos;synfuels&apos;,&apos;education&apos;, &apos;superfund&apos;,</span><br><span class="line">&apos;crime&apos;, &apos;duty_free_exports&apos;, &apos;eaa_rsa&apos;]</span><br></pre></td></tr></table></figure><p>上面是数据集的列名，即一些议题的投票情况。</p><p>我们使用countplot图来探索这些数据，</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.figure()</span><br><span class="line">sns.countplot(x=&apos;education&apos;, hue=&apos;party&apos;, data=df, palette=&apos;RdBu&apos;)</span><br><span class="line">plt.xticks([0,1], [&apos;No&apos;, &apos;Yes&apos;])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h1 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h1><p>我们手头有labled的数据，但我们还需要对那些没有标记的数据进行标记，我们需要对标记过数据学习，然后建立一个标记器。</p><p>标记过的数据叫做traning data.</p><h3 id="标记数据-KNN算法"><a href="#标记数据-KNN算法" class="headerlink" title="标记数据-KNN算法"></a>标记数据-KNN算法</h3><p>我们用knn算法来实现这个步骤，knn是根据数据的邻居来预测的一种算法，比如放眼望全世界，如果您的位置在中国，那么我可以预测您有很大的几率是中国人，因为您和很多的中国人在一起，对于knn算法，我们首先需要根据knn算法建立模型并训练，训练模型我们叫fiting modal，在sklearn中，我们使用<code>fit()</code>方法，而<code>predit()</code>用来预测。</p><p>如:<code>knn.fit(iris[&#39;data],iris[&#39;target&#39;])</code></p><p>使用knn fit方法的条件:</p><ol><li>np或者pd类型的数据</li><li>features是连续型的数据，不是分类数据</li><li>没有缺失值</li></ol><p>fit后，knn会返回fit后的分类器（classifier）本身，然后就可以拿来使用了。</p><p>示例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># Import KNeighborsClassifier from sklearn.neighbors</span><br><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line"></span><br><span class="line"># Create arrays for the features and the response variable</span><br><span class="line">y = df[&apos;party&apos;].values</span><br><span class="line">X = df.drop(&apos;party&apos;, axis=1).values</span><br><span class="line"></span><br><span class="line"># Create a k-NN classifier with 6 neighbors</span><br><span class="line">knn = KNeighborsClassifier(n_neighbors=6)</span><br><span class="line"></span><br><span class="line"># Fit the classifier to the data</span><br><span class="line">knn.fit(X,y)</span><br></pre></td></tr></table></figure><p>neighbors设置为6，这是这个示例默认的值，您可以设置成其他的值，在这个示例中，6是最合适的。</p><h2 id="测试模型性能-Accuracy"><a href="#测试模型性能-Accuracy" class="headerlink" title="测试模型性能-Accuracy"></a>测试模型性能-Accuracy</h2><p>accuracy是测试一个模型的指标，计算方法是模型的<code>正确预测数/测试数据总数</code>，那么我们用什么数据来算accuracy呢？</p><p>我们肯定需要用从来没有给模型用过的数据来计算，也不能用那些训练过模型的数据。</p><p>所以，一般的做法是，将数据分成两组：</p><ol><li>traning set,用来训练模型</li><li>test set，用来预测，测试模型性能</li></ol><p>我们用<code>train_test_split</code> 方法来实现，这个方法的参数中，</p><ul><li>x，y就不多介绍</li><li>test_size为您要分隔的比例，一般来说traing占0.7，test占0.3</li><li><p>stratify设置为y（y包含lable），这个参数可以让您的lable（分类数据）比较均匀的分布在分隔后的数据中，不至于过于集中</p><p>  训练完成之后，可以预测，然后就可以使用<code>knn.score(x_test,y_testx)</code>查看模型的分数。</p></li></ul><p>另外对于n_neighbors，设置的值越大，则数据集之间的分界线（decision boundary）越不敏感，曲线变得更平滑，更少的波动，但太大会导致overfitting,而太小会导致underfiting。</p><h1 id="Regression"><a href="#Regression" class="headerlink" title="Regression"></a>Regression</h1><p>regression问题是连续型的值的预测，如gdp, 房价。</p><p>我们对波士顿房价的数据进行预测，x值为一个街区中的房子房间的平均数量，可以观察到，房间数越多，价格越高。</p><p>regression的预测使用的是 <code>linear_model</code>模块。</p><h2 id="线性回归基础"><a href="#线性回归基础" class="headerlink" title="线性回归基础"></a>线性回归基础</h2><p>线性回归的基础就是<code>y=a*x+b</code>类似的一次函数,y是我们需要预测的值，x是我们的features，我们做的就是去寻找最合适的a与b，确定最合适的那个函数。</p><p>这么一个函数，我们叫做loss或者cost函数，我们为这个函数找到最合适的a与b值，让它确定的这个线，跟所有图中的点的的 <strong>垂直</strong> 距离最近，这里所说的距离就叫做 <code>residual</code>。</p><p><img src="https://i.loli.net/2019/11/15/9sEMrji8LR5AXUt.png" alt="Residual"></p><p>我们可以尝试减少所有 <code>risidual</code> 相加的和，但是正负会抵消，因为点距离线的距离有正负，那么我们减少这个距离的平方的和会比较好，即将所有的点与线段的距离平方后，再相加。</p><p>使用这个函数，就叫做最小二乘法（ordinary least squares）或者说OLS.</p><p>当我们训练的模型只有一个feature的时候，我们会使用 <code>y=a*x+b</code>,当feature增加到两个，则使用<code>y=a1*x1+a2*x2+b</code>,以此类推。</p><p>所以如果有两个feature的情况，我们的任务就是确定函数中三个数的值，<code>a1,a2,b</code>.</p><h2 id="实例讲解"><a href="#实例讲解" class="headerlink" title="实例讲解"></a>实例讲解</h2><p>我们现在根据人的生育率来预测寿命，那么我们的x值就是生育率，我们会把它作为参数传给回归器，我们的生育率是有一个范围的，不可能为负数，也不可能是好几百，所以我们从收集到的真实数据中找到最小的和最大的作为生育率的范围。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># 导入相关的包</span><br><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line"></span><br><span class="line"># 创建回归器</span><br><span class="line">reg = LinearRegression()</span><br><span class="line"></span><br><span class="line"># 确定生育率的范围，并reshape为回归器需要的shape（这里的数据是给预测器预测用的）</span><br><span class="line">prediction_space = np.linspace(min(X_fertility), max(X_fertility)).reshape(-1,1)</span><br><span class="line"></span><br><span class="line"># 把收集到的数据x与y传给回归器，让它学会怎么回归</span><br><span class="line">reg.fit(X_fertility,y)</span><br><span class="line"></span><br><span class="line"># 学会回归之后，把我们确定好的生育率范围数据传给预测器</span><br><span class="line">y_pred = reg.predict(prediction_space)</span><br><span class="line"></span><br><span class="line"># 打印 R^2 ，评分</span><br><span class="line">print(reg.score(X_fertility, y))</span><br><span class="line"></span><br><span class="line"># 绘图</span><br><span class="line">plt.plot(prediction_space, y_pred, color=&apos;black&apos;, linewidth=3)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h2 id="分割数据"><a href="#分割数据" class="headerlink" title="分割数据"></a>分割数据</h2><p>我们提到过分割数据的概念，主要是使用<code>train_test_split</code>包方法。<br>分隔好数据后我们即可进行预测，预测后的数据使用回归器的score方法查看预测效果，另外这里还介绍一个对预测效果的打分工具，即<code>mean_squared_error</code>.</p><p>您可以通过 <code>from sklearn.metrics import mean_squared_error</code> 引入并使用它。</p><p>它又叫做 <em>Root Mean Squared Error (RMSE)</em>.</p><p>它使用的参数是预测的数据与真实的数据：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># y_test已c好</span><br><span class="line"></span><br><span class="line">y_pred = reg.predict(X_test)</span><br><span class="line">rmse = np.sqrt(mean_squared_error(y_test,y_pred))</span><br></pre></td></tr></table></figure><h2 id="Cross-validation"><a href="#Cross-validation" class="headerlink" title="Cross-validation"></a>Cross-validation</h2><p>RMSE的分数和您分割数据的方式是有关系的，我们需要一种科学的分割方式。<br>在test的数据中，可能会存在一种数据层面的 <em>peculiarities</em> 导致它不能代表模型对新数据的预测能力。<br>解决这个问题的技术就叫做 <em>cross-validation</em>,它将所有数据分组，并分别作为测试与训练组，这样便可以最大化训练的数据，同时也将所有的对所有的数据进行了预测。</p><p>先简单介绍下 <em>cross-validation</em> 的步骤：</p><ol><li>将数据分隔成5（或者别的）组，这里可以说组 group,也有人说fold</li><li>将第一组作为test组，剩下的4组作为training组，training完成后，预测test组的数据，计算出结果作为标准（Metric1）</li><li>将第二组作为test，重复直到最后一组(metric1,2,3,4,5)</li><li>对5组metric进行统计分析，如mean，median，置信区间等等</li></ol><blockquote><p>分割成5组，即5folds = 5-fold CV, 10 folds = 10 folds CV,组数越多，所需要的计算量就大。</p></blockquote><h2 id="Regularized-regression"><a href="#Regularized-regression" class="headerlink" title="Regularized regression"></a>Regularized regression</h2><p>回忆一下，我们对于线性回归的定义，我们找到与所有点的垂直距离最短的线,即确定这个一次函数的系数（coefficient），但如果我们让这些系数或者说参数很大，我们就会过度拟合（overfitting），所以我们需要控制这个系数（coefficient），如果coefficient变得很大，它就是不听话，那我们就对函数做出惩罚，我们知道regulation是合规的意思，这里的也就是说对regression的参数作出规范。</p><p>接下来我们会介绍一些常见的regulation。</p><h3 id="Ridge-regression-岭回归"><a href="#Ridge-regression-岭回归" class="headerlink" title="Ridge regression 岭回归"></a>Ridge regression 岭回归</h3><p>ridge regression就是一个加强版的OLS loss function，它多了一个<code>阿尔法</code>参数，当阿尔法为0的时候，ridge regression变成了普通的ols函数，当阿尔法变得很大，对overfitting的惩罚也变得更大，更敏感，这会让模型变得过于简单(underfitting).</p><p>对于ridge regression的使用，它多了个alpha参数。另外对于不同参数，我们需要将它 <em>归一化</em>，所以在初始化ridge实例的时候，需要指定 <code>normalize=true</code>.</p><h3 id="Lasso-regression-套索回归"><a href="#Lasso-regression-套索回归" class="headerlink" title="Lasso regression 套索回归"></a>Lasso regression 套索回归</h3><p>Lasson回归的特点是，它可以自己选择feature，这样就会把那些不重要features的系数降为或者说（shrink）为0.</p><p>当我们训练好模型后，我们可以通过 <code>.coef_</code> 来查看模型中各个features的权重，或者说偏好。</p><p>下面是关于 coef_ 的解释。：</p><blockquote><p><em>The coef_ contain the coefficients for the prediction of each of the targets. It is also the same as if you trained a model to predict each of the targets separately.</em></p></blockquote><p>我们可以将columns与conef_绘图，这就可以看到哪些featues对模型的影响是最大的，这在许多的bussniss与科学实验中都有很多应用。</p><p><strong>附：关于Lasso的Python实践</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># Import Lasso</span><br><span class="line">from sklearn.linear_model import Lasso</span><br><span class="line"></span><br><span class="line"># Instantiate a lasso regressor: lasso</span><br><span class="line">lasso = Lasso(alpha=0.4,normalize=True)</span><br><span class="line"></span><br><span class="line"># Fit the regressor to the data</span><br><span class="line">lasso.fit(X,y)</span><br><span class="line"></span><br><span class="line"># Compute and print the coefficients</span><br><span class="line">lasso_coef = lasso.coef_</span><br><span class="line">print(lasso_coef)</span><br><span class="line"></span><br><span class="line"># Plot the coefficients</span><br><span class="line">plt.plot(range(len(df_columns)), lasso_coef)</span><br><span class="line">plt.xticks(range(len(df_columns)), df_columns.values, rotation=60)</span><br><span class="line">plt.margins(0.02)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>Lasso非常适合选择features，但是在构建回归模型时，Ridge回归应该是您的首选。</p><p>关于阿尔法参数对ridge的影响，可以多研究研究<a href="https://campus.datacamp.com/courses/supervised-learning-with-scikit-learn/regression-2?ex=13" target="_blank" rel="noopener">这个</a>章节。</p><h1 id="调整模型"><a href="#调整模型" class="headerlink" title="调整模型"></a>调整模型</h1><p>训练好模型之后，并不能完美的预测数据，就如打磨任何一件产品，粗加工后还需要细腻的打磨。这一节将会引入一些其他的metric来衡量您建立的模型，同时也会介绍优化模型的技术，即hyperparameter tuning.</p><p>在分类的问题中，accuracy是我们评价模型的标尺，但accuracy不总是唯一衡量模型的标准。</p><p>比如在垃圾邮件的检测问题中，如果我们把所有的邮件都作为正常邮件，因为我们只有1%的垃圾邮件。我们的模型准确度高达99%！听起来还不错，但这完全是个糟糕的模型</p><p>先记住，这种正常的数据远远多于异常数据的情况，叫做 <code>class imbalance</code>.</p><h2 id="评价模型的标尺"><a href="#评价模型的标尺" class="headerlink" title="评价模型的标尺"></a>评价模型的标尺</h2><p>给定一个两个结果的分类器，如垃圾邮件问题：</p><table><thead><tr><th style="text-align:left"></th><th style="text-align:left">预测到的垃圾邮件</th><th style="text-align:left">预测到的真实邮件</th></tr></thead><tbody><tr><td style="text-align:left">实际为垃圾邮件</td><td style="text-align:left"><strong>True Positive</strong></td><td style="text-align:left">False Negative</td></tr><tr><td style="text-align:left">实际为真实邮件</td><td style="text-align:left">False Positive</td><td style="text-align:left"><strong>True Negative</strong></td></tr></tbody></table><p>上面的这个表，叫做confusion matrix</p><ul><li>左上和右下的为预测正确的情况</li><li>通常，感兴趣的组为positive，想要预测垃圾邮件，那么垃圾邮件即为positive的</li></ul><p>为什么需要confusion matrix?</p><ol><li>计算Accuracy,即：对角线（diagonal）格子数/格子总数, <code>tp+tn/(tp+tn+fp+fn)</code></li><li>计算其他的模型指标，如：<ol><li><strong>Precision</strong>，又叫positive predictive,PPV: <code>tp/(tp+fp)</code>,在垃圾邮件模型中为，<code>实际垃圾邮件数量/预测垃圾邮件数量</code>；这个指标值越高，意味着我们更少的真实邮件预测为垃圾邮件，提高precision则我们的预测更准确，它又叫做准确率，查准率</li><li><strong>Recall</strong>，<code>tp/(tp+fn)</code>,预测正确的垃圾邮件占所有实际垃圾邮件之比，提高recall即意味着尽可能多的预测所有垃圾邮件，所以它也叫做查全率或叫召回率</li><li><strong>F1score</strong>,<code>2*(precision*recall/precision+recall)</code>，Precision与recall分别对应查准问题与查全问题，然而常常二者不能同时提高，所以对于实际复杂问题处理很有偏见，于是我们引入F1-score来近似帮助我们解决实际问题。</li></ol></li></ol><p>可以直接使用confusion matrix函数来计算，它接受两个数据，一个是y_test,另一个是y_pred，即预测出来的数据。</p><p>对于 resulting matrix, 也是一样的，在所有的sklearn的预测函数中，第一个参数总是test数据，第二个一般都是预测出来的数据,另外还有一个support参数，它就是test数据中对于不同结果的响应情况，总数就是test数据的长度。</p><h2 id="Logistic-regression"><a href="#Logistic-regression" class="headerlink" title="Logistic regression"></a>Logistic regression</h2><p>不要被这个名字迷惑，logistic regression其实是用来处理分类问题的。</p><p>它返回的是概率，当预测的数据概率大于0.5，我们标记为1，如果小于0.5，则标记为0.</p><p>它有点像线性回归，会在图像上把两组数据区分开来,这个边界就叫做线性决策边界（linear decision boundary）</p><p>在使用logistic regression的时候，我们可以定义这个概率（默认是0.5）.</p><ul><li>如果定为0，那么所有进来的数据全部预测为1</li><li>如果定为1，所有进来的数据全部预测为0</li></ul><h3 id="ROC-曲线"><a href="#ROC-曲线" class="headerlink" title="ROC 曲线"></a>ROC 曲线</h3><p>根据我们之前定义的混淆矩阵，我们再来了解两个指标,方便我们引入ROC的概念：</p><table><thead><tr><th style="text-align:left"></th><th style="text-align:left">预测到的垃圾邮件</th><th style="text-align:left">预测到的真实邮件</th></tr></thead><tbody><tr><td style="text-align:left">实际为垃圾邮件</td><td style="text-align:left"><strong>True Positive</strong></td><td style="text-align:left">False Negative</td></tr><tr><td style="text-align:left">实际为真实邮件</td><td style="text-align:left">False Positive</td><td style="text-align:left"><strong>True Negative</strong></td></tr></tbody></table><p>假设我们有如下的图：</p><p><img src="https://i.loli.net/2019/11/14/a9OnfKcCSb4tw1r.png" alt="ROC曲线"></p><ul><li><p>FPR, fpr = fp/(fp+tn),FPR表示，在所有的垃圾邮件中，被预测成正常邮件的比例。它告诉我们，随机拿一个垃圾邮件，有多大概率会将其预测成正常邮件。显然我们会希望FPR越小越好。</p></li><li><p>TPR，fpr=(tp/tp+fn), TPR表示，在所有的正常邮件中，被预测为正常邮件的比例，即随机拿一个正常邮件，有多大的概率会被预测称正常邮件，我们希望这个值越大越好。</p></li></ul><p>x轴是FPR，y轴是TPR，那么点（0，0），（1，1）意味着什么呢？</p><ul><li>（0，0）即FPR=0，TPR=0，也就是FP=0，TP=0，意味着，所有的邮件，我都把它预测为垃圾邮件</li><li>（1，1）意味着，所有邮件，我都预测为正常邮件</li><li>(1,0)，即FPR=1，TPR=0，这是最糟糕的情况。所有的预测都预测错了</li><li>点(0,1)，FPR=0说明FP=0，也就是说没有一个真实邮件被看作垃圾邮件，TPR=1，即所有正常邮件都是标记成正常邮件，这是最好的情况</li></ul><p>我们知道，在二分类（0，1）的模型中，一般我们最后的输出是一个概率值，表示结果是1的概率。那么我们最后怎么决定输入的x是属于0或1呢？我们需要一个阈值，超过这个阈值则归类为1，低于这个阈值就归类为0。所以，不同的阈值会导致分类的结果不同，也就是混淆矩阵不一样了，FPR和TPR也就不一样了。所以当阈值从0开始慢慢移动到1的过程，就会形成很多对(FPR, TPR)的值，将它们画在坐标系上，就是所谓的ROC曲线了。</p><blockquote><p>引用自CSDN博主「Webbley」的<a href="https://blog.csdn.net/liweibin1994/article/details/79462554" target="_blank" rel="noopener">原创文章</a>。</p></blockquote><h3 id="建立Logistic-modal"><a href="#建立Logistic-modal" class="headerlink" title="建立Logistic modal"></a>建立Logistic modal</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># Import the necessary modules</span><br><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line">from sklearn.metrics import confusion_matrix,classification_report</span><br><span class="line"></span><br><span class="line"># Create training and test sets</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)</span><br><span class="line"></span><br><span class="line"># Create the classifier: logreg</span><br><span class="line">logreg = LogisticRegression()</span><br><span class="line"></span><br><span class="line"># Fit the classifier to the training data</span><br><span class="line">logreg.fit(X_train,y_train)</span><br><span class="line"></span><br><span class="line"># Predict the labels of the test set: y_pred</span><br><span class="line">y_pred = logreg.predict(X_test)</span><br><span class="line"></span><br><span class="line"># Compute and print the confusion matrix and classification report</span><br><span class="line">print(confusion_matrix(y_test, y_pred))</span><br><span class="line">print(classification_report(y_test, y_pred))</span><br></pre></td></tr></table></figure><h3 id="绘制ROC曲线"><a href="#绘制ROC曲线" class="headerlink" title="绘制ROC曲线"></a>绘制ROC曲线</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 引入roc的包</span><br><span class="line">from sklearn.metrics import roc_curve</span><br><span class="line"></span><br><span class="line">y_pred_prob = logreg.predict_proba(X_test)[:,1]</span><br><span class="line">fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)</span><br><span class="line"></span><br><span class="line">plt.plot([0, 1], [0, 1], &apos;k--&apos;)</span><br><span class="line">plt.plot(fpr, tpr, label=&apos;Logistic Regression&apos;)</span><br><span class="line">plt.xlabel(&apos;False Positive Rate’)</span><br><span class="line">plt.ylabel(&apos;True Positive Rate&apos;)</span><br><span class="line">plt.title(&apos;Logistic Regression ROC Curve&apos;)</span><br><span class="line">plt.show();</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/11/15/kQdZoCr5EAwiF8q.png" alt="ROC曲线下面的面积"></p><p>当我们的FPR与TRP位于（0，1）的时候，预测到的结果是最好的，观察这个ROC图像，即ROC曲线下面的面积最大的时候，所以我们可以得出:</p><blockquote><p>ROC曲线下面的面积越大，模型越好！</p></blockquote><p>这个面积就叫做AUC，同样也是一个使用广泛的分类问题评价标尺。</p><h3 id="计算AUC"><a href="#计算AUC" class="headerlink" title="计算AUC"></a>计算AUC</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># Import necessary modules</span><br><span class="line">from sklearn.metrics import roc_auc_score</span><br><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line"></span><br><span class="line"># Compute predicted probabilities: y_pred_prob</span><br><span class="line">y_pred_prob = logreg.predict_proba(X_test)[:,1]</span><br><span class="line"></span><br><span class="line"># Compute and print AUC score</span><br><span class="line">print(&quot;AUC: &#123;&#125;&quot;.format(roc_auc_score(y_test, y_pred_prob)))</span><br><span class="line"></span><br><span class="line"># Compute cross-validated AUC scores: cv_auc</span><br><span class="line">cv_auc = cross_val_score(logreg,X,y,cv=5,scoring=&apos;roc_auc&apos;)</span><br><span class="line"></span><br><span class="line"># Print list of AUC scores</span><br><span class="line">print(&quot;AUC scores computed using 5-fold cross-validation: &#123;&#125;&quot;.format(cv_auc))</span><br></pre></td></tr></table></figure><h2 id="Hyperparameter-tuning"><a href="#Hyperparameter-tuning" class="headerlink" title="Hyperparameter tuning"></a>Hyperparameter tuning</h2><ul><li>线性回归：选择参数</li><li>ridge/lasso: 选择alpha</li><li>KNN：选择neighbors</li></ul><p>上面这些选择的参数，就叫做Hyperparameter tuning。</p><p>所以一个好的模型，就在于选择一个好的参数，这个参数如何决定呢？</p><p>我们可以定义一个grid表格，将参数填进去，一个一个的试验，直到找到最好的那个。</p><p><img src="https://i.loli.net/2019/11/15/5VwtUYGKu8gH6ey.png" alt="Grid search cross-validation"></p><h3 id="GridSearchCV"><a href="#GridSearchCV" class="headerlink" title="GridSearchCV"></a>GridSearchCV</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># Import necessary modules</span><br><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line">from sklearn.model_selection import GridSearchCV</span><br><span class="line"></span><br><span class="line"># Setup the hyperparameter grid</span><br><span class="line">c_space = np.logspace(-5, 8, 15)</span><br><span class="line">param_grid = &#123;&apos;C&apos;: c_space&#125;</span><br><span class="line"></span><br><span class="line"># Instantiate a logistic regression classifier: logreg</span><br><span class="line">logreg = LogisticRegression()</span><br><span class="line"></span><br><span class="line"># Instantiate the GridSearchCV object: logreg_cv</span><br><span class="line">logreg_cv = GridSearchCV(logreg, param_grid, cv=5)</span><br><span class="line"></span><br><span class="line"># Fit it to the data</span><br><span class="line">logreg_cv.fit(X,y)</span><br><span class="line"></span><br><span class="line"># Print the tuned parameters and score</span><br><span class="line">print(&quot;Tuned Logistic Regression Parameters: &#123;&#125;&quot;.format(logreg_cv.best_params_))</span><br><span class="line">print(&quot;Best score is &#123;&#125;&quot;.format(logreg_cv.best_score_))</span><br></pre></td></tr></table></figure><h3 id="RandomizedSearchCV"><a href="#RandomizedSearchCV" class="headerlink" title="RandomizedSearchCV"></a>RandomizedSearchCV</h3><p>上面的searchCV是按照一定的规则来测试参数，而randomizedSearchCV则是随机选择数据作为测试的参数，代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># Import necessary modules</span><br><span class="line">from scipy.stats import randint</span><br><span class="line">from sklearn.tree import DecisionTreeClassifier</span><br><span class="line">from sklearn.model_selection import RandomizedSearchCV</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Setup the parameters and distributions to sample from: param_dist</span><br><span class="line">param_dist = &#123;&quot;max_depth&quot;: [3, None],</span><br><span class="line">              &quot;max_features&quot;: randint(1, 9),</span><br><span class="line">              &quot;min_samples_leaf&quot;: randint(1, 9),</span><br><span class="line">              &quot;criterion&quot;: [&quot;gini&quot;, &quot;entropy&quot;]&#125;</span><br><span class="line"></span><br><span class="line"># Instantiate a Decision Tree classifier: tree</span><br><span class="line">tree = DecisionTreeClassifier()</span><br><span class="line"></span><br><span class="line"># Instantiate the RandomizedSearchCV object: tree_cv</span><br><span class="line">tree_cv = RandomizedSearchCV(tree, param_dist, cv=5)</span><br><span class="line"></span><br><span class="line"># Fit it to the data</span><br><span class="line">tree_cv.fit(X,y)</span><br><span class="line"></span><br><span class="line"># Print the tuned parameters and score</span><br><span class="line">print(&quot;Tuned Decision Tree Parameters: &#123;&#125;&quot;.format(tree_cv.best_params_))</span><br><span class="line">print(&quot;Best score is &#123;&#125;&quot;.format(tree_cv.best_score_))</span><br></pre></td></tr></table></figure><h1 id="数据预处理与管道"><a href="#数据预处理与管道" class="headerlink" title="数据预处理与管道"></a>数据预处理与管道</h1><p>现实世界的数据是复杂的，我们目前使用的都是标记过的数据，如果是没有标记过的数据，我们就需要将其打上标记，我们可以使用pandas的get_dummies()方法或者是sklearn的OneHotEncoder()，它会完成数据之间的转换，如下所示:</p><p><em>原始数据：</em></p><table><thead><tr><th style="text-align:left"></th><th style="text-align:left">origin</th></tr></thead><tbody><tr><td style="text-align:left">0</td><td style="text-align:left">US</td></tr><tr><td style="text-align:left">1</td><td style="text-align:left">Europe</td></tr><tr><td style="text-align:left">2</td><td style="text-align:left">Asia</td></tr></tbody></table><p><em>get_dummies()后：</em></p><table><thead><tr><th style="text-align:left">origin_Asia</th><th style="text-align:left">origin_Europe</th><th style="text-align:left">origin_US</th></tr></thead><tbody><tr><td style="text-align:left">0</td><td style="text-align:left">0</td><td style="text-align:left">1</td></tr><tr><td style="text-align:left">0</td><td style="text-align:left">1</td><td style="text-align:left">0</td></tr><tr><td style="text-align:left">1</td><td style="text-align:left">0</td><td style="text-align:left">0</td></tr></tbody></table><p>对于dummies后的数据，如果我们已经有了前两列（origin_Asia,origin_Rurope）的数据，就可以推测剩下的就是US的数据了，所以可以把US这里列删掉。</p><h2 id="处理missing-data"><a href="#处理missing-data" class="headerlink" title="处理missing data"></a>处理missing data</h2><p>您收集到的数据，不会是完美的，肯定有些值是缺失的，它们可能为0，为nan，或者以其他形式记录的空值。</p><p>你可以使用np.dropna来把所有为空值的行删除，但这样很可能会让你的数据总量变少。</p><p>你也可以自动将所有的空值，以该列的平均值替代。</p><p>可以利用imputer对象来处理，如:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">imp = impImputer(missing_values=&apos;NaN&apos;,strategy=&apos;mean&apos;,axix=0)</span><br><span class="line"></span><br><span class="line">imp.fit(X)</span><br><span class="line">imp.transform(X)</span><br></pre></td></tr></table></figure><p>用imp fit X后，便可对数据进行transform，因此imputer对象也叫transformer.</p><h2 id="管道"><a href="#管道" class="headerlink" title="管道"></a>管道</h2><p>将你的操作打包成一个数组，就变成了一个pipline，你可以把你的操作（如处理missing value，大小写转换等等）都写进管道，一次性处理。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># Import necessary modules</span><br><span class="line">from sklearn.preprocessing import Imputer</span><br><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line">from sklearn.svm import SVC</span><br><span class="line"></span><br><span class="line"># Setup the pipeline steps: steps</span><br><span class="line">steps = [(&apos;imputation&apos;, Imputer(missing_values=&apos;NaN&apos;, strategy=&apos;most_frequent&apos;, axis=0)),</span><br><span class="line">        (&apos;SVM&apos;, SVC())]</span><br><span class="line"></span><br><span class="line"># Create the pipeline: pipeline</span><br><span class="line">pipeline = Pipeline(steps)</span><br><span class="line"></span><br><span class="line"># Create training and test sets</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)</span><br><span class="line"></span><br><span class="line"># Fit the pipeline to the train set</span><br><span class="line">pipeline.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"># Predict the labels of the test set</span><br><span class="line">y_pred = pipeline.predict(X_test)</span><br><span class="line"></span><br><span class="line"># Compute metrics</span><br><span class="line">print(classification_report(y_test, y_pred))</span><br></pre></td></tr></table></figure><h2 id="Centering-and-scaling"><a href="#Centering-and-scaling" class="headerlink" title="Centering and scaling"></a>Centering and scaling</h2><p>模型的featuers的数据值，它的取值范围可能是非常大的，比如年龄的区间是0-100，而体重的区间则不一样。对模型来说，我们最好将这些数据进行缩放（scaling），全部放到同一个区间中，这样它们对于模型的重要程度才比较好估计。</p><p>缩放的范围可以是0-1，也可以是-1到1.</p><p>可以查看sklearn的文档，了解更多关于scaling的细节。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/11/15/AFHezumhwD5grWB.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;给机器学习的能力，让它可以根据&lt;strong&gt;数据&lt;/strong&gt;自己做决定的一种技术。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="coding" scheme="http://wittyfans.com/categories/coding/"/>
    
    
      <category term="data analysis" scheme="http://wittyfans.com/tags/data-analysis/"/>
    
      <category term="machine learning" scheme="http://wittyfans.com/tags/machine-learning/"/>
    
      <category term="sklearn" scheme="http://wittyfans.com/tags/sklearn/"/>
    
      <category term="Python" scheme="http://wittyfans.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Numpy ndarray 基本操作</title>
    <link href="http://wittyfans.com/coding/NumPy-ndarray-%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C.html"/>
    <id>http://wittyfans.com/coding/NumPy-ndarray-基本操作.html</id>
    <published>2019-07-01T02:45:05.000Z</published>
    <updated>2019-11-15T14:36:42.035Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://i.loli.net/2019/11/15/qUBCxdZk7VmIFe1.png" alt=""></p><blockquote><p>为什么要使用Numpy？给你两组数据运算，然后对比一下性能就知道了.</p></blockquote><a id="more"></a><h1 id="Why-Numpy"><a href="#Why-Numpy" class="headerlink" title="Why Numpy?"></a>Why Numpy?</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">my_arr = np.arange(1000000)</span><br><span class="line"></span><br><span class="line">my_list = list(range(1000000))</span><br></pre></td></tr></table></figure><p>现在对两组数乘以2</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">%time for _ in range(10): my_arr2 = my_arr * 2</span><br><span class="line"></span><br><span class="line">CPU times: user 20 ms, sys: 50 ms, total: 70 ms Wall time: 72.4 ms</span><br><span class="line"></span><br><span class="line">%time for _ in range(10): my_list2 = [x * 2 for x in my_list]</span><br><span class="line"></span><br><span class="line">CPU times: user 760 ms, sys: 290 ms, total: 1.05 s</span><br></pre></td></tr></table></figure><h2 id="Numpy"><a href="#Numpy" class="headerlink" title="Numpy"></a>Numpy</h2><h3 id="生成随机数"><a href="#生成随机数" class="headerlink" title="生成随机数"></a>生成随机数</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">data = np.random.randn(2,3)</span><br></pre></td></tr></table></figure><p>数据长这样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([[-0.05094946, -1.54555805, -1.19695135],</span><br><span class="line">       [-1.06169454,  1.13763682,  0.57538678]])</span><br></pre></td></tr></table></figure><p>将它们乘10:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([[  9.41882893,   3.20674452,  18.05866858],</span><br><span class="line">       [ -7.97835594,  -9.56449228,  -0.83342424]])</span><br></pre></td></tr></table></figure><p>两份数据相加：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([[-2.37617968,  3.45388874, -0.64218591],</span><br><span class="line">       [-2.99399147, -1.11118452, -1.11992404]])</span><br></pre></td></tr></table></figure><p>对于Numpy的数据：</p><blockquote><p>An ndarray is a generic multidimensional container for homogeneous data; that is, all of the elements must be the same type. Every array has a shape, a tuple indicating the size of each dimension, and a dtype, an object describing the data type of the array:</p></blockquote><ul><li>所有的数据必须是同样的类型</li><li>每个数组都有一个元组类型的shape属性，表示这个数组的维度信息</li><li>每个数组都有一个dtype属性用来描述它其中的数据类型</li></ul><p>如上面的data：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data.shape ---&gt; (2, 3)</span><br><span class="line">data.dtype --&gt; dtype(&apos;float64&apos;)</span><br></pre></td></tr></table></figure><blockquote><p>While it’s not necessary to have a deep understanding of NumPy for many data analytical applications, becoming proficient in array-oriented programming and thinking is a key step along the way to becoming a scientific Python guru.</p></blockquote><h2 id="创建-NDarrays"><a href="#创建-NDarrays" class="headerlink" title="创建 NDarrays"></a>创建 NDarrays</h2><p>直接从数组创建：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data1 = [6,7.5,8,0,1]</span><br><span class="line">arr1 = np.array(data1)</span><br><span class="line">arr1</span><br></pre></td></tr></table></figure><p>也可以从多维数组创建：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data2 = [[1, 2, 3, 4], [5, 6, 7, 8]]</span><br><span class="line">arr2 = np.array(data2)</span><br><span class="line"></span><br><span class="line">arr2.shape --&gt; (2,4)</span><br><span class="line">arr2.dim --&gt;2</span><br></pre></td></tr></table></figure><p>可以用 <em>ndim</em> 属性来看数组的维度信息。</p><p>Numpy还有一些有趣的方法，可以直接创建0和1，或者空值：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">np.zeros(10) --&gt; 创建10个0的数组</span><br><span class="line">np.zeros((3,6))</span><br><span class="line">np.empty((2,3,2)) --&gt; 创建两个两列三行的数组</span><br></pre></td></tr></table></figure><p>还有一些创建<em>ndarrays</em>的方法：</p><ul><li>array: Convert input data (list, tuple, array, or other sequence type) to an ndarray either by inferring a dtype</li><li>asarray: Convert input to ndarray, but do not copy if the input is already an ndarray</li><li>arange: Like the built-in range but returns an ndarray instead of a list</li></ul><p>更多的方法可以参考：<em>Python for data analyse, Table 4-1</em></p><h2 id="NDarrays的数据类型"><a href="#NDarrays的数据类型" class="headerlink" title="NDarrays的数据类型"></a>NDarrays的数据类型</h2><p>ndarrays 的data type或者是dtype包含了一些基本的信息(meta),array在定义的时候是可以指定数据类型的，比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">arr1 = np.array([1,2,3],dtype=np.float64)</span><br><span class="line">arr2 = np.array([1,2,3],dtype=np.int32)</span><br></pre></td></tr></table></figure><p>数据类型可以相互转化：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">arr = np.array([1,2,3,4])</span><br><span class="line">arr.dtype</span><br><span class="line"># 输出 dtype(&apos;int64&apos;)</span><br><span class="line"></span><br><span class="line">arr = np.array([1,2,3,4])</span><br><span class="line">floatarr = arr.astype(np.float64)</span><br><span class="line">floatarr.dtype</span><br><span class="line"># 输出 dtype(&apos;float64&apos;)</span><br></pre></td></tr></table></figure><p>相反的<em>float</em>也可以转化成 <em>int</em>,十进制多出来的部分会被四舍五入。</p><h2 id="数组运算"><a href="#数组运算" class="headerlink" title="数组运算"></a>数组运算</h2><p>下面是基本的运算：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arr = np.array([[1., 2., 3.], [4., 5., 6.]])</span><br></pre></td></tr></table></figure><p>乘：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">arr*arr</span><br><span class="line"># out</span><br><span class="line">array([[  1.,   4.,   9.],</span><br><span class="line">       [ 16.,  25.,  36.]])</span><br></pre></td></tr></table></figure><p>减:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">arr-arr</span><br><span class="line"># out</span><br><span class="line">array([[ 0.,  0.,  0.],</span><br><span class="line">       [ 0.,  0.,  0.]])</span><br></pre></td></tr></table></figure><p>所有的运算都是基于相对关系的，记住这一点即可。除此之外，np还支持比较，假设两个arr对比，返回结果会是一个包含true或false的数组。</p><h2 id="切片和索引"><a href="#切片和索引" class="headerlink" title="切片和索引"></a>切片和索引</h2><p>Numpy的切片和索引和数组的差不多，切片就是按照坐标或者坐标范围来找出对应，或对应范围内的值，根据坐标来理解就很简单</p><p><img src="https://i.loli.net/2019/02/08/5c5d05c2d4a0f.jpeg" alt=""></p><p>你可以对一个切片范围内的值重新赋值：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">arr = np.arange(10)</span><br><span class="line">arr[5] --&gt; 5</span><br><span class="line">arr[5:8] --&gt; [5,6,7]</span><br><span class="line">arr[5:8] = 12</span><br><span class="line">arr --&gt; array([ 0,  1,  2,  3,  4, 12, 12, 12,  8,  9])</span><br></pre></td></tr></table></figure><p>np设计需要处理大量的数据，所以对于数组的操作，都是在原来的数据上改动，不会copy。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">arr_slice = arr[5:8]</span><br><span class="line">arr_slice</span><br><span class="line"># out: array([5, 6, 7])</span><br><span class="line"></span><br><span class="line">arr_slice[:] = 9 # [:]是应用在数组中的所有元素</span><br><span class="line">arr</span><br><span class="line"># out: array([0, 1, 2, 3, 4, 9, 9, 9, 8, 9])</span><br></pre></td></tr></table></figure><p>如果你要copy，np提供了一个copy函数:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">arr3d = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])</span><br><span class="line">copyed = arr3d.copy()</span><br><span class="line">copyed</span><br><span class="line"># out:</span><br><span class="line">array([[[ 1,  2,  3],</span><br><span class="line">        [ 4,  5,  6]],</span><br><span class="line"></span><br><span class="line">       [[ 7,  8,  9],</span><br><span class="line">        [10, 11, 12]]])</span><br></pre></td></tr></table></figure><p>可以在两个维度上切片：</p><p><em>arr2d[:]</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([[1, 2, 3],</span><br><span class="line">       [4, 5, 6],</span><br><span class="line">       [7, 8, 9]])</span><br></pre></td></tr></table></figure><p><em>arr2d[:2]</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([[1, 2, 3],</span><br><span class="line">       [4, 5, 6]])</span><br></pre></td></tr></table></figure><p><em>arr2d[:2,1:]</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([[2, 3],</span><br><span class="line">       [5, 6]])</span><br></pre></td></tr></table></figure><p><em>arr2d[:,:0]</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([[1],</span><br><span class="line">       [4],</span><br><span class="line">       [7]])</span><br></pre></td></tr></table></figure><p>参照下图，动手实践几次，就会懂其中的套路了。</p><p><img src="https://i.loli.net/2019/02/08/5c5d054478e7b.jpeg" alt=""></p><h2 id="Boolean-Indexing"><a href="#Boolean-Indexing" class="headerlink" title="Boolean Indexing"></a>Boolean Indexing</h2><p>我们有一批名字:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">names = np.array([&apos;Bob&apos;, &apos;Joe&apos;, &apos;Will&apos;, &apos;Bob&apos;, &apos;Will&apos;, &apos;Joe&apos;, &apos;Joe&apos;])</span><br></pre></td></tr></table></figure><p>我们可以直接通过 <em>names == ‘Bob’</em> 来返回一个检查结果，这个结果包含的是一个 <em>bollean</em> 的 <em>list</em>.</p><p><em>names == ‘Bob’</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([ True, False, False,  True, False, False, False], dtype=bool)</span><br></pre></td></tr></table></figure><p>如果我们有一份数据，也是7行，那么我们可以吧这个包含 <em>True</em> 和 <em>False</em> 的l <em>List</em> 传进去，这样 <em>Numpy</em> 会选出那些对应 <em>True</em> 的行。</p><p><em>data = np.random.randn(7,4)</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">array([[-0.71030181, -0.14900916, -1.15238417, -0.49395683],</span><br><span class="line">       [-0.92601472,  0.88452947, -0.9206763 , -0.43338155],</span><br><span class="line">       [-0.68093622,  0.93612942,  0.03261537,  1.44615091],</span><br><span class="line">       [ 1.40919226, -0.07214425, -0.07973205, -1.01432059],</span><br><span class="line">       [-0.4042085 ,  0.66812768,  0.4715137 ,  0.34981598],</span><br><span class="line">       [ 0.89631112, -0.70534677,  0.44560626,  0.6133761 ],</span><br><span class="line">       [-0.28979691,  0.58481489, -0.06945283, -0.99545537]])</span><br></pre></td></tr></table></figure><p><em>data[names==’Bob’]</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([[-0.71030181, -0.14900916, -1.15238417, -0.49395683],</span><br><span class="line">       [ 1.40919226, -0.07214425, -0.07973205, -1.01432059]])</span><br></pre></td></tr></table></figure><blockquote><p> Boolean selection will not fail if the boolean array is not the correct length, so I recommend care when using this feature.</p></blockquote><p>上面的选择，也可以配合切片：</p><p><em>data[names==’Bob’,:1]</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([[-0.71030181],</span><br><span class="line">       [ 1.40919226]])</span><br></pre></td></tr></table></figure><p>选择除了 <em>Bob</em> 之外的名字：</p><ul><li><em>names != ‘Bob’</em></li><li><em>~(names == ‘Bob’)</em></li></ul><p>对于 <em>names</em> 的过滤，可以用组合条件：</p><ul><li><em>cond = names == ‘Bob’</em></li><li><em>cond = (names==’Bob’) | (names == ‘will’)</em></li></ul><p>对于 <em>data</em> 也一样：</p><p><em>data[data &lt; 0] = 0</em></p><p>设置整行的值也非常简单：</p><p><em>data[names != ‘Joe’] = 7</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">array([[ 7.        ,  7.        ,  7.        ,  7.        ],</span><br><span class="line">       [-0.92601472,  0.88452947, -0.9206763 , -0.43338155],</span><br><span class="line">       [ 7.        ,  7.        ,  7.        ,  7.        ],</span><br><span class="line">       [ 7.        ,  7.        ,  7.        ,  7.        ],</span><br><span class="line">       [ 7.        ,  7.        ,  7.        ,  7.        ],</span><br><span class="line">       [ 0.89631112, -0.70534677,  0.44560626,  0.6133761 ],</span><br><span class="line">       [-0.28979691,  0.58481489, -0.06945283, -0.99545537]])</span><br></pre></td></tr></table></figure><h2 id="Fancy-Indexing"><a href="#Fancy-Indexing" class="headerlink" title="Fancy Indexing"></a>Fancy Indexing</h2><p>Fancy indexing is a term adopted by NumPy to describe indexing using integer arrays. Suppose we had an 8 × 4 array:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">arr = np.empty((8,4),dtype=np.int)</span><br><span class="line">for i in range(8):</span><br><span class="line">    arr[i] = i</span><br><span class="line">arr</span><br></pre></td></tr></table></figure><p>选择单个值：</p><p><em>arr[3,0]</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">out: 3</span><br></pre></td></tr></table></figure><p>选择多行：</p><p><em>arr[[3,0]]</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([[3, 3, 3, 3],</span><br><span class="line">       [0, 0, 0, 0]])</span><br></pre></td></tr></table></figure><p>让我们构建一个按顺序排列的 <em>8x4</em> 的数组：</p><p><em>arr = np.arange(32).reshape((8,4))</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">array([[ 0,  1,  2,  3],</span><br><span class="line">       [ 4,  5,  6,  7],</span><br><span class="line">       [ 8,  9, 10, 11],</span><br><span class="line">       [12, 13, 14, 15],</span><br><span class="line">       [16, 17, 18, 19],</span><br><span class="line">       [20, 21, 22, 23],</span><br><span class="line">       [24, 25, 26, 27],</span><br><span class="line">       [28, 29, 30, 31]])</span><br></pre></td></tr></table></figure><p>按选择前两个子数组的第一个数：</p><p><em>arr[[1,2],[0,0]]</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([4, 8])</span><br></pre></td></tr></table></figure><p>你也可以对选择出来的数组，进行排序：</p><p><em>arr[[1,2]][:]</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([[ 4,  5,  6,  7],</span><br><span class="line">       [ 8,  9, 10, 11]])</span><br></pre></td></tr></table></figure><p><em>arr[[1,2]][:,[0]]</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([[4],</span><br><span class="line">       [8]])</span><br></pre></td></tr></table></figure><p><em>arr[[1,2]][:,[0,3,2,1]]</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([[ 4,  7,  6,  5],</span><br><span class="line">       [ 8, 11, 10,  9]])</span><br></pre></td></tr></table></figure><blockquote><p>Fancy indexing always copies the data into a new array.</p></blockquote><h2 id="Transposing-Arrays-and-Swapping-Axes"><a href="#Transposing-Arrays-and-Swapping-Axes" class="headerlink" title="Transposing Arrays and Swapping Axes"></a>Transposing Arrays and Swapping Axes</h2><h3 id="Shape"><a href="#Shape" class="headerlink" title="Shape"></a>Shape</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">value = 18</span><br><span class="line">x = 2</span><br><span class="line">y = 9</span><br><span class="line">arr = np.arange(value).reshape((x,y))</span><br><span class="line">arr</span><br><span class="line"># 输出</span><br><span class="line">array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8],</span><br><span class="line">       [ 9, 10, 11, 12, 13, 14, 15, 16, 17]])</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">value = 18</span><br><span class="line">x = 3</span><br><span class="line">y = 6</span><br><span class="line">arr = np.arange(value).reshape((x,y))</span><br><span class="line"># 输出</span><br><span class="line">array([[ 0,  1,  2,  3,  4,  5],</span><br><span class="line">       [ 6,  7,  8,  9, 10, 11],</span><br><span class="line">       [12, 13, 14, 15, 16, 17]])</span><br></pre></td></tr></table></figure><p>只需要确保 Value = X <em> Y 就可以任意 </em>shape* 了。</p><h3 id="Transposing"><a href="#Transposing" class="headerlink" title="Transposing"></a>Transposing</h3><p>看例子：</p><p><em>arr = np.arange(18).reshape((3,6))</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([[ 0,  1,  2,  3,  4,  5],</span><br><span class="line">       [ 6,  7,  8,  9, 10, 11],</span><br><span class="line">       [12, 13, 14, 15, 16, 17]])</span><br></pre></td></tr></table></figure><p><em>arr.T</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">array([[ 0,  6, 12],</span><br><span class="line">       [ 1,  7, 13],</span><br><span class="line">       [ 2,  8, 14],</span><br><span class="line">       [ 3,  9, 15],</span><br><span class="line">       [ 4, 10, 16],</span><br><span class="line">       [ 5, 11, 17]])</span><br></pre></td></tr></table></figure><p><em>Transposing</em> 在矩阵计算中用的非常多，比如用 <em>np.dot</em> 方法计算矩阵的内积:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">arra = np.array([2,3,0])</span><br><span class="line">arrb = np.array([2,-1,1])</span><br><span class="line">np.dot(arra,arrb)</span><br><span class="line"># 输出 1</span><br></pre></td></tr></table></figure><blockquote><p>怎么计算内积？看下图就明白了</p></blockquote><p><img src="https://i.loli.net/2019/02/08/5c5d41ff41077.png" alt=""></p><p><img src="https://i.loli.net/2019/02/08/5c5d4246ea899.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/11/15/qUBCxdZk7VmIFe1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;为什么要使用Numpy？给你两组数据运算，然后对比一下性能就知道了.&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="coding" scheme="http://wittyfans.com/categories/coding/"/>
    
    
      <category term="python" scheme="http://wittyfans.com/tags/python/"/>
    
      <category term="data analysis" scheme="http://wittyfans.com/tags/data-analysis/"/>
    
      <category term="NumPy" scheme="http://wittyfans.com/tags/NumPy/"/>
    
  </entry>
  
  <entry>
    <title>Linux 常用命令整理(eng)</title>
    <link href="http://wittyfans.com/writing/Linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86-eng.html"/>
    <id>http://wittyfans.com/writing/Linux-常用命令整理-eng.html</id>
    <published>2019-06-07T13:56:19.000Z</published>
    <updated>2019-06-07T13:59:34.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>常用命令的cheatsheet，如果想了解更多理论部分，请参考之前的文章<a href="http://wittyfans.com/coding/Linux阅读笔记.html">Linux阅读笔记</a>。</p></blockquote><a id="more"></a><h1 id="Linux-Mac-Commands"><a href="#Linux-Mac-Commands" class="headerlink" title="Linux / Mac Commands"></a>Linux / Mac Commands</h1><h1 id="Basic"><a href="#Basic" class="headerlink" title="Basic"></a>Basic</h1><ul><li>cd</li><li>pwd</li><li>ls</li><li>ls -a</li><li>ls -l </li><li>ls -la</li><li>cd .. </li><li>ls sub_dir/</li><li>cd ~</li></ul><h1 id="Files"><a href="#Files" class="headerlink" title="Files"></a>Files</h1><ul><li>mkdir</li><li>touch</li><li>cp, copy a file</li><li>cp -r, copy a directory</li><li>mv, rename or moving a file</li><li>open</li><li>rm</li><li>rm -rf, force removing a directory</li><li>man(-r), show some info</li><li>about, info</li></ul><h1 id="Find"><a href="#Find" class="headerlink" title="Find"></a>Find</h1><h2 id="help"><a href="#help" class="headerlink" title="help"></a>help</h2><ul><li>man find</li></ul><h2 id="by-name"><a href="#by-name" class="headerlink" title="by name"></a>by name</h2><ul><li>find ., list all file and folder below current</li><li>find folder</li><li>find . -type d, find all foldre, no file</li><li>find . -type f, find all file , no foldre</li><li>find . -type f -name “test.txt”, name as text txt file</li><li>find . -type f -name “text*”, name as txt all file</li><li>find . -type f -iname “text*”, 不区分大小写</li><li>find . -type f -name “*.py”</li></ul><h2 id="by-time"><a href="#by-time" class="headerlink" title="by time"></a>by time</h2><ul><li>find . -type f -mmin -10,过去十分钟修改过的文件</li><li>find . -type f -mmin +10</li><li>find . -type f -mmin +1 -mmin -5</li><li>find . -type f -mtime -20</li></ul><blockquote><p>amin,atime: access min and access day; cmin,ctime: change min and change day; mmin,mtime: modify;</p></blockquote><h2 id="by-size"><a href="#by-size" class="headerlink" title="by size"></a>by size</h2><ul><li><p>find . -size +5m</p><blockquote><p>k,g is work too</p></blockquote></li><li><p>ls -lah ./folders, info about sub folder and files,including size</p></li><li>find . -empty</li></ul><h2 id="permission"><a href="#permission" class="headerlink" title="permission"></a>permission</h2><ul><li>find. -perm 777, read, write, and excute</li><li>find folder -exec chown coreschafer:www-data {} +</li></ul><blockquote><p>find folder, will return all folder, -exec will run the command in that results, {} palceholder, + end of the command.</p></blockquote><ul><li>find folder -type f -exec chmod 664 {} +</li><li>find folder -perm 664</li><li>find . -type f -name “*.jpg”</li><li>find . -type f -name “*.jpg” -maxdepth 1, searched 1 level down</li><li>find . -type f -name “*.jpg” -maxdepth 1 -exec rm {} +, delete serched files</li></ul><h1 id="Grep"><a href="#Grep" class="headerlink" title="Grep"></a>Grep</h1><h2 id="Grep-single-file"><a href="#Grep-single-file" class="headerlink" title="Grep single file"></a>Grep single file</h2><blockquote><p>searched text</p></blockquote><ul><li>grep “text_you_want_search” filename.txt</li><li>grep -w “text_you_want_search” filename.txt, have to match all words</li><li>grep -wi “text_you_want_search” filename.txt, igore the lowcase and uppearcse.</li><li>grep -win “text_you_want_search” filename.txt, get info about the line number</li><li>grep -win -B 4 “text_you_want_search” filename.txt, return the context about the searched words, 4 line, behind</li><li>grep -win -A 4 “text_you_want_search” filename.txt, return the context about the searched words, 4 line, ahead</li><li>grep -win -C 4 “text_you_want_search” filename.txt, return the context about the searched words, 4 line, two line before and two behind.</li></ul><h2 id="Grep-multi-file"><a href="#Grep-multi-file" class="headerlink" title="Grep multi file"></a>Grep multi file</h2><ul><li>grep -win “text_” ./*, all file</li><li>grep -win “text_” ./*.txt, txt file</li><li>grep -winr “text” ./ , search all subdir</li><li>grep -wirl “text” ./ , no need match info, just file list</li><li>grep -wirc “text” ./ , show matched number in eatch file</li></ul><h2 id="Grep-command-history"><a href="#Grep-command-history" class="headerlink" title="Grep command history"></a>Grep command history</h2><ul><li>history | grep “git commit”</li><li>history | grep “git commit” | grep “dotfile”</li></ul><h2 id="Grep-rgx"><a href="#Grep-rgx" class="headerlink" title="Grep rgx"></a>Grep rgx</h2><ul><li>grep -P “\d{3}-\d{3}-\d{4}” file.txt, work well in linux, mac need to config, I configed</li></ul><h1 id="cURL"><a href="#cURL" class="headerlink" title="cURL"></a>cURL</h1><h2 id="Requests"><a href="#Requests" class="headerlink" title="Requests"></a>Requests</h2><ul><li>curl url</li><li>curl <a href="http://localhost:5000" target="_blank" rel="noopener">http://localhost:5000</a></li><li>curl http:***/json_file<ul><li>curl -i http:***/json_file, details info about the get</li></ul></li><li>curl http:***/method<ul><li>curl -d “first=name&amp;last=lastname” http:***/method, d for data, Post request</li><li>curl -X PUT -d “first=name&amp;last=lastname” http:***/method, d for data, Pust request</li><li>curl -X DELETE http:***/method, delete request</li></ul></li></ul><h2 id="Verify"><a href="#Verify" class="headerlink" title="Verify"></a>Verify</h2><blockquote><p>could not verify your access ?</p></blockquote><ul><li>curl -u username:password http://***, Auth</li></ul><h2 id="Download"><a href="#Download" class="headerlink" title="Download"></a>Download</h2><blockquote><p>Download file</p></blockquote><ul><li>curl http://***/folder, return binary file , error</li><li>curl -o filename.jpg http://***/folder, sucess</li></ul><blockquote><p>Saving large json file</p></blockquote><ul><li>curl -o file_name.json http:/.api.the_url*</li></ul><h1 id="rsync"><a href="#rsync" class="headerlink" title="rsync"></a>rsync</h1><h2 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h2><blockquote><p>aviable in Mac, debian-based linux need to install</p></blockquote><ul><li>apt-get install rsync</li><li>yum install rsync</li></ul><h2 id="Use"><a href="#Use" class="headerlink" title="Use"></a>Use</h2><ul><li>rsync folder1/* backup/ , sync fils to backup folder,will skping the subfolder’s file, but affected subfolder</li><li>rsync -r folder1/* backup/ , including subfolder’s file</li><li>rsync -r folder1 backup/, sync folder, not content in it</li></ul><h2 id="Check-chage-before-run"><a href="#Check-chage-before-run" class="headerlink" title="Check chage before run"></a>Check chage before run</h2><ul><li>rsync -a –dry-run folder1/* backup/, check before the command run, now view showed<ul><li>rsync -av –dry-run folder1/* backup/, auto view</li></ul></li></ul><h2 id="Source-folder-has-new-file"><a href="#Source-folder-has-new-file" class="headerlink" title="Source_folder has new file"></a>Source_folder has new file</h2><ul><li>rsync -av –delete –dry-run original/ backup/, check, be careful !</li></ul><h2 id="Do-it-in-local-and-host"><a href="#Do-it-in-local-and-host" class="headerlink" title="Do it in local and host"></a>Do it in local and host</h2><ul><li>rsync -zaP -p local_folder username@ip:~/public/, z for compress, a for all, P for tarnsfer in internet</li><li>rsync 0zaP username@ip:~/public/file ~/Downloads/, revers</li></ul><h1 id="Cron"><a href="#Cron" class="headerlink" title="Cron"></a>Cron</h1><ul><li>crontab -l, list the crons</li></ul><blockquote><p>set your editor to nano, default vim</p></blockquote><ul><li><p>export EDITOR=/user/bin/nano</p></li><li><p>crontab -e, open editor</p><ul><li>press i to input</li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Algorhythm for schuel you task with time</span><br><span class="line"></span><br><span class="line"># ┌───────────── minute (0 - 59)</span><br><span class="line"># │ ┌───────────── hour (0 - 23)</span><br><span class="line"># │ │ ┌───────────── day of month (1 - 31)</span><br><span class="line"># │ │ │ ┌───────────── month (1 - 12)</span><br><span class="line"># │ │ │ │ ┌───────────── day of week (0 - 6) (Sunday to Saturday;</span><br><span class="line"># │ │ │ │ │                                       7 is also Sunday on some systems)</span><br><span class="line"># │ │ │ │ │</span><br><span class="line"># │ │ │ │ │</span><br><span class="line"># * * * * *  command_to_execute</span><br></pre></td></tr></table></figure><ul><li><a href="https://youtu.be/QZJ1drMQz1A" target="_blank" rel="noopener">More in</a></li><li><a href="https://github.com/CoreyMSchafer/code_snippets/blob/master/Cron-Tasks/snippets.txt" target="_blank" rel="noopener">snippets</a></li><li><a href="https://crontab.guru/" target="_blank" rel="noopener">tools to make a cron job</a></li></ul><h1 id="Profile"><a href="#Profile" class="headerlink" title="Profile"></a>Profile</h1><ul><li>PS1=”customer_namae”; , change the name, temporary</li><li>ls -la, show dot file, find .bash_profile</li></ul><h2 id="backup"><a href="#backup" class="headerlink" title="backup"></a>backup</h2><ol><li>mv .bash_profile backup_folder</li><li>mv .bashrc back_folder</li></ol><h2 id="created"><a href="#created" class="headerlink" title="created"></a>created</h2><ol><li>cd !</li><li>touch .bash_profile</li><li>touch .bashrc</li><li>subl .bash_profile -&gt; echo “Hello from bash_profile”, subl for sublime</li><li>subl .bashrc -&gt; echo “Hello from bashrc”</li></ol><blockquote><p>bash_profile, run every time you open terminal, or ssh login to some machine. when you input bash, you will get the print from bashrc.</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if [-f ~/.bashrc]; then</span><br><span class="line">source ~/.bashrc</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><h2 id="config-terminal-view"><a href="#config-terminal-view" class="headerlink" title="config terminal view"></a>config terminal view</h2><p>You can add the keywords in below list to the ps1, to show some extra info.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># config display name</span><br><span class="line">ps1 = &quot;-&gt;&quot;; export PS1</span><br><span class="line"></span><br><span class="line"># if you config command is too long, you can += it</span><br><span class="line">ps1 += &quot;some_other_config&quot;</span><br><span class="line"></span><br><span class="line"># add the infomation of you computer, or time</span><br><span class="line"></span><br><span class="line">\u: usernmae</span><br><span class="line">\h: hostname</span><br><span class="line">\n: new line</span><br><span class="line">\t: the current time</span><br><span class="line">\w: current working directory</span><br><span class="line">\W: base name of current working directory</span><br></pre></td></tr></table></figure><p>In shell, you can print with {}, like :</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># This will print the pwd&apos;s output in shell.</span><br><span class="line">You current diretory is $(pwd)</span><br><span class="line"></span><br><span class="line"># change color, no stop, all font will set to orange</span><br><span class="line">echo &quot;$(tput setaf 166) This is orange&quot;</span><br><span class="line"></span><br><span class="line"># set a stop of the change color command</span><br><span class="line">echo &quot;$(tput setaf 166) This is orange $(tput sgr0)&quot;</span><br></pre></td></tr></table></figure><h1 id="Mac-OS-Keyboard-Shortcuts"><a href="#Mac-OS-Keyboard-Shortcuts" class="headerlink" title="Mac OS Keyboard Shortcuts"></a>Mac OS Keyboard Shortcuts</h1><ul><li>using arrow key to view the history command</li><li>ctrl + a, jump to the begining of line</li><li>ctrl + e, jump to the end</li><li>option + left/rithg, jump by words</li><li>holding option key, move mourse to the point you want to go</li><li>ctrl + u, delete code before the point</li><li>ctrl + k, delete everything after the cursor</li><li>!fi, re run the command in history that begins with fi</li><li>ctrl+ r, search the history command that you inputed</li><li>ctrl + l, clean the screen, without clean the history output</li><li>ctrl + k, clearn the screen ,including the history output</li></ul><h1 id="Aliases"><a href="#Aliases" class="headerlink" title="Aliases"></a>Aliases</h1><ol><li>sudo vim .bash_profile</li><li>alias dt = ‘cd !/Desktop/‘</li><li>killall Finder</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.bash_profile</span><br><span class="line">alias testhost=&apos;ssh root@8.8.8.8 -p 22&apos;</span><br></pre></td></tr></table></figure><h1 id="generate-key"><a href="#generate-key" class="headerlink" title="generate key"></a>generate key</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 生成本地秘钥，一路回车即可</span><br><span class="line">ssh-keygen -t rsa</span><br><span class="line"># 上传生成的秘钥到服务器</span><br><span class="line">scp ~/.ssh/id_rsa.pub testhost:~/.ssh/</span><br><span class="line"># 使用以下命令将 id_rsa.pub 更名为 authorized_keys</span><br><span class="line">mv id_rsa.pub authorized_keys</span><br><span class="line"># 修改权限</span><br><span class="line">chmod 700 ~/.ssh/</span><br><span class="line">chmod 600 ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;常用命令的cheatsheet，如果想了解更多理论部分，请参考之前的文章&lt;a href=&quot;http://wittyfans.com/coding/Linux阅读笔记.html&quot;&gt;Linux阅读笔记&lt;/a&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Excel笔记P1</title>
    <link href="http://wittyfans.com/coding/Excel%E7%AC%94%E8%AE%B0P1.html"/>
    <id>http://wittyfans.com/coding/Excel笔记P1.html</id>
    <published>2019-06-07T13:25:55.000Z</published>
    <updated>2019-06-07T13:31:53.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>主要记录我在YouTube上学习到的Excel知识，没有整理所以顺序比较乱。</p></blockquote><a id="more"></a><h1 id="1-省时的快捷键"><a href="#1-省时的快捷键" class="headerlink" title="1. 省时的快捷键"></a>1. 省时的快捷键</h1><ul><li>alt + pageup/pagedown, 左右移动光标</li><li>ctrl + 右/左, 将光标移动到列尾/列首</li><li>ctrl + 上/下，将光标移动到行首/行尾</li><li>如何根据列名快速找到列？<ol><li>选择cell</li><li>shift + space 选择整行</li><li>ctrl + f </li><li>输入名字搜索</li></ol></li></ul><blockquote><p>我电脑按shift + space 没反应，有冲突？ </p></blockquote><ul><li>F2，快速编辑，在excel中，点击cell不会自动编辑，需要双击，你也可以通过按f2开始快速编辑<ul><li>开始快速编辑后，在右下角会显示edit模式，这时候如果你编辑公式，左右光标会在公式之间移动，如果你想要选择cell作为公式的参数呢？再按一次将edit模式变成enter模式即可</li></ul></li></ul><h1 id="2-高级复制粘贴"><a href="#2-高级复制粘贴" class="headerlink" title="2. 高级复制粘贴"></a>2. 高级复制粘贴</h1><h2 id="拖动粘贴"><a href="#拖动粘贴" class="headerlink" title="拖动粘贴"></a>拖动粘贴</h2><ol><li>选中值</li><li>移动光标至框边缘出现四向箭头</li><li>右键鼠标按住不放</li><li>拖动到其它位置</li><li>松开选择粘贴类型</li></ol><h2 id="粘贴选择多格式"><a href="#粘贴选择多格式" class="headerlink" title="粘贴选择多格式"></a>粘贴选择多格式</h2><ol><li>正常复制</li><li>按 ALT+E+S,打开粘贴格式面板（Mac使用contrl+command+v）<ol><li>自定义粘贴</li><li>比如按v -&gt; 回车，只粘贴值</li></ol></li></ol><p>如果你的键盘有menu键，可以之间使用memu+v粘贴值。</p><h1 id="3-在两个表中使用VLookup-Hlookup函数"><a href="#3-在两个表中使用VLookup-Hlookup函数" class="headerlink" title="3. 在两个表中使用VLookup/Hlookup函数"></a>3. 在两个表中使用VLookup/Hlookup函数</h1><p>如果你表的header在上面，使用vlookup函数，如果你的header在左边，那么hlookup也许更适合你。</p><h2 id="Vertical-Look-UP"><a href="#Vertical-Look-UP" class="headerlink" title="Vertical Look UP"></a>Vertical Look UP</h2><blockquote><p>V stands for Vertical look up, not value, as there is a Hlookup = horzizontal；大家可能把vlookup函数理解为value look up，其实它是 vertical lookup</p></blockquote><p>你只能根据左边的列找出右边列的值，而不可以通过根据右边的列来找出左边列的值。</p><p>先将两个表摊开放到一起看，选择review -&gt; Arrange all -&gt; vertical</p><p>使用vlookup函数，它需要四个参数：</p><ol><li>查什么？选中那个cell</li><li>去哪里查，选中整个范围</li><li>查所选数据中的第几列，需要注意，excel从1开始编号</li><li>精确匹配还是近似匹配（近似匹配：查a，那么abc也会被返回）</li></ol><p>按回车，就可以成功的找出你需要的值。</p><h2 id="Horzizontal-Look-UP"><a href="#Horzizontal-Look-UP" class="headerlink" title="Horzizontal Look UP"></a>Horzizontal Look UP</h2><p>使用hlookup函数，它需要四个参数：</p><ol><li>查什么？选中那个cell</li><li>去哪里查，选中整个范围</li><li>查所选数据中的第几行，需要注意，excel从1开始编号</li><li>精确匹配还是近似匹配（近似匹配：查a，那么abc也会被返回）</li></ol><h1 id="4-如何把两列值相加"><a href="#4-如何把两列值相加" class="headerlink" title="4. 如何把两列值相加"></a>4. 如何把两列值相加</h1><p>假设两个cell的值类型为文本(Text)，也就是字符串，可以直接将两个值使用 &amp; 结合，如果不是文本，你可以使用Text函数完成，即:Text(值的坐标,0).</p><h1 id="5-透视表"><a href="#5-透视表" class="headerlink" title="5. 透视表"></a>5. 透视表</h1><p>我是在Python中使用过 pivot_table 才知道 pivot 操作的意思，接触 excel 后才知道这叫透视表，有些人也叫这个数据剖析.</p><p>anyway, 今天来记录一下透视表的使用。</p><p>我使用的是 excel 2016 英文版，微软的 excel 界面不会差太多，打开excel你的界面应该和我差不多。</p><p>首先你需要打开你的表，然后选择你需要透视的数据：</p><p><img src="https://i.loli.net/2019/06/04/5cf65f311a5c943124.png" alt="pivot_table0.png"></p><h1 id="6-我只要透视后的排名前十的数据"><a href="#6-我只要透视后的排名前十的数据" class="headerlink" title="6. 我只要透视后的排名前十的数据"></a>6. 我只要透视后的排名前十的数据</h1><p>点击 cell 旁边的 sort 按钮，点击 value filter, 选择最下面的 top 10， 当然你也可以在这里做其他的filter操作。</p><h1 id="7-安装-excel-插件"><a href="#7-安装-excel-插件" class="headerlink" title="7 安装 excel 插件"></a>7 安装 excel 插件</h1><p> excel的插件是 xlam 格式的文件，你不可以直接双击打开，需要打开excel.</p><p> file -&gt; add-ins -&gt; manage -&gt; go</p><p> 这时候可以看到你安装好了的和没安装的插件，然后点击 browser，找到你的插件，点击 ok 即可。</p><p> 插件会每次都随着excel的打开而启动，也许有时候你并不需要这样，你可以在 Developer, add-ins 里面 把这个插件的选项 unchec。</p><h1 id="8-完全卸载excel插件"><a href="#8-完全卸载excel插件" class="headerlink" title="8. 完全卸载excel插件"></a>8. 完全卸载excel插件</h1><ol><li>取消选择插件。</li><li>file -&gt; options -&gt; add-ins</li><li>选择需要卸载的插件，找到路径</li><li>打开该路径，删除该插件</li><li>打开选择插件按钮，重新选择，excel会提示无法找到，是否删除，点击确定</li></ol><h1 id="9-插件不见了？重新加载插件"><a href="#9-插件不见了？重新加载插件" class="headerlink" title="9. 插件不见了？重新加载插件"></a>9. 插件不见了？重新加载插件</h1><ol><li>file - options - add-ins</li><li>manage -&gt; disabled items -&gt; go</li></ol><h1 id="10-做一个drop-down-memu（下拉菜单）"><a href="#10-做一个drop-down-memu（下拉菜单）" class="headerlink" title="10. 做一个drop down memu（下拉菜单）"></a>10. 做一个drop down memu（下拉菜单）</h1><p>下拉菜单可以让你在填写cell中的值的时候，有一些选择，不用手动填写也避免了错误的输入，发现一个插件 List Search（免费），可以很简单的创建下拉菜单。</p><h1 id="11-做一个-Table-of-contents-Gallery"><a href="#11-做一个-Table-of-contents-Gallery" class="headerlink" title="11. 做一个 Table of contents Gallery"></a>11. 做一个 Table of contents Gallery</h1><p>我也不知道如何翻译这个词，反正就是把你所有做好的图，整齐的放在第一页做一个预览图，点击后就可以跳转到子页面，类似这样：</p><p><img src="https://i.loli.net/2019/06/04/5cf6780d097a640476.jpeg" alt="56D77E73-AE1E-4F47-853D-55DEFD291D38.jpeg"></p><p>Tab Hound, 需要收费，有兴趣的可以找到这个文章研究一下宏的用法。</p><h1 id="12-过滤器"><a href="#12-过滤器" class="headerlink" title="12. 过滤器"></a>12. 过滤器</h1><p>点击任意的cell，ctrl+shift+L, 启动/关闭过滤器。</p><p>在过滤器中，你可以按照一列中的值去过滤整个表（不是删除，只是隐藏），你也可以在里面排序。</p><p>推荐数据转换成 Table 分析，这样配合过滤器使用，在你插入行和列的时候，exel会自动将你的操作与filter关联起来，利用公式求值的时候，table会自动填充表中其他row的值。</p><p>在table中，你也可以轻松的添加 total 的行，excel会自动帮你计算（不包括隐藏的值），可以选择求和，求平均等操作。</p><p>table还可以对同一个sheet中的两个table一起过滤。</p><p>一些常用的filter快捷键：</p><ul><li>alt + 下箭头，就可以快速调出filter的菜单</li><li>alt + 下 + e, 调出filter菜单然后开始输入文字搜索</li><li>alt + 下 + c, 清除当前列的 filter条件</li><li>shfit + alt + 下，在任意cell调出filter菜单</li><li>alt + 下 + f + e + enter, 快速找出为空的行</li></ul><p>最舒服的是根据当前选择的值进行筛选:</p><ul><li>右键-&gt; filter -&gt; filter by selected cell’s value</li><li>快捷键：menu key + E + V (Windows)</li></ul><h2 id="多列过滤"><a href="#多列过滤" class="headerlink" title="多列过滤"></a>多列过滤</h2><p>过滤器默认是只针对这些看得见的数据的，所以可以很简单的进行多列过滤。你可想象，每次进行一个过滤器的应用，都是给你看得见的结果加了一个条件，在编程的世界里，也就是进行了and操作。</p><p>但如果你想要or操作呢？</p><p>你可以借助or公式来达到这个目的：</p><p><img src="https://i.loli.net/2019/06/04/5cf68eafbf80710954.jpeg" alt="or"></p><p>你可以直接将鼠标移动到filter button上，查看当前的条件，而不需要进去菜单。</p><h2 id="重复值过滤"><a href="#重复值过滤" class="headerlink" title="重复值过滤"></a>重复值过滤</h2><p>你想要找某一列中重复的值，然后把他们放在一起对比。</p><ol><li>选择列</li><li>conditional formating, highlight cell</li><li>筛选，sort</li></ol><h2 id="根据已有的list过滤"><a href="#根据已有的list过滤" class="headerlink" title="根据已有的list过滤"></a>根据已有的list过滤</h2><ol><li>选择列</li><li>打开filter菜单</li><li>搜索到你需要的关键字</li><li>选择第二个，同时加上“添加”选项</li></ol><h1 id="13-Power-Query"><a href="#13-Power-Query" class="headerlink" title="13. Power Query"></a>13. Power Query</h1><h2 id="Tidy-Data"><a href="#Tidy-Data" class="headerlink" title="Tidy Data"></a>Tidy Data</h2><p>在利用Python Pandas分析数据的时候，我们最开始一般都需要将数据转化成容易分析的格式，也就是大家所说的Tiday Data, 如果你不知tidy data的定义，那么可以参考<a href="https://vita.had.co.nz/papers/tidy-data.pdf" target="_blank" rel="noopener">这篇</a>文章。</p><p>那么在Exce中如何进行这样的操作呢？今天发现可以利用 Power Query 实现这个需求。</p><p>如果你的Excel版本是2016，那么Power Query就已经内置在其中了，如果是比较早的版本，那么可以在<a href="https://www.microsoft.com/en-us/download/confirmation.aspx?id=39379" target="_blank" rel="noopener">这个</a>页面下载到Power Query。</p><p>同时微软也提供了 Power Query 的<a href="https://support.office.com/en-us/article/power-query-overview-and-learning-ed614c81-4b00-4291-bd3a-55d80767f81d" target="_blank" rel="noopener">教程</a>.</p><p>要 unpivolt 你的数据，</p><ol><li>选择你的数据</li><li>Insert -&gt; Table, 将你的数据转化成Table</li><li>再点击Data -&gt; From Table，进入 Power Query 的编辑界面</li><li>选择你需要操作的列</li><li>点击 Transform -&gt; Unpivot Columns (如果你没看到这个选项，将excel拖宽一点)</li></ol><p>这样就完成了你数据的转化，你还可以对 unpivot 后的数据进行过滤操作。</p><h2 id="Unpivot-Columns"><a href="#Unpivot-Columns" class="headerlink" title="Unpivot Columns"></a>Unpivot Columns</h2><p>假设你的数据是这样的:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1 a,b</span><br><span class="line">2 b,c</span><br></pre></td></tr></table></figure><p>然后你想要把它们分开，就像这样:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1 a</span><br><span class="line">1 b</span><br><span class="line">2 b</span><br><span class="line">2 c</span><br></pre></td></tr></table></figure></p><p>基本操作和上面的是一样的，</p><ol><li>选择data -&gt; from table</li><li>home-&gt; spilt columns -&gt; by delimiter -&gt; ok</li><li>删除多余的列</li><li>transform -&gt; unpivot columns</li></ol><h2 id="根据已有的数据计算百分比"><a href="#根据已有的数据计算百分比" class="headerlink" title="根据已有的数据计算百分比"></a>根据已有的数据计算百分比</h2><ol><li>输入总数</li><li>输入函数开始计算，在这一步需要注意关闭 Generate GetPirovtData选项，方法是:<ol><li>点击需要计算的值</li><li>analyse-&gt; options 去掉Generate GetPirovtData的钩</li><li>输入函数计算值</li><li><strong>control + shift 5</strong> 快速转换成百分比</li></ol></li></ol><h1 id="14-如何根据现有数据绘图"><a href="#14-如何根据现有数据绘图" class="headerlink" title="14. 如何根据现有数据绘图"></a>14. 如何根据现有数据绘图</h1><ol><li>选择你要绘制图的数据</li><li>insert table，选择图类型</li><li>选择labels<ol><li>select data</li><li>edite labels</li><li>选择label的区间</li></ol></li></ol><h1 id="15-如何制作excel选择器"><a href="#15-如何制作excel选择器" class="headerlink" title="15. 如何制作excel选择器"></a>15. 如何制作excel选择器</h1><p>我们在预览数据的时候，可以通过过滤器(Filter)来过滤我们看到的数据，这时候可以在过滤器标签上看到它显示为 Multiple Items, 但是我们并不能很直观的看到它到底选择了什么数据项。</p><p>为了让你所选的项目一目了然，我们可以制作一个多选菜单：</p><ol><li>Add a Slicer</li></ol><p>首先，先将你的数据透视好，然后在你透视操作的基列上面点击，再打开analyse选项卡，插入 Slicer, 选择你需要选择的列，然后你就可以看到 slicer 出现，你可以在这里选择过滤项目。</p><p>但是如何知道你选择了哪些项目呢？也就是说如果你需要在另一个表中使用你选过哪些选项要怎么实现呢？</p><p>你可以copy一份你已经透视过的表（需要注意保留filter），然后在 pivot 选项中，将除了filte的其他值全部删掉，这样你在 slicer中选择的时候，这个list也会实时更新。</p><h1 id="16-excel编程"><a href="#16-excel编程" class="headerlink" title="16. excel编程"></a>16. excel编程</h1><h2 id="函数定义"><a href="#函数定义" class="headerlink" title="函数定义"></a>函数定义</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">function func_name(arg as arg_type) as returned_type</span><br><span class="line">    func_name = caculated_value</span><br><span class="line">end function</span><br><span class="line"></span><br><span class="line">用中文解释一遍：</span><br><span class="line"></span><br><span class="line">function 函数名(参数 as 参数数据类型) as 返回值类型</span><br><span class="line">    函数名= 计算的结果</span><br><span class="line">function</span><br></pre></td></tr></table></figure><ul><li>function 是关键字，用来定义函数</li><li>end function 用来标记函数的结束</li><li>excel 的函数没有类似编程语言中的return关键字，只需要把计算结果赋值给函数名即可完成结果的返回</li></ul><h2 id="参考python语法对比"><a href="#参考python语法对比" class="headerlink" title="参考python语法对比"></a>参考python语法对比</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># python</span><br><span class="line">a = 10</span><br><span class="line"></span><br><span class="line"># excel</span><br><span class="line">dim a as 10</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># if 语句</span><br><span class="line"># python</span><br><span class="line">if a == b:</span><br><span class="line">    ...</span><br><span class="line">else:</span><br><span class="line">   ...</span><br><span class="line"></span><br><span class="line"># excel</span><br><span class="line"></span><br><span class="line">if a==b then</span><br><span class="line">    ...</span><br><span class="line">else</span><br><span class="line">    ....</span><br><span class="line">end if</span><br></pre></td></tr></table></figure><h1 id="17-锁定某个Cell"><a href="#17-锁定某个Cell" class="headerlink" title="17. 锁定某个Cell"></a>17. 锁定某个Cell</h1><ol><li>选中所有其他的cell，formate -&gt; proctet -&gt; 取消选中</li><li>在sheet name右键，保护该表</li><li>设置密码</li></ol><p>锁定某个cell的好处：</p><p>假设你按照行统计，用扫码枪去扫描自动输入，果excel会自动换行，某一行你想要直接跳过，就可以设置锁定不允许选择。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;主要记录我在YouTube上学习到的Excel知识，没有整理所以顺序比较乱。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="coding" scheme="http://wittyfans.com/categories/coding/"/>
    
    
      <category term="data analyse" scheme="http://wittyfans.com/tags/data-analyse/"/>
    
      <category term="数据分析" scheme="http://wittyfans.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>PowerShell通过http, https, 和ftp下载文件</title>
    <link href="http://wittyfans.com/coding/PowerShell%E9%80%9A%E8%BF%87Http-HTTPS-%E5%92%8CFTp%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6.html"/>
    <id>http://wittyfans.com/coding/PowerShell通过Http-HTTPS-和FTp下载文件.html</id>
    <published>2019-04-08T14:13:44.000Z</published>
    <updated>2019-04-08T14:29:56.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>利用 <em>PowerShell</em> 发起请求，不仅可以下载文件，还可以利用管道对文件进行解析，这一点比 <em>CMD</em> 命令行和 <em>Linux</em> 下的 <em>wget</em> 还要好用。</p></blockquote><a id="more"></a><h1 id="内网环境下"><a href="#内网环境下" class="headerlink" title="内网环境下"></a>内网环境下</h1><p>如果你工作的环境主要是通过 <em>Server Message Block (SMB)</em> 协议来传输文件，那么可以直接在 <em>powershell</em> 中使用 <em>copy-item</em> 命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Copy-Item -Source \\server\share\file -Destination C:\path\</span><br></pre></td></tr></table></figure><p>如果你在公司的内网（域环境）下，那么这个命令挺适合你，如果你是要下载外网或者 <em>Internet</em> 上面的数据，事情就变得复杂一点了。</p><h1 id="Internet"><a href="#Internet" class="headerlink" title="Internet"></a>Internet</h1><h2 id="任意版本-powershell"><a href="#任意版本-powershell" class="headerlink" title="任意版本 powershell"></a>任意版本 <em>powershell</em></h2><p>如果你用的power shell 2.x 的版本，你需要使用 <em>new-object</em> 配合 <em>System.Net.WebClient</em> 来实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$WebClient = New-Object System.Net.WebClient</span><br><span class="line">$WebClient.DownloadFile(&quot;https://www.wittyfans.com/file&quot;,&quot;C:\path\file&quot;)</span><br></pre></td></tr></table></figure><h2 id="powershell-版本3-x-以上"><a href="#powershell-版本3-x-以上" class="headerlink" title="powershell 版本3.x 以上"></a><em>powershell</em> 版本3.x 以上</h2><p>如果是 <em>powershell 3.x</em>, 可以用 <em>Invoke-WebRequest</em>命令。Invoke-WebRequest 和Linux其实还有一些关系。它比 <em>wget</em> 还要好用一些，因为它不仅可以下载，而且可以对文件进行解析。</p><p>使用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Invoke-WebRequest -Uri &quot;http://www.wittyfans.com&quot; -OutFile &quot;C:\path\file&quot;</span><br></pre></td></tr></table></figure><ul><li>默认会下载这个网页，所以如果你指定的下载路径只是一个文件夹，<em>powershell</em>会提示找不到路径，这时候你需要指定路径加文件名.</li><li>如果你省略本地路径，则<em>powershell</em>会默认使用脚本所在目录的路径</li></ul><p>举例：</p><p>下载<em>sublime</em>:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Invoke-WebRequest -uri &quot;https://download.sublimetext.com/Sublime%20Text%20Build%203207%20x64%20Setup.exe&quot; -OutFile &quot;C:\Users\wittyfans\Desktop\sublime.exe&quot;</span><br></pre></td></tr></table></figure><p><em>Invoke-WebRequest</em> 默认把下载的东西传输给管道，如果你需要保存文件，必须要指定 <em>outfile</em> 参数。而且你还可以在管道中后面去分析这个文件，如果你传输的是二进制文件，<em>power shell</em>会默认以文本的方式处理，这时候你就没办法分析了，不过你可以增加一个参数，只分析文本内容，你需要这样使用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Invoke-WebRequest &quot;http://www.wittyfans.com&quot; | Select-Object -ExpandProperty Content | Out-File &quot;file&quot;</span><br></pre></td></tr></table></figure><p>如果你想要保存所有管道中的文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Invoke-WebRequest &quot;http://www.wittyfans.com&quot; -OutFile &quot;file&quot; -PassThru | Select-Object -ExpandProperty Content</span><br></pre></td></tr></table></figure><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>如果你的下载需要验证身份，<em>powershell</em>不会提示你，除非你指定了用户名，此时<em>powershell</em>会提示你输入密码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 1</span><br><span class="line">Invoke-WebRequest -Uri https://www.wittyfans.com/ -OutFile C:&quot;\path\file&quot; -Credential &quot;yourUserName&quot;</span><br><span class="line"></span><br><span class="line"># 2</span><br><span class="line">$Credentials = Get-Credential</span><br><span class="line">Invoke-WebRequest -Uri &quot;https://www.wittyfans.com&quot; -OutFile &quot;C:\path\file&quot; -Credential $Credentials</span><br></pre></td></tr></table></figure><p>你可以使用<em>-UseDefaultCredentials</em> 参数来使用当前用户的凭据，这样就可以省略 <em>Credential</em> 参数。</p><p>也可以使用弹窗来要求输入密码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$client = new-object System.Net.WebClient</span><br><span class="line">$client.Credentials = Get-Credential</span><br><span class="line">$client.DownloadFile(&quot;http://i.imgur.com/JnphmRt.jpg&quot;,&quot;C:\Users\Fatima Wahab\Desktop\cat.jpg&quot;)</span><br></pre></td></tr></table></figure><p>注意检查资源的路径是对的，如果你的路径是该网站的首页，那么就会出错。</p><p>为了确保安全，建议你使用 <em>https</em> 验证，如果只是基本的验证方式，你的密码可能会被抓包分析出来。</p><p>这种下载的验证方式之适用于那些服务器自己管理凭据的情况，现今很多的公司都是用 <em>content management system (CMS)</em> 来验证用户，这时候你就需要使用<em>powershell</em>填写一些表单再提交,用我写的一个函数来举个例子,这个函数只是验证身份，没有下载的动作:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Function login-in($userName,$userPassWord)&#123;</span><br><span class="line">    # 请求并保存session</span><br><span class="line">    $R=Invoke-WebRequest &quot;the_url&quot; -SessionVariable fb</span><br><span class="line"></span><br><span class="line">    # 填写表单信息</span><br><span class="line">    $Form = $R.Forms[0]</span><br><span class="line">    $Form.Fields[&quot;account&quot;]=$userName</span><br><span class="line">    $Form.Fields[&quot;password&quot;] = $userPassWord</span><br><span class="line">    $Form.Fields[&quot;signIn&quot;] = &quot;Sign+in&quot;</span><br><span class="line"></span><br><span class="line">    # 提交 </span><br><span class="line">    $R=Invoke-WebRequest -Uri (&quot;the_url&quot; + $Form.Action) -WebSession $FB -Method POST -Body $Form.Fields</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果想要安全一些，最好不要使用<em>FTP</em>的方式，建议用<em>SFTP</em> 或者 <em>SCP</em>，但 <em>Invoke-WebRequest</em> 不支持这些协议，你可以安装一些第三方的库来实现，现在已经有相关的库实现了。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://www.addictivetips.com/windows-tips/how-to-download-a-file-with-a-powershell-command-in-windows-10/" target="_blank" rel="noopener">How To Download A File With A PowerShell Command In Windows 10</a></li><li><a href="https://stackoverflow.com/questions/51225598/downloading-a-file-with-powershell" target="_blank" rel="noopener">StackOverFlow上关于 Downloading a file with powershell 的回答</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;利用 &lt;em&gt;PowerShell&lt;/em&gt; 发起请求，不仅可以下载文件，还可以利用管道对文件进行解析，这一点比 &lt;em&gt;CMD&lt;/em&gt; 命令行和 &lt;em&gt;Linux&lt;/em&gt; 下的 &lt;em&gt;wget&lt;/em&gt; 还要好用。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="coding" scheme="http://wittyfans.com/categories/coding/"/>
    
    
      <category term="helpdesk" scheme="http://wittyfans.com/tags/helpdesk/"/>
    
      <category term="powershell" scheme="http://wittyfans.com/tags/powershell/"/>
    
      <category term="windows" scheme="http://wittyfans.com/tags/windows/"/>
    
  </entry>
  
  <entry>
    <title>Pandas 统计工作数据</title>
    <link href="http://wittyfans.com/coding/Pandas-%E7%BB%9F%E8%AE%A1%E5%B7%A5%E4%BD%9C%E6%95%B0%E6%8D%AE.html"/>
    <id>http://wittyfans.com/coding/Pandas-统计工作数据.html</id>
    <published>2019-03-28T12:19:18.000Z</published>
    <updated>2019-03-28T12:20:58.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>利用Pandas统计工作中的数据，包括数据导入、时间序列处理、loc方法，绘图等等。</p></blockquote><a id="more"></a><h1 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h1><p><img src="https://i.loli.net/2019/03/28/5c9cb955919aa.png" alt="import_data.png"></p><ul><li>因为从txt导入数据，所以固定sep为，</li><li>header即没有头部</li><li>爬取日期数据则会将string类型的date自动转化为date类型，方便整理</li></ul><h1 id="设置index"><a href="#设置index" class="headerlink" title="设置index"></a>设置index</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pwdlog = pwdlog.set_index(&apos;date&apos;)</span><br></pre></td></tr></table></figure><p>设置index方便索引，对时间进行切片。</p><h1 id="探索数据"><a href="#探索数据" class="headerlink" title="探索数据"></a>探索数据</h1><h2 id="数据描述"><a href="#数据描述" class="headerlink" title="数据描述"></a>数据描述</h2><p><img src="https://i.loli.net/2019/03/28/5c9cb919e4393.png" alt="describe.png"></p><h2 id="按天数计算数据"><a href="#按天数计算数据" class="headerlink" title="按天数计算数据"></a>按天数计算数据</h2><p><img src="https://i.loli.net/2019/03/28/5c9cb9561af75.png" alt="resample_d.png"></p><p>resample方法将按照时间区间统计数量，count方法为统计，如果是sum则为相加，另也有机酸平均值等方法可选，resample可以将天数缩小为时间，对于的值将会被填充为你想要设置的值，也可以将分钟，小时等统计成天数，周数，工作日等等。</p><h2 id="谁的数据最多？"><a href="#谁的数据最多？" class="headerlink" title="谁的数据最多？"></a>谁的数据最多？</h2><p><img src="https://i.loli.net/2019/03/28/5c9cb956112b1.png" alt="reset_numbers.png"></p><p>to_frame方法主要将这些数据转化为frame。</p><h2 id="哪一天的数据最多？"><a href="#哪一天的数据最多？" class="headerlink" title="哪一天的数据最多？"></a>哪一天的数据最多？</h2><p><img src="https://i.loli.net/2019/03/28/5c9cb9561cd6c.png" alt="reset_order_by_day.png"></p><h2 id="探索2-13这一天的数据"><a href="#探索2-13这一天的数据" class="headerlink" title="探索2/13这一天的数据"></a>探索2/13这一天的数据</h2><p><img src="https://i.loli.net/2019/03/28/5c9cb9553474b.png" alt="2_13_loc .png"></p><p>可以看到一共收到133个用户改密码请求。</p><h2 id="2-13谁处理的请求最多"><a href="#2-13谁处理的请求最多" class="headerlink" title="2/13谁处理的请求最多"></a>2/13谁处理的请求最多</h2><p><img src="https://i.loli.net/2019/03/28/5c9cb95556338.png" alt="2_13_loc_it.png"></p><h1 id="绘图"><a href="#绘图" class="headerlink" title="绘图"></a>绘图</h1><h1 id="按天"><a href="#按天" class="headerlink" title="按天"></a>按天</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pwdlog.resample(&apos;d&apos;).count()[&apos;name&apos;].plot()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/03/28/5c9cb955da58b.png" alt="plot_by_day.png"></p><h1 id="按小时"><a href="#按小时" class="headerlink" title="按小时"></a>按小时</h1><p><img src="https://i.loli.net/2019/03/28/5c9cb955dd364.png" alt="plot_h.png"></p><h1 id="按分钟"><a href="#按分钟" class="headerlink" title="按分钟"></a>按分钟</h1><p><img src="https://i.loli.net/2019/03/28/5c9cb955e96ec.png" alt="plot_m.png"></p><h1 id="按名字"><a href="#按名字" class="headerlink" title="按名字"></a>按名字</h1><p><img src="https://i.loli.net/2019/03/28/5c9cb95565cb9.png" alt="fz.png"></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;利用Pandas统计工作中的数据，包括数据导入、时间序列处理、loc方法，绘图等等。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="coding" scheme="http://wittyfans.com/categories/coding/"/>
    
    
      <category term="bigdata" scheme="http://wittyfans.com/tags/bigdata/"/>
    
      <category term="pandas" scheme="http://wittyfans.com/tags/pandas/"/>
    
  </entry>
  
  <entry>
    <title>NumPy操作数组</title>
    <link href="http://wittyfans.com/coding/NumPy%E6%93%8D%E4%BD%9C%E6%95%B0%E7%BB%84.html"/>
    <id>http://wittyfans.com/coding/NumPy操作数组.html</id>
    <published>2019-02-09T15:00:40.000Z</published>
    <updated>2019-02-09T16:24:25.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>对数组的操作是 <em>NumPy</em> 中很重要的一部分，了解这些内置的方法，可以让你的效率事半功倍。</p></blockquote><a id="more"></a><h1 id="操作数组"><a href="#操作数组" class="headerlink" title="操作数组"></a>操作数组</h1><h2 id="np-meshgrid方法"><a href="#np-meshgrid方法" class="headerlink" title="np.meshgrid方法"></a>np.meshgrid方法</h2><p>如果你给meshgrid两个一位数组，A像这样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[𝑎1,𝑎2,𝑎3]</span><br></pre></td></tr></table></figure><p>B像这样:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[𝑏1,𝑏2,𝑏3]</span><br></pre></td></tr></table></figure><p>如果你运行 <em>np.meshgrid(A,B)</em>,那么你会得到一个嵌套数组，里面分别是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[𝑎1,𝑎1,𝑎1],[𝑎2,𝑎2,𝑎2],[𝑎3,𝑎3,𝑎3]]</span><br></pre></td></tr></table></figure><p>和</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[𝑏1,𝑏1,𝑏1],[𝑏2,𝑏2,𝑏2],[𝑏3,𝑏3,𝑏3]]</span><br></pre></td></tr></table></figure><p>By adding these two arrays together, we can create the 2D array containing, as its elements, every combination of sums between the numbers in the original elements. Arrays such as linspace and arange are typically used to constuct N-D arrays used to plot in 3 dimensions.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import plotly.plotly as py</span><br><span class="line">import plotly.graph_objs as go</span><br><span class="line"></span><br><span class="line">x = np.arange(-10, 10, 0.4)</span><br><span class="line">y = np.arange(-10, 10, 0.4)</span><br><span class="line">XX, YY = np.meshgrid(x, y)</span><br><span class="line">ZZ = np.sin(XX**2 + YY**2) / (XX**2 + YY**2)</span><br><span class="line"></span><br><span class="line">lines = []</span><br><span class="line">line_marker = dict(color=&apos;#0066FF&apos;, width=2)</span><br><span class="line">for i, j, k in zip(XX, YY, ZZ):</span><br><span class="line">    lines.append(go.Scatter3d(x=i, y=j, z=k, mode=&apos;lines&apos;, line=line_marker))</span><br><span class="line"></span><br><span class="line">layout = go.Layout(</span><br><span class="line">    title=&apos;Wireframe with Meshgrid&apos;,</span><br><span class="line">    showlegend=False</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">fig = go.Figure(data=lines, layout=layout)</span><br><span class="line">py.iplot(fig, filename=&apos;numpy-arange-to-meshgrid&apos;)</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2019/02/08/5c5d6f5855efe.png" alt="绘图请配合plotly"></p><h2 id="np-where方法"><a href="#np-where方法" class="headerlink" title="np.where方法"></a>np.where方法</h2><p>假设你有三个数组，第三个数组存的是布尔值，你想要按照条件去前两个数组中选值，如果第三个数组中的值是真，那么就去第一个数组中拿对应的值，否则就拿第二个数组中的值。</p><p>我们可以利用<em>zip</em> 函数实现这一需求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">xarr = np.array([1.1, 1.2, 1.3, 1.4, 1.5])</span><br><span class="line"></span><br><span class="line">yarr = np.array([2.1, 2.2, 2.3, 2.4, 2.5])</span><br><span class="line"></span><br><span class="line">cond = np.array([True, False, True, True, False])</span><br><span class="line"></span><br><span class="line">result = [(x if contidion else y) for x,y,contidion in zip(xarr,yarr,cond)]</span><br><span class="line">result</span><br></pre></td></tr></table></figure><p>虽然这样可以实现，但是会有一些问题：</p><ol><li>如果数组很大就会有性能问题</li><li>多重数组无法这样操作</li></ol><p>利用 <em>np.where</em> 方法，就可以简单的实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result = np.where(cond,xarr,yarr)</span><br></pre></td></tr></table></figure><p><em>np.where</em> 会返回一个新的数组，其中包含了你需要的值。</p><p>再举一个例子，将一堆数中的值进行替换，正数变成2，负数变成-2:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">arr = np.random.randn(2, 10)</span><br><span class="line">arr</span><br><span class="line"></span><br><span class="line"># out</span><br><span class="line">array([[-0.81110748,  0.68433723,  0.52473733, -0.41852741, -2.84401244,</span><br><span class="line">        -1.68747418, -0.11169401, -1.10101844, -0.8750002 ,  1.18884515],</span><br><span class="line">       [-0.30515971,  0.60605408,  0.16320091, -0.99053775, -0.76669183,</span><br><span class="line">        -0.29594746,  0.33500369,  0.28612921, -0.93350166, -0.67301814]])</span><br><span class="line"></span><br><span class="line">np.where(arr&lt;0,-2,2)</span><br><span class="line"># out</span><br><span class="line">array([[-2,  2,  2, -2, -2, -2, -2, -2, -2,  2],</span><br><span class="line">       [-2,  2,  2, -2, -2, -2,  2,  2, -2, -2]])</span><br></pre></td></tr></table></figure><p>通过将arr本身传进去，可以指修改某一部分的值，比如下面是指将负数修改为-2，正数不变:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">np.where(arr&lt;0,-2,arr)</span><br><span class="line"># out</span><br><span class="line"></span><br><span class="line">array([[-2.        ,  0.68433723,  0.52473733, -2.        , -2.        ,</span><br><span class="line">        -2.        , -2.        , -2.        , -2.        ,  1.18884515],</span><br><span class="line">       [-2.        ,  0.60605408,  0.16320091, -2.        , -2.        ,</span><br><span class="line">        -2.        ,  0.33500369,  0.28612921, -2.        , -2.        ]])</span><br></pre></td></tr></table></figure><h2 id="数学方法"><a href="#数学方法" class="headerlink" title="数学方法"></a>数学方法</h2><p><em>Numpy</em> 支持很多常用的数学方法，比如对数组求和，算平均值，等等，可以直接对数组对象调用，也可以通过 <em>np.method</em> 的方式调用。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">arr = np.random.rand(2,2)*10</span><br><span class="line">arr</span><br><span class="line">out:</span><br><span class="line">array([[ 0.89779239,  8.62581317],</span><br><span class="line">       [ 3.48522587,  5.17990087]])</span><br></pre></td></tr></table></figure><h2 id="平均值"><a href="#平均值" class="headerlink" title="平均值"></a>平均值</h2><p><em>arr.mean()</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">4.5471830734485419</span><br></pre></td></tr></table></figure><p>对横向数值求平均：</p><p><em>arr.mean(axis=1)</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([ 4.76180278,  4.33256337])</span><br></pre></td></tr></table></figure><p>纵向数求平均：</p><p><em>arr.mean(axis=0)</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([ 2.19150913,  6.90285702])</span><br></pre></td></tr></table></figure><h2 id="求和"><a href="#求和" class="headerlink" title="求和"></a>求和</h2><p><em>arr.sum()</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">18.188732293794168</span><br></pre></td></tr></table></figure><p>求和函数也可以用 <em>axis</em> 来指定行或列求和。</p><blockquote><p>更多方法请参考附录。</p></blockquote><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><p><img src="https://i.loli.net/2019/02/09/5c5e8e1bb9f55.jpg" alt="math_funcs.jpg"></p><h2 id="布尔数组方法"><a href="#布尔数组方法" class="headerlink" title="布尔数组方法"></a>布尔数组方法</h2><p>可以对一个包含True和False的布尔数组执行 <em>sum</em> 运算：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">arr = np.random.randn(100)</span><br><span class="line">(arr &gt; 0).sum()</span><br><span class="line"></span><br><span class="line">49</span><br></pre></td></tr></table></figure><p><em>bools.any()</em> 测试数组中是否有 <em>True</em> 的:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bools = np.array([False])</span><br><span class="line">bools.any()</span><br><span class="line"></span><br><span class="line"># 输出</span><br><span class="line">False</span><br></pre></td></tr></table></figure><p><em>bools.all()</em> 测试所有值是否都是 <em>True</em>.</p><h2 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h2><p>NumPy 的数组排序：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">arr = np.random.randn(6)</span><br><span class="line">arr.sort()</span><br></pre></td></tr></table></figure><p><em>sort</em> 是 <em>in-place</em> 的， 也就是会修改原来数组的数据。</p><h2 id="Unique函数"><a href="#Unique函数" class="headerlink" title="Unique函数"></a>Unique函数</h2><p>unique函数返回排序后的、数组中唯一的值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">names = np.array([&apos;Bob&apos;, &apos;Joe&apos;, &apos;Will&apos;, &apos;Bob&apos;, &apos;Will&apos;, &apos;Joe&apos;, &apos;Joe&apos;])</span><br><span class="line">np.unique(names)</span><br></pre></td></tr></table></figure><p>它的作用和下面的代码差不多:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sorted(set(names))</span><br></pre></td></tr></table></figure><h2 id="in1d函数"><a href="#in1d函数" class="headerlink" title="in1d函数"></a>in1d函数</h2><p>in1d函数测试一个数组中的值，是否都在另一个数组中，如果在就返回True，不再返回False:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">values = np.array([1,2,3])</span><br><span class="line">np.in1d(values,[1])</span><br><span class="line"># </span><br><span class="line">arrray([True,False,False])</span><br></pre></td></tr></table></figure><p>更多函数请参考下图：</p><p><img src="https://i.loli.net/2019/02/09/5c5eea638e62f.jpeg" alt="array_set_operations.jpeg"></p><h1 id="NumPy数据持久化、随机数生成"><a href="#NumPy数据持久化、随机数生成" class="headerlink" title="NumPy数据持久化、随机数生成"></a>NumPy数据持久化、随机数生成</h1><p>NumPy可以从磁盘读取数据，也可以将数据保存到本地。这个部分只讲一些基本的内容，因为大家可能更喜欢用 <em>Pandas</em> 来导入数据。</p><p>分别介绍两个方法：</p><ul><li><em>np.save</em></li><li><em>np.load</em></li></ul><h2 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">arr = np.arrange(10)</span><br><span class="line">np.save(&apos;/Users/wittyfans/Desktop/data&apos;,arr)</span><br></pre></td></tr></table></figure><h2 id="读取"><a href="#读取" class="headerlink" title="读取"></a>读取</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">saved = np.load(&apos;/Users/wittyfans/Desktop/data.npy&apos;)</span><br><span class="line">saved</span><br><span class="line"># 输出</span><br><span class="line"></span><br><span class="line">array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</span><br></pre></td></tr></table></figure><h2 id="打包储存"><a href="#打包储存" class="headerlink" title="打包储存"></a>打包储存</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.savez(&apos;path&apos;,a=arr,b=arr)</span><br></pre></td></tr></table></figure><h2 id="读取打包文件"><a href="#读取打包文件" class="headerlink" title="读取打包文件"></a>读取打包文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">arch = np.load(&apos;path.npz&apos;)</span><br><span class="line">arch[&apos;a&apos;] # 通过类似dict的方式来读取数据</span><br><span class="line">arch[&apos;b&apos;]</span><br></pre></td></tr></table></figure><h2 id="随机生成"><a href="#随机生成" class="headerlink" title="随机生成"></a>随机生成</h2><p>生成符合正态分布的4x4数组:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">samples = np.random.normal(size=(4, 4))</span><br><span class="line">samples</span><br><span class="line"># 输出</span><br><span class="line"></span><br><span class="line">array([[ 0.5732,</span><br><span class="line"></span><br><span class="line">0.1933, 0.4429, 1.2796],</span><br><span class="line"></span><br><span class="line">[ 0.575 , [-0.5367, [ 0.1525,</span><br><span class="line"></span><br><span class="line">0.4339, -0.7658, -1.237 ],</span><br><span class="line"></span><br><span class="line">1.8545, -0.92 , -0.1082],</span><br><span class="line"></span><br><span class="line">0.9435, -1.0953, -0.144 ]])</span><br></pre></td></tr></table></figure><p>Python内置的 <em>random</em> 模块，相比于NumPy要慢一个数量级。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from random import normalvariate</span><br><span class="line"></span><br><span class="line">N = 1000000</span><br><span class="line"></span><br><span class="line">%timeit samples = [normalvariate(0, 1) for _ in range(N)] 1.77 s +- 126 ms per loop (mean +- std. dev. of 7 runs, 1 loop each)</span><br><span class="line"></span><br><span class="line">%timeit np.random.normal(size=N) 61.7 ms +- 1.32 ms per loop (mean +- std. dev. of 7 runs, 10 loops each)</span><br></pre></td></tr></table></figure><p>这些随机数都是根据种子即 <em>seed</em> 生成的,如果每次生成随机数的时候seed都不变，那么每次生成的随机数都会是一样的。默认NumPy会根据时间来更改seed，这样每次我们就可以拿到不一样的随机数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 随机产生一个数据，此随机数是变动的</span><br><span class="line">print(np.random.random())</span><br><span class="line">print(&apos;--分割线0--&apos;)</span><br><span class="line"># 设置随机数种子</span><br><span class="line">np.random.seed(1)</span><br><span class="line"># 产生一组顺序的固定的数数据</span><br><span class="line">for _ in range(5):</span><br><span class="line">    print(np.random.random())</span><br><span class="line"># 此时，如果再生成一个数据，该数据也是固定的</span><br><span class="line">print(&apos;--分割线1--&apos;)</span><br><span class="line">print(np.random.random())</span><br><span class="line"># 说明我们设置的种子会一直有效，除非我们再次设置</span><br><span class="line">np.random.seed()</span><br><span class="line">print(&apos;--分割线2--&apos;)</span><br><span class="line"># 此随机数是变动的</span><br><span class="line">print(np.random.random())</span><br></pre></td></tr></table></figure><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul><li><a href="https://www.jianshu.com/p/7f4f2303a125" target="_blank" rel="noopener">数据分析学习笔记</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;对数组的操作是 &lt;em&gt;NumPy&lt;/em&gt; 中很重要的一部分，了解这些内置的方法，可以让你的效率事半功倍。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="coding" scheme="http://wittyfans.com/categories/coding/"/>
    
    
      <category term="python" scheme="http://wittyfans.com/tags/python/"/>
    
      <category term="numpy" scheme="http://wittyfans.com/tags/numpy/"/>
    
  </entry>
  
  <entry>
    <title>Numpy Universal Functions</title>
    <link href="http://wittyfans.com/coding/Numpy-Universal-Functions.html"/>
    <id>http://wittyfans.com/coding/Numpy-Universal-Functions.html</id>
    <published>2019-02-09T08:01:12.000Z</published>
    <updated>2019-02-09T08:05:49.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Numpy中一些基本函数参考。</p></blockquote><a id="more"></a><h1 id="Universal-Functions"><a href="#Universal-Functions" class="headerlink" title="Universal Functions"></a>Universal Functions</h1><p><em>Universal Functions</em> 也叫 <em>ufunc</em>，比如开根 <em>sqrt</em>，<em>exp</em>:</p><p><em>Sqrt:</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">arr = np.arange(10)</span><br><span class="line">np.sqrt(arr)</span><br><span class="line">输出：</span><br><span class="line"></span><br><span class="line">array([ 0.        ,  1.        ,  1.41421356,  1.73205081,  2.        ,</span><br><span class="line">        2.23606798,  2.44948974,  2.64575131,  2.82842712,  3.        ])</span><br></pre></td></tr></table></figure><p><em>exp:</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">np.exp(arr)</span><br><span class="line">输出：</span><br><span class="line"></span><br><span class="line">array([  1.00000000e+00,   2.71828183e+00,   7.38905610e+00,</span><br><span class="line">         2.00855369e+01,   5.45981500e+01,   1.48413159e+02,</span><br><span class="line">         4.03428793e+02,   1.09663316e+03,   2.98095799e+03,</span><br><span class="line">         8.10308393e+03])</span><br></pre></td></tr></table></figure><p>你有两个数组，它们的长度都是一样的，你需要对比两个数组中对应的值，返回大的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">a = np.random.randn(1,10)*10</span><br><span class="line"># 输出</span><br><span class="line"></span><br><span class="line">array([[  7.45106569,   2.47039999,  13.3143474 ,  11.73359137,</span><br><span class="line">         -5.16471496,   3.37688733,  -3.03783497,  13.94821303,</span><br><span class="line">        -13.79166595,   4.35553629]])</span><br><span class="line"></span><br><span class="line">b = np.random.randn(1,10)*10</span><br><span class="line"># 输出</span><br><span class="line"></span><br><span class="line">array([[  0.73315303,   5.87494888,   4.01168595,   3.78652398,</span><br><span class="line">         -0.35151181,  -5.61564742,   3.0190971 ,  -2.28944227,</span><br><span class="line">          6.45900038,  14.22907421]])</span><br></pre></td></tr></table></figure><p>利用 <em>np</em> 的 <em>maximun</em> 函数就可以做到：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">np.maximum(a,b)</span><br><span class="line"># 输出：</span><br><span class="line"></span><br><span class="line">array([[  7.45106569,   5.87494888,  13.3143474 ,  11.73359137,</span><br><span class="line">         -0.35151181,   3.37688733,   3.0190971 ,  13.94821303,</span><br><span class="line">          6.45900038,  14.22907421]])</span><br></pre></td></tr></table></figure><h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><p><img src="https://i.loli.net/2019/02/09/5c5e89c06da7b.jpg" alt="ufuncs"></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Numpy中一些基本函数参考。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="coding" scheme="http://wittyfans.com/categories/coding/"/>
    
    
      <category term="python" scheme="http://wittyfans.com/tags/python/"/>
    
      <category term="numpy" scheme="http://wittyfans.com/tags/numpy/"/>
    
  </entry>
  
  <entry>
    <title>Windows 批量映射并重命名网络驱动器</title>
    <link href="http://wittyfans.com/coding/Windows-%E6%89%B9%E9%87%8F%E6%98%A0%E5%B0%84%E5%B9%B6%E9%87%8D%E5%91%BD%E5%90%8D%E7%BD%91%E7%BB%9C%E9%A9%B1%E5%8A%A8%E5%99%A8.html"/>
    <id>http://wittyfans.com/coding/Windows-批量映射并重命名网络驱动器.html</id>
    <published>2019-02-08T09:24:34.000Z</published>
    <updated>2019-02-08T09:40:23.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>如何用脚本批量映射windows网络驱动器，并修改其名称？</p></blockquote><a id="more"></a><p>映射网络驱动器后，可以直接在windows的资源管理器中访问指定的网络路径，不用每次都输入常常的路径地址，非常方便。</p><p><img src="https://msegceporticoprodassets.blob.core.windows.net/inline-media/0e21d35a-52f5-4ea4-9971-d0c4a23ea705-zh-hans" alt=""></p><h1 id="手动映射"><a href="#手动映射" class="headerlink" title="手动映射"></a>手动映射</h1><p>映射网络路径很简单</p><ol><li>直接打开文件资源管理器，然后选择映射网络驱动器</li><li>在“驱动器”列表中，选择驱动器号。（任何可用驱动器号均可。）</li><li>在“文件夹”框中，键入文件夹或计算机的路径，或者选择“浏览”以查找文件夹或计算机。若要在每次登录到电脑时都进行连接，请选中“登录时重新连接”复选框。<br>选择“完成”。</li></ol><p>但这有个问题，即它映射后显示的名字是该文件夹的路径，如果名字中有空格或者中文，可能会出现名字就是整个路径的情况，尽管你可以手动改过来，但如果你要在域中批量给电脑映射，这种方式就不太方便了。</p><h1 id="bat直接映射"><a href="#bat直接映射" class="headerlink" title="bat直接映射"></a>bat直接映射</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">@ECHO OFF</span><br><span class="line">net use Z: /delete</span><br><span class="line">net use Z: \\you\\net\\url /persistent:yes</span><br><span class="line">exit</span><br></pre></td></tr></table></figure><p>通过bat批量映射，不过这种方法也无法自定义名字。</p><h1 id="修改注册表-bat"><a href="#修改注册表-bat" class="headerlink" title="修改注册表+bat"></a>修改注册表+bat</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">net use F: /delete</span><br><span class="line">reg add HKCU\Software\Microsoft\Windows\CurrentVersion\Explorer\MountPoints2\##\10.22.22.2#disk#file#&apos;wittyfans file&apos;#files /v _LabelFromReg /t REG_SZ /f /d &quot;我随便映射的一个盘&quot;</span><br><span class="line">net use F: &quot;\\10.22.22.2\disk\file\wittyfans file\files&quot; /persistent:yes</span><br></pre></td></tr></table></figure><p>先将需要命名的盘符删除，再将路径和需要定义的名字添加到注册表,随后映射即可。<br>需要注意几点：</p><ul><li>在注册表编辑语句中，后面的路径中的斜杠需要用井号替代</li><li>路径中文件夹的名字中包含空格的，需要用引号括起来</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;如何用脚本批量映射windows网络驱动器，并修改其名称？&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="coding" scheme="http://wittyfans.com/categories/coding/"/>
    
    
      <category term="windows" scheme="http://wittyfans.com/tags/windows/"/>
    
      <category term="cmd" scheme="http://wittyfans.com/tags/cmd/"/>
    
  </entry>
  
  <entry>
    <title>NumPy之NDarrays创建、运算、切片、索引</title>
    <link href="http://wittyfans.com/coding/NumPy%E4%B9%8BNDarrays%E5%88%9B%E5%BB%BA%E3%80%81%E8%BF%90%E7%AE%97%E3%80%81%E5%88%87%E7%89%87%E3%80%81%E7%B4%A2%E5%BC%95.html"/>
    <id>http://wittyfans.com/coding/NumPy之NDarrays创建、运算、切片、索引.html</id>
    <published>2019-02-08T08:55:13.000Z</published>
    <updated>2019-02-08T08:57:19.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>无须多讲，Most important foundational packages for numerical computing in Python.</p></blockquote><a id="more"></a><h1 id="NumPy之NDarrays创建、运算、切片、索引"><a href="#NumPy之NDarrays创建、运算、切片、索引" class="headerlink" title="NumPy之NDarrays创建、运算、切片、索引"></a>NumPy之NDarrays创建、运算、切片、索引</h1><p>为什么要使用Numpy？给你两组数据运算，然后对比一下性能就知道了，</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">my_arr = np.arange(1000000)</span><br><span class="line"></span><br><span class="line">my_list = list(range(1000000))</span><br></pre></td></tr></table></figure><p>现在对两组数乘以2</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">%time for _ in range(10): my_arr2 = my_arr * 2 </span><br><span class="line"></span><br><span class="line">CPU times: user 20 ms, sys: 50 ms, total: 70 ms Wall time: 72.4 ms</span><br><span class="line"></span><br><span class="line">%time for _ in range(10): my_list2 = [x * 2 for x in my_list] </span><br><span class="line"></span><br><span class="line">CPU times: user 760 ms, sys: 290 ms, total: 1.05 s</span><br></pre></td></tr></table></figure><h2 id="Numpy"><a href="#Numpy" class="headerlink" title="Numpy"></a>Numpy</h2><p>Numpy中生成随机数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">data = np.random.randn(2,3)</span><br></pre></td></tr></table></figure><p>数据长这样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([[-0.05094946, -1.54555805, -1.19695135],</span><br><span class="line">       [-1.06169454,  1.13763682,  0.57538678]])</span><br></pre></td></tr></table></figure><p>将它们乘10:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([[  9.41882893,   3.20674452,  18.05866858],</span><br><span class="line">       [ -7.97835594,  -9.56449228,  -0.83342424]])</span><br></pre></td></tr></table></figure><p>两份数据相加：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([[-2.37617968,  3.45388874, -0.64218591],</span><br><span class="line">       [-2.99399147, -1.11118452, -1.11992404]])</span><br></pre></td></tr></table></figure><p>对于Numpy的数据：</p><blockquote><p>An ndarray is a generic multidimensional container for homogeneous data; that is, all of the elements must be the same type. Every array has a shape, a tuple indicating the size of each dimension, and a dtype, an object describing the data type of the array:</p></blockquote><ul><li>所有的数据必须是同样的类型</li><li>每个数组都有一个元组类型的shape属性，表示这个数组的维度信息</li><li>每个数组都有一个dtype属性用来描述它其中的数据类型</li></ul><p>如上面的data：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data.shape ---&gt; (2, 3)</span><br><span class="line">data.dtype --&gt; dtype(&apos;float64&apos;)</span><br></pre></td></tr></table></figure><blockquote><p>While it’s not necessary to have a deep understanding of NumPy for many data analytical applications, becoming proficient in array-oriented programming and thinking is a key step along the way to becoming a scientific Python guru.</p></blockquote><h2 id="创建-NDarrays"><a href="#创建-NDarrays" class="headerlink" title="创建 NDarrays"></a>创建 NDarrays</h2><p>直接从数组创建：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data1 = [6,7.5,8,0,1]</span><br><span class="line">arr1 = np.array(data1)</span><br><span class="line">arr1</span><br></pre></td></tr></table></figure><p>也可以从多维数组创建：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data2 = [[1, 2, 3, 4], [5, 6, 7, 8]]</span><br><span class="line">arr2 = np.array(data2)</span><br><span class="line"></span><br><span class="line">arr2.shape --&gt; (2,4)</span><br><span class="line">arr2.dim --&gt;2</span><br></pre></td></tr></table></figure><p>可以用 <em>ndim</em> 属性来看数组的维度信息。</p><p>Numpy还有一些有趣的方法，可以直接创建0和1，或者空值：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">np.zeros(10) --&gt; 创建10个0的数组</span><br><span class="line">np.zeros((3,6))</span><br><span class="line">np.empty((2,3,2)) --&gt; 创建两个两列三行的数组</span><br></pre></td></tr></table></figure><p>还有一些创建<em>ndarrays</em>的方法：</p><ul><li>array: Convert input data (list, tuple, array, or other sequence type) to an ndarray either by inferring a dtype</li><li>asarray: Convert input to ndarray, but do not copy if the input is already an ndarray</li><li>arange: Like the built-in range but returns an ndarray instead of a list</li></ul><p>更多的方法可以参考：<em>Python for data analyse, Table 4-1</em></p><h2 id="NDarrays的数据类型"><a href="#NDarrays的数据类型" class="headerlink" title="NDarrays的数据类型"></a>NDarrays的数据类型</h2><p>ndarrays 的data type或者是dtype包含了一些基本的信息(meta),array在定义的时候是可以指定数据类型的，比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">arr1 = np.array([1,2,3],dtype=np.float64)</span><br><span class="line">arr2 = np.array([1,2,3],dtype=np.int32)</span><br></pre></td></tr></table></figure><p>数据类型可以相互转化：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">arr = np.array([1,2,3,4])</span><br><span class="line">arr.dtype</span><br><span class="line"># 输出 dtype(&apos;int64&apos;)</span><br><span class="line"></span><br><span class="line">arr = np.array([1,2,3,4])</span><br><span class="line">floatarr = arr.astype(np.float64)</span><br><span class="line">floatarr.dtype</span><br><span class="line"># 输出 dtype(&apos;float64&apos;)</span><br></pre></td></tr></table></figure><p>相反的<em>float</em>也可以转化成 <em>int</em>,十进制多出来的部分会被四舍五入。</p><h2 id="数组运算"><a href="#数组运算" class="headerlink" title="数组运算"></a>数组运算</h2><p>下面是基本的运算：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arr = np.array([[1., 2., 3.], [4., 5., 6.]])</span><br></pre></td></tr></table></figure><p>乘：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">arr*arr</span><br><span class="line"># out</span><br><span class="line">array([[  1.,   4.,   9.],</span><br><span class="line">       [ 16.,  25.,  36.]])</span><br></pre></td></tr></table></figure><p>减:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">arr-arr</span><br><span class="line"># out</span><br><span class="line">array([[ 0.,  0.,  0.],</span><br><span class="line">       [ 0.,  0.,  0.]])</span><br></pre></td></tr></table></figure><p>所有的运算都是基于相对关系的，记住这一点即可。除此之外，np还支持比较，假设两个arr对比，返回结果会是一个包含true或false的数组。</p><h2 id="切片和索引"><a href="#切片和索引" class="headerlink" title="切片和索引"></a>切片和索引</h2><p>Numpy的切片和索引和数组的差不多，切片就是按照坐标或者坐标范围来找出对应，或对应范围内的值，根据坐标来理解就很简单</p><p><img src="https://i.loli.net/2019/02/08/5c5d05c2d4a0f.jpeg" alt=""></p><p>你可以对一个切片范围内的值重新赋值：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">arr = np.arange(10)</span><br><span class="line">arr[5] --&gt; 5</span><br><span class="line">arr[5:8] --&gt; [5,6,7]</span><br><span class="line">arr[5:8] = 12</span><br><span class="line">arr --&gt; array([ 0,  1,  2,  3,  4, 12, 12, 12,  8,  9])</span><br></pre></td></tr></table></figure><p>np设计需要处理大量的数据，所以对于数组的操作，都是在原来的数据上改动，不会copy。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">arr_slice = arr[5:8]</span><br><span class="line">arr_slice</span><br><span class="line"># out: array([5, 6, 7])</span><br><span class="line"></span><br><span class="line">arr_slice[:] = 9 # [:]是应用在数组中的所有元素</span><br><span class="line">arr</span><br><span class="line"># out: array([0, 1, 2, 3, 4, 9, 9, 9, 8, 9])</span><br></pre></td></tr></table></figure><p>如果你要copy，np提供了一个copy函数:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">arr3d = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])</span><br><span class="line">copyed = arr3d.copy()</span><br><span class="line">copyed</span><br><span class="line"># out:</span><br><span class="line">array([[[ 1,  2,  3],</span><br><span class="line">        [ 4,  5,  6]],</span><br><span class="line"></span><br><span class="line">       [[ 7,  8,  9],</span><br><span class="line">        [10, 11, 12]]])</span><br></pre></td></tr></table></figure><p>可以在两个维度上切片：</p><p><em>arr2d[:]</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([[1, 2, 3],</span><br><span class="line">       [4, 5, 6],</span><br><span class="line">       [7, 8, 9]])</span><br></pre></td></tr></table></figure><p><em>arr2d[:2]</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([[1, 2, 3],</span><br><span class="line">       [4, 5, 6]])</span><br></pre></td></tr></table></figure><p><em>arr2d[:2,1:]</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([[2, 3],</span><br><span class="line">       [5, 6]])</span><br></pre></td></tr></table></figure><p><em>arr2d[:,:0]</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([[1],</span><br><span class="line">       [4],</span><br><span class="line">       [7]])</span><br></pre></td></tr></table></figure><p>参照下图，动手实践几次，就会懂其中的套路了。</p><p><img src="https://i.loli.net/2019/02/08/5c5d054478e7b.jpeg" alt=""></p><h2 id="Boolean-Indexing"><a href="#Boolean-Indexing" class="headerlink" title="Boolean Indexing"></a>Boolean Indexing</h2><p>我们有一批名字:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">names = np.array([&apos;Bob&apos;, &apos;Joe&apos;, &apos;Will&apos;, &apos;Bob&apos;, &apos;Will&apos;, &apos;Joe&apos;, &apos;Joe&apos;])</span><br></pre></td></tr></table></figure><p>我们可以直接通过 <em>names == ‘Bob’</em> 来返回一个检查结果，这个结果包含的是一个 <em>bollean</em> 的 <em>list</em>.</p><p><em>names == ‘Bob’</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([ True, False, False,  True, False, False, False], dtype=bool)</span><br></pre></td></tr></table></figure><p>如果我们有一份数据，也是7行，那么我们可以吧这个包含 <em>True</em> 和 <em>False</em> 的l <em>List</em> 传进去，这样 <em>Numpy</em> 会选出那些对应 <em>True</em> 的行。</p><p><em>data = np.random.randn(7,4)</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">array([[-0.71030181, -0.14900916, -1.15238417, -0.49395683],</span><br><span class="line">       [-0.92601472,  0.88452947, -0.9206763 , -0.43338155],</span><br><span class="line">       [-0.68093622,  0.93612942,  0.03261537,  1.44615091],</span><br><span class="line">       [ 1.40919226, -0.07214425, -0.07973205, -1.01432059],</span><br><span class="line">       [-0.4042085 ,  0.66812768,  0.4715137 ,  0.34981598],</span><br><span class="line">       [ 0.89631112, -0.70534677,  0.44560626,  0.6133761 ],</span><br><span class="line">       [-0.28979691,  0.58481489, -0.06945283, -0.99545537]])</span><br></pre></td></tr></table></figure><p><em>data[names==’Bob’]</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([[-0.71030181, -0.14900916, -1.15238417, -0.49395683],</span><br><span class="line">       [ 1.40919226, -0.07214425, -0.07973205, -1.01432059]])</span><br></pre></td></tr></table></figure><blockquote><p> Boolean selection will not fail if the boolean array is not the correct length, so I recommend care when using this feature.</p></blockquote><p>上面的选择，也可以配合切片：</p><p><em>data[names==’Bob’,:1]</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([[-0.71030181],</span><br><span class="line">       [ 1.40919226]])</span><br></pre></td></tr></table></figure><p>选择除了 <em>Bob</em> 之外的名字：</p><ul><li><em>names != ‘Bob’</em></li><li><em>~(names == ‘Bob’)</em></li></ul><p>对于 <em>names</em> 的过滤，可以用组合条件：</p><ul><li><em>cond = names == ‘Bob’</em></li><li><em>cond = (names==’Bob’) | (names == ‘will’)</em></li></ul><p>对于 <em>data</em> 也一样：</p><p><em>data[data &lt; 0] = 0</em></p><p>设置整行的值也非常简单：</p><p><em>data[names != ‘Joe’] = 7</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">array([[ 7.        ,  7.        ,  7.        ,  7.        ],</span><br><span class="line">       [-0.92601472,  0.88452947, -0.9206763 , -0.43338155],</span><br><span class="line">       [ 7.        ,  7.        ,  7.        ,  7.        ],</span><br><span class="line">       [ 7.        ,  7.        ,  7.        ,  7.        ],</span><br><span class="line">       [ 7.        ,  7.        ,  7.        ,  7.        ],</span><br><span class="line">       [ 0.89631112, -0.70534677,  0.44560626,  0.6133761 ],</span><br><span class="line">       [-0.28979691,  0.58481489, -0.06945283, -0.99545537]])</span><br></pre></td></tr></table></figure><h2 id="Fancy-Indexing"><a href="#Fancy-Indexing" class="headerlink" title="Fancy Indexing"></a>Fancy Indexing</h2><p>Fancy indexing is a term adopted by NumPy to describe indexing using integer arrays. Suppose we had an 8 × 4 array:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">arr = np.empty((8,4),dtype=np.int)</span><br><span class="line">for i in range(8):</span><br><span class="line">    arr[i] = i</span><br><span class="line">arr</span><br></pre></td></tr></table></figure><p>选择单个值：</p><p><em>arr[3,0]</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">out: 3</span><br></pre></td></tr></table></figure><p>选择多行：</p><p><em>arr[[3,0]]</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([[3, 3, 3, 3],</span><br><span class="line">       [0, 0, 0, 0]])</span><br></pre></td></tr></table></figure><p>让我们构建一个按顺序排列的 <em>8x4</em> 的数组：</p><p><em>arr = np.arange(32).reshape((8,4))</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">array([[ 0,  1,  2,  3],</span><br><span class="line">       [ 4,  5,  6,  7],</span><br><span class="line">       [ 8,  9, 10, 11],</span><br><span class="line">       [12, 13, 14, 15],</span><br><span class="line">       [16, 17, 18, 19],</span><br><span class="line">       [20, 21, 22, 23],</span><br><span class="line">       [24, 25, 26, 27],</span><br><span class="line">       [28, 29, 30, 31]])</span><br></pre></td></tr></table></figure><p>按选择前两个子数组的第一个数：</p><p><em>arr[[1,2],[0,0]]</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([4, 8])</span><br></pre></td></tr></table></figure><p>你也可以对选择出来的数组，进行排序：</p><p><em>arr[[1,2]][:]</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([[ 4,  5,  6,  7],</span><br><span class="line">       [ 8,  9, 10, 11]])</span><br></pre></td></tr></table></figure><p><em>arr[[1,2]][:,[0]]</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([[4],</span><br><span class="line">       [8]])</span><br></pre></td></tr></table></figure><p><em>arr[[1,2]][:,[0,3,2,1]]</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([[ 4,  7,  6,  5],</span><br><span class="line">       [ 8, 11, 10,  9]])</span><br></pre></td></tr></table></figure><blockquote><p>Fancy indexing always copies the data into a new array.</p></blockquote><h2 id="Transposing-Arrays-and-Swapping-Axes"><a href="#Transposing-Arrays-and-Swapping-Axes" class="headerlink" title="Transposing Arrays and Swapping Axes"></a>Transposing Arrays and Swapping Axes</h2><h3 id="Shape"><a href="#Shape" class="headerlink" title="Shape"></a>Shape</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">value = 18</span><br><span class="line">x = 2</span><br><span class="line">y = 9</span><br><span class="line">arr = np.arange(value).reshape((x,y))</span><br><span class="line">arr</span><br><span class="line"># 输出 </span><br><span class="line">array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8],</span><br><span class="line">       [ 9, 10, 11, 12, 13, 14, 15, 16, 17]])</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">value = 18</span><br><span class="line">x = 3</span><br><span class="line">y = 6</span><br><span class="line">arr = np.arange(value).reshape((x,y))</span><br><span class="line"># 输出</span><br><span class="line">array([[ 0,  1,  2,  3,  4,  5],</span><br><span class="line">       [ 6,  7,  8,  9, 10, 11],</span><br><span class="line">       [12, 13, 14, 15, 16, 17]])</span><br></pre></td></tr></table></figure><p>只需要确保 Value = X <em> Y 就可以任意 </em>shape* 了。</p><h3 id="Transposing"><a href="#Transposing" class="headerlink" title="Transposing"></a>Transposing</h3><p>看例子：</p><p><em>arr = np.arange(18).reshape((3,6))</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([[ 0,  1,  2,  3,  4,  5],</span><br><span class="line">       [ 6,  7,  8,  9, 10, 11],</span><br><span class="line">       [12, 13, 14, 15, 16, 17]])</span><br></pre></td></tr></table></figure><p><em>arr.T</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">array([[ 0,  6, 12],</span><br><span class="line">       [ 1,  7, 13],</span><br><span class="line">       [ 2,  8, 14],</span><br><span class="line">       [ 3,  9, 15],</span><br><span class="line">       [ 4, 10, 16],</span><br><span class="line">       [ 5, 11, 17]])</span><br></pre></td></tr></table></figure><p><em>Transposing</em> 在矩阵计算中用的非常多，比如用 <em>np.dot</em> 方法计算矩阵的内积:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">arra = np.array([2,3,0])</span><br><span class="line">arrb = np.array([2,-1,1])</span><br><span class="line">np.dot(arra,arrb)</span><br><span class="line"># 输出 1</span><br></pre></td></tr></table></figure><blockquote><p>怎么计算内积？看下图就明白了</p></blockquote><p><img src="https://i.loli.net/2019/02/08/5c5d41ff41077.png" alt=""></p><p><img src="https://i.loli.net/2019/02/08/5c5d4246ea899.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;无须多讲，Most important foundational packages for numerical computing in Python.&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="coding" scheme="http://wittyfans.com/categories/coding/"/>
    
    
      <category term="python" scheme="http://wittyfans.com/tags/python/"/>
    
      <category term="numpy" scheme="http://wittyfans.com/tags/numpy/"/>
    
      <category term="ndarrays" scheme="http://wittyfans.com/tags/ndarrays/"/>
    
  </entry>
  
  <entry>
    <title>Python文件操作与编码</title>
    <link href="http://wittyfans.com/coding/Python%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C%E4%B8%8E%E7%BC%96%E7%A0%81.html"/>
    <id>http://wittyfans.com/coding/Python文件操作与编码.html</id>
    <published>2019-02-06T14:34:30.000Z</published>
    <updated>2019-02-06T14:38:32.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>在数据分析中，我们通常用<em>pandas</em>的 <em>read_csv</em>方法来读取系统中的文件，但理解这背后的原理也是非常重要的，而且幸运的是，这很简单。</p></blockquote><a id="more"></a><h1 id="Python与文件、操作系统交互"><a href="#Python与文件、操作系统交互" class="headerlink" title="Python与文件、操作系统交互"></a>Python与文件、操作系统交互</h1><h2 id="文件读取"><a href="#文件读取" class="headerlink" title="文件读取"></a>文件读取</h2><p>python使用open方法接受一个路径（绝对或相对路径都可以）来读取读取文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">path = &apos;/Users/wittyfans/Documents/data/all_girls.csv&apos; # :)</span><br><span class="line">f = open(path)</span><br></pre></td></tr></table></figure><p>默认打开是以 <em>r</em> 模式打开的，即只读。</p><p>我们可以用推导式来读取文件中的行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lines = [x.rstrip() for x in open(path)]</span><br></pre></td></tr></table></figure><p>当你使用open方法创建一个文件的时候，一定要关掉这个文件:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">f.close()</span><br></pre></td></tr></table></figure><p>python也考虑到了一些人可能记性不好，所以建议你使用这种方式跟文件交互：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">with open(path) as f:</span><br><span class="line">lines = [x.rstrip() for x in f]</span><br></pre></td></tr></table></figure><p><em>with</em> 语句会自动关闭文件。</p><p>在使用open语句的是，有一点要小心，如果当前文件夹內有一个a.txt的文件，如果你不小心使用了 <em>f = open(‘./a.txt’,’w’)</em> 语句，那么python会立即创建一个a.txt文件，并替换掉当前的（小心⚠️）。</p><p>假设当前文件夹中有一个ftext.txt文件，如果我运行下面的代码，则可以正常显示文件中的内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">with open(&quot;./ftest.txt&quot;) as f:</span><br><span class="line">    lines = [line for line in f]</span><br><span class="line">    print(lines)</span><br></pre></td></tr></table></figure></p><p>如果我这样写:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">with open(&quot;./ftest.txt&quot;,&apos;w&apos;) as f:</span><br><span class="line">    lines = [line for line in f]</span><br><span class="line">    print(lines)</span><br></pre></td></tr></table></figure><p>则会报错：<em>UnsupportedOperation: not readable</em>，因为文件依据被覆盖。<br>文件模式还有一个 <em>x</em>，它也会在path指定的路径中创建文件，不过如果路径中已经有了文件，则会创建失败。</p><p>如果你想在读取文件的时候，了解当前读取到了哪一行，或者根据行数去做控制，可以使用 <em>f.tell()</em> 函数。</p><h2 id="写文件"><a href="#写文件" class="headerlink" title="写文件"></a>写文件</h2><p>使用文件对象的 <em>write</em> 或者 <em>writelines</em> 方法即可向文件执行写操操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">with open(&apos;tmp.txt&apos;,&apos;w&apos;) as handle:</span><br><span class="line">handle.writelines(x for x in open(path) if len(x) &gt; 1)</span><br><span class="line"></span><br><span class="line">with open(&apos;tmp.txt&apos;) as f:</span><br><span class="line">lines = f.readlines()</span><br></pre></td></tr></table></figure><h2 id="Bytes和Unicode类型"><a href="#Bytes和Unicode类型" class="headerlink" title="Bytes和Unicode类型"></a>Bytes和Unicode类型</h2><p>计算机最早的编码类型是ASCII，能存一个字节的信息，对与英文刚好够用，但是如果对于汉字，最少需要两个字节才能存下来，所以后面为了统一，就制定了Unicode。因为用两个字节去存本来一个字节就可以存下来的东西，unicode会有些浪费，于是就出现了utf-8，它把一个Unicode字符根据不同的数字大小编码成1-6个字节，常用的英文字母被编码成1个字节，汉字通常是3个字节，只有很生僻的字符才会被编码成4-6个字节，这样在网络上传输的时候，可以节省很多带宽。</p><p>这些编码都是可以相互转化的，在计算机内存中，统一使用Unicode编码，当需要保存到硬盘或者需要传输的时候，就转换为UTF-8编码。</p><p>Python的字符串类型是str，在内存中以Unicode表示，一个字符对应若干个字节，如果要在网络上传输，或者保存到磁盘上，就需要把str变为以字节为单位的bytes。</p><p>python中的字节：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = b&apos;ABC&apos;# 字节类型的数据，只占用一个字节</span><br><span class="line">x = &apos;ABC&apos; # str，unicode类型的数据，占用多个字节</span><br></pre></td></tr></table></figure><p>unicode类型的数据（str），可以转化成字节类型表示的数据，通过encode方法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&apos;ABC&apos;.encode(&apos;ascii&apos;) # unicode类型的str，转化成ascii编码类型的数据，转化后占用1个字节</span><br><span class="line">&apos;中文&apos;.encode(&apos;utf-8&apos;) # unicode类型的str，转化成utf-8编码类型的数据，例如从内存到硬盘</span><br></pre></td></tr></table></figure><p>在python中，如果你想要读取10个字符：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">with open(path) as f:</span><br><span class="line">chars = f.read(10)</span><br></pre></td></tr></table></figure><p>这样会从文件中读取10个字符，也就是UTF-8格式下的10个字符。</p><p>如果你以 <em>rb</em> 模式打开：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">with open(path,&apos;rb&apos;) as f:</span><br><span class="line">data = f.read(10)</span><br></pre></td></tr></table></figure><p>则python会读取10个字节，如果是同一份数据，则读取10个字节的这种方式会少一些数据。</p><p>对于file的seek方法要注意，如果你使用的时候出错，会导致后面的读取也出错。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul><li><a href="https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/001431664106267f12e9bef7ee14cf6a8776a479bdec9b9000" target="_blank" rel="noopener">字符串和编码-廖雪峰</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;在数据分析中，我们通常用&lt;em&gt;pandas&lt;/em&gt;的 &lt;em&gt;read_csv&lt;/em&gt;方法来读取系统中的文件，但理解这背后的原理也是非常重要的，而且幸运的是，这很简单。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="coding" scheme="http://wittyfans.com/categories/coding/"/>
    
    
      <category term="python" scheme="http://wittyfans.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>Python函数、生成器、异常处理</title>
    <link href="http://wittyfans.com/coding/Python%E5%87%BD%E6%95%B0%E3%80%81%E7%94%9F%E6%88%90%E5%99%A8%E3%80%81%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86.html"/>
    <id>http://wittyfans.com/coding/Python函数、生成器、异常处理.html</id>
    <published>2019-02-06T07:40:48.000Z</published>
    <updated>2019-02-06T07:44:37.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>函数：命名空间、多个值返回、函数作为对象、Lambda；<br>生成器：生成器表达式、itertools；<br>错误与异常捕获：try 语句的使用；</p></blockquote><a id="more"></a><h1 id="Python-函数"><a href="#Python-函数" class="headerlink" title="Python 函数"></a>Python 函数</h1><h2 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h2><p>函数是实现代码复用与组织化最重要的方法，函数用 <strong>def</strong> 关键字定义：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def my_func(x,y,z=1.5):</span><br><span class="line">if z&gt;1:</span><br><span class="line">return z*(x+y)</span><br><span class="line">else:</span><br><span class="line">return z/(x+y)</span><br></pre></td></tr></table></figure><p>python中返回多个值也是没问题的，如果你写的函数没有返回值，那么默认python会返回 <strong>None</strong>.</p><p>每个函数都有 <em>positional arguments</em> 和 <em>keyword arguments</em>. <em>keyword arguments</em> 在设置函数的默认参数的时候用的比较多，在前面的函数中，x和y是 <em>positional arguments</em>，而z是 <em>keyword arguments</em>。</p><p>这些参数的顺序是有限制的：</p><blockquote><p>keyword arguments must follow the positional arguments(if any).</p></blockquote><h2 id="命名空间"><a href="#命名空间" class="headerlink" title="命名空间"></a>命名空间</h2><p>函数可以访问两种类型的变量，<em>global</em> 和 <em>local</em> 的，中文叫全局的或局部的。</p><p>局部变量在函数运行的时候马上创建，如果函数运行完毕，马上会被销毁（也有例外，但不在这里的讨论范围之内）。</p><p>比如下面的函数:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def func():</span><br><span class="line">a = []</span><br><span class="line">for i in range(5):</span><br><span class="line">a.append(i)</span><br></pre></td></tr></table></figure><p><strong>func()</strong>函数调用后，在它的内部创建了一个空的数组，然后5个元素添加了进去，但当函数运行结束后，a马上就会被销毁。</p><p>假设将代码改成这样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = []</span><br><span class="line">def func():</span><br><span class="line">for i in range(5):</span><br><span class="line">a.append(i)</span><br></pre></td></tr></table></figure><p>修改函数外面的变量是可能的，但这些变量必须声明为 <em>global</em> 类型：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = None</span><br><span class="line">def bind_a_variable():</span><br><span class="line">global a</span><br><span class="line">a = []</span><br><span class="line">bind_a_variable() # 输出 []</span><br></pre></td></tr></table></figure><blockquote><p>个人不是很推荐使用 <em>global</em> 关键字，通常来说全局变量都用来存储一些系统的状态，如果你需要大量的使用，更推荐你用更面向对象的方式，例如类。</p></blockquote><h2 id="返回多个值"><a href="#返回多个值" class="headerlink" title="返回多个值"></a>返回多个值</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def f():</span><br><span class="line">a = 5</span><br><span class="line">b = 6</span><br><span class="line">c = 7</span><br><span class="line">return a,b,c</span><br></pre></td></tr></table></figure><p>python的函数可以返回多个值，它们会被包装成一个元组，随后再被解包。</p><h2 id="函数作为对象"><a href="#函数作为对象" class="headerlink" title="函数作为对象"></a>函数作为对象</h2><p>因为python的函数也是对象，所以可以做很多别的语言很难做到的事情。<br>假设我们有一些数据需要清理：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">states = [&apos; Alabama &apos;, &apos;Georgia!&apos;, &apos;Georgia&apos;, &apos;georgia&apos;, &apos;FlOrIda&apos;,&apos;south carolina##&apos;, &apos;West virginia?&apos;]</span><br></pre></td></tr></table></figure><p>如果你处理过用户提交上来的数据就懂我说的，很多简直想象不到输入都会发生，对于那些输入，我们要去掉首尾空格，多余的符号，正确的首字母大小写等等。一种方法是，我们可以用自带的re正则模块：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line"></span><br><span class="line">def clean_strings(strings):</span><br><span class="line">result = []</span><br><span class="line">for value in strings:</span><br><span class="line">value = value.strip()</span><br><span class="line">value = re.sub(&apos;[!#?]&apos;,&apos;&apos;,value)</span><br><span class="line">value = value.title()</span><br><span class="line">result = append(value)</span><br></pre></td></tr></table></figure><p>上面的结果看起来是这样的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">clean_strings(states)</span><br><span class="line">输出:</span><br><span class="line">[&apos;Alabama&apos;,&apos;Georgia&apos;, &apos;Georgia&apos;, &apos;Georgia&apos;, &apos;Florida&apos;, &apos;South Carolina&apos;, &apos;West Virginia&apos;]</span><br></pre></td></tr></table></figure><p>我们函数作为对象，存到数组中，来实现这一需求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">def remove_punctuation(value):</span><br><span class="line">return re.sub(&apos;[!#?]&apos;, &apos;&apos;, value)</span><br><span class="line"># 函数数组</span><br><span class="line">clean_ops = [str.strip,remove_punctuation,str.title]</span><br><span class="line"></span><br><span class="line"># ops参数接受函数数组对象</span><br><span class="line">def clean_string(strings,ops):</span><br><span class="line">result = []</span><br><span class="line">for value in strings:</span><br><span class="line">for function in ops:</span><br><span class="line">value = function(value)</span><br><span class="line">result.append(value)</span><br><span class="line">return result</span><br><span class="line"></span><br><span class="line">clean_string(states,clean_ops)</span><br><span class="line"></span><br><span class="line">输出是一样的:</span><br><span class="line">[&apos;Alabama&apos;,&apos;Georgia&apos;, &apos;Georgia&apos;, &apos;Georgia&apos;, &apos;Florida&apos;, &apos;South Carolina&apos;, &apos;West Virginia&apos;]</span><br></pre></td></tr></table></figure><p>这种方式可以让你的代码更解耦。</p><p>用map方法也可以将一个函数作用到序列的每一个元素上：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for x in map(remove_punctuation,states):</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure><h2 id="Lambda"><a href="#Lambda" class="headerlink" title="Lambda"></a>Lambda</h2><p>Lambda是把那些很简短的函数形式做了简化，让你可以用一种非常简单的方式定义一个函数，然后将这个小函数用在需要它的地方，这在特定的情境下，非常方便：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def short_function(x):</span><br><span class="line">return x* 2</span><br><span class="line"># 等于</span><br><span class="line">equiv_anon = lambda x: x*2</span><br></pre></td></tr></table></figure><p>看下面代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def apply_to_list(some_list,f):</span><br><span class="line">return [f(x) for x in some_list]</span><br><span class="line"></span><br><span class="line">ints = [1,2,3,4]</span><br><span class="line">apply_to_list(ints,lambdax:x*2)</span><br></pre></td></tr></table></figure><p>你可以在参数中，直接定义要传进去的参数。</p><p>再来看另一个例子，你有一堆字符，你需要根据每一个字符中字母出现的个数多少来排序（重复的不算）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">strings = [&apos;foo&apos;, &apos;card&apos;, &apos;bar&apos;, &apos;aaaa&apos;, &apos;abab&apos;]</span><br><span class="line">strings.sort(key= lambda x: len(set(list(x))))</span><br></pre></td></tr></table></figure><ul><li>list,会将字母串分解</li><li>set,会去掉重复的字母</li></ul><p>最后算出每个字母串的长度并以此排序。</p><blockquote><p>lambda函数是没有<strong>name</strong>属性的</p></blockquote><h1 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h1><p>可以将<em>iter</em>函数作用到序列上，这样便返回了一个生成器。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dict_iterator = iter(some_dict)</span><br><span class="line"></span><br><span class="line">dict_iterator </span><br><span class="line">输出: &lt;dict_keyiterator at 0x7fbbd5a9f908&gt;</span><br></pre></td></tr></table></figure><p>可以用list包含一个生成器，得到内部的值：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">list(dict_iterator)</span><br></pre></td></tr></table></figure><p>生成器是惰性的，比如你要读一个文件有一万行，你不需要一次性全部的读取，用生成器，你只需要一行一行的返回。</p><h2 id="生成器表达式"><a href="#生成器表达式" class="headerlink" title="生成器表达式"></a>生成器表达式</h2><p>生成器表达式和列表推导式有些类似，不过包裹它的是括号：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gen = (x ** 2 for x in range(100))</span><br><span class="line">gen </span><br><span class="line"># 输出 &lt;generator object &lt;genexpr&gt; at 0x109cbf3b8&gt;</span><br></pre></td></tr></table></figure><p>上面这种写法和下面的代码完全一样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def make_gen():</span><br><span class="line">for x in range(100):</span><br><span class="line">yield x**2</span><br><span class="line">gen = make_gen()</span><br></pre></td></tr></table></figure><p>生成器可以像数组一样当作函数的参数，比如计算list內所有数的和：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">gen = [x ** 2 for x in range(100)]</span><br><span class="line">sum(gen) # 输出328350</span><br><span class="line"></span><br><span class="line">gen = （x ** 2 for x in range(100)）</span><br><span class="line">sum(gen) # 生成器当作参数，一样输出328350</span><br></pre></td></tr></table></figure><h1 id="itertools"><a href="#itertools" class="headerlink" title="itertools"></a>itertools</h1><p><em>itertools</em>标准库为一些常用的数据，内置了一些通用的生成器。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import itertools</span><br><span class="line"></span><br><span class="line">first_letter = lambda x: x[0]</span><br><span class="line"></span><br><span class="line">names = [&apos;Alan&apos;, &apos;Adam&apos;, &apos;Wes&apos;, &apos;Will&apos;, &apos;Albert&apos;, &apos;Steven&apos;]</span><br><span class="line"></span><br><span class="line">for letter, names in itertools.groupby(names, first_letter):</span><br><span class="line">print(letter, list(names)) # names is a generator</span><br><span class="line"></span><br><span class="line"># 输出</span><br><span class="line">A [&apos;Alan&apos;, &apos;Adam&apos;] </span><br><span class="line">W [&apos;Wes&apos;, &apos;Will&apos;] </span><br><span class="line">A [&apos;Albert&apos;] </span><br><span class="line">S [&apos;Steven&apos;]</span><br></pre></td></tr></table></figure><h1 id="错误与异常捕获"><a href="#错误与异常捕获" class="headerlink" title="错误与异常捕获"></a>错误与异常捕获</h1><p>健壮的程序一定要有错误与异常捕获，我么要进行类型转化：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">float(&apos;1.2345&apos;) ---&gt; 1.2345</span><br><span class="line">float(&apos;string&apos;) ---&gt; value error</span><br></pre></td></tr></table></figure><p>我们定义一个函数来捕获这个异常：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def attemp_float(x)</span><br><span class="line">tyr:</span><br><span class="line">return float(x)</span><br><span class="line">except:</span><br><span class="line">return x</span><br></pre></td></tr></table></figure><p>这时候，如果捕获到了value error，就会返回输出的数据：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">float(&apos;1.2345&apos;) ---&gt; 1.2345</span><br><span class="line">float(&apos;string&apos;) ---&gt; string</span><br></pre></td></tr></table></figure><p>函数有可能会返回别的错误，这时候需要把可能出现的错误写出来：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">except(TypeError,ValueError)</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>在文件读取中，你打开了一个文件，不管你有没有操作，你都需要把它关闭，这时候就需要用到final语句，即不管前面是否捕获到了异常，最终都要做的事情：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">f = open(path,&apos;w&apos;)</span><br><span class="line">try:</span><br><span class="line">write_to_file(f)</span><br><span class="line">finally:</span><br><span class="line">f.close()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;函数：命名空间、多个值返回、函数作为对象、Lambda；&lt;br&gt;生成器：生成器表达式、itertools；&lt;br&gt;错误与异常捕获：try 语句的使用；&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="coding" scheme="http://wittyfans.com/categories/coding/"/>
    
    
      <category term="python" scheme="http://wittyfans.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>Python推导式探究</title>
    <link href="http://wittyfans.com/coding/Python%E6%8E%A8%E5%AF%BC%E5%BC%8F%E6%8E%A2%E7%A9%B6.html"/>
    <id>http://wittyfans.com/coding/Python推导式探究.html</id>
    <published>2019-02-06T04:08:59.000Z</published>
    <updated>2019-02-06T04:13:26.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>推导式应该是python中最受喜爱的一部分内容了，它可以让你以一种简单的形式过滤原来的数据生成一份新的数据。</p></blockquote><a id="more"></a><h1 id="推导式"><a href="#推导式" class="headerlink" title="推导式"></a>推导式</h1><h2 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h2><p>在数组中，推导式的用法类似这样：</p><p>[<em>expr</em> for val in collection if <em>condition</em>]</p><p>基本上和下面的for循环的意思一样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">result = []</span><br><span class="line">for val in collection:</span><br><span class="line">    if condition:</span><br><span class="line">        result.append(expr)</span><br></pre></td></tr></table></figure><p>举例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">string = [&apos;a&apos;,&apos;as&apos;,&apos;bat&apos;,&apos;car&apos;,&apos;dove&apos;,&apos;python&apos;]</span><br><span class="line">[x.upper() for x in strings if len(x) &gt;2]</span><br><span class="line"></span><br><span class="line">[&apos;BAT&apos;,&apos;CAR&apos;,&apos;DOVE&apos;,&apos;PYTHON&apos;]</span><br></pre></td></tr></table></figure><h2 id="字典"><a href="#字典" class="headerlink" title="字典"></a>字典</h2><p>字典的推导式，类似这样，注意外面是花括号：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dict_comp = &#123;key-expr:value-expr for value in collection if condition&#125;</span><br></pre></td></tr></table></figure><p>快速建立键值对：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loc_mapping = &#123;val:index for index,val in enumerate(strings)&#125;</span><br></pre></td></tr></table></figure><p>假设你有一堆股票数据:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">prices = &#123;</span><br><span class="line">    &apos;ACME&apos;: 45.23,</span><br><span class="line">    &apos;AAPL&apos;: 612.78,</span><br><span class="line">    &apos;IBM&apos;: 205.55,</span><br><span class="line">    &apos;HPQ&apos;: 37.20,</span><br><span class="line">    &apos;FB&apos;: 10.75</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>利用字典推导来过滤这些数据：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 过滤出价格高于200的</span><br><span class="line">p1 = &#123;key: value for key, value in prices.items() if value &gt; 200&#125;</span><br><span class="line"></span><br><span class="line"># 找出科技公司</span><br><span class="line">tech_names = &#123;&apos;AAPL&apos;, &apos;IBM&apos;, &apos;HPQ&apos;, &apos;MSFT&apos;&#125;</span><br><span class="line">p2 = &#123;key: value for key, value in prices.items() if key in tech_names&#125;</span><br></pre></td></tr></table></figure><h2 id="集合"><a href="#集合" class="headerlink" title="集合"></a>集合</h2><p>集合的推导式和列表几乎一样，除了外面的括号不一样<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;expr for value in collection if condition&#125;</span><br></pre></td></tr></table></figure></p><p>假设我们需要一个集合，里面包含了所有集合元素的长度，那么可以这样写:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">unique_lengths = &#123;len(x) for x in strings&#125;</span><br></pre></td></tr></table></figure><p>利用map函数，可以更简洁：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set(map(len,strings))</span><br></pre></td></tr></table></figure><h2 id="复合推导"><a href="#复合推导" class="headerlink" title="复合推导"></a>复合推导</h2><p>假设我们有个二维数组包含了英语和西班牙语的名字:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">all_data = [</span><br><span class="line">                [&apos;John&apos;, &apos;Emily&apos;, &apos;Michael&apos;, &apos;Mary&apos;, &apos;Steven&apos;],</span><br><span class="line">                [&apos;Maria&apos;, &apos;Juan&apos;, &apos;Javier&apos;, &apos;Natalia&apos;, &apos;Pilar&apos;]</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>我们现在想要找出这两个子列表中，包含e字母的个数大于等于两个的，这样我们写一个复合推导:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">result = [name for names in all_data for name in names if name.count(&apos;e&apos;) &gt;=2 ]</span><br><span class="line">result = [&apos;Steven&apos;]</span><br></pre></td></tr></table></figure><p>这样写也许有点难以理解，再来看一个将元组合并成数组的例子:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">some_tuples = [(1,2,3),(4,5,6),(7,8,9)]</span><br><span class="line">flattened = [x for tup in some_tuples for x in tup]</span><br><span class="line">flattened #输出 [1,2,3,4,5,6,7,8,9]</span><br></pre></td></tr></table></figure><p>在[]中的表达式的顺序，其实和我们自己写的遍历数组是一样的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">flattened = []</span><br><span class="line">for tup in some_tuples:</span><br><span class="line">    for x in tup:</span><br><span class="line">        flattened.append(x)</span><br></pre></td></tr></table></figure><p>推导式尽管很方便，但是我们有时候也要从代码可读性上去思考问题，而不是让人在语法上面很困惑你写的代码，虽然这样也是可以的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">some_tuples = [(1,2,3),(4,5,6),(7,8,9)]</span><br><span class="line">[[x for x in tup] for tup in some_tuples]</span><br></pre></td></tr></table></figure><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul><li><em>Python for data analyse - List,Set, and Dict Comprehensions</em></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;推导式应该是python中最受喜爱的一部分内容了，它可以让你以一种简单的形式过滤原来的数据生成一份新的数据。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="coding" scheme="http://wittyfans.com/categories/coding/"/>
    
    
      <category term="python" scheme="http://wittyfans.com/tags/python/"/>
    
  </entry>
  
</feed>
